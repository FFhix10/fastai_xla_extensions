# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).

__all__ = ['XLAOptimProxy', 'XLAOptFuncWrapper']

# Internal Cell
import torch
XLA_AVAILABLE = True
try:
    import torch_xla.core.xla_model as xm
except ImportError as e:
    XLA_AVAILABLE = False
    import warnings
    warnings.warn('fastai_xla_extensions requires Pytorch-XLA, will revert to default',
                  RuntimeWarning)

# Internal Cell
if not XLA_AVAILABLE:
    from types import SimpleNamespace
    import torch.cuda
    def fake_opt_step(opt,barrier=False):
        opt.step()
    def fake_device():
        gpu_available = torch.cuda.is_available()
        return torch.device(torch.cuda.current_device()) if gpu_available else torch.device('cpu')
    xm = SimpleNamespace(
        optimizer_step = fake_opt_step,
        xla_device = fake_device
    )


# Cell
class XLAOptimProxy:
    def __init__(self,opt):
        self.opt = opt

    def xla_step(self):
        xm.optimizer_step(self.opt,barrier=True) # sync on gradient update

    def __getattr__(self,name):
        if name == 'step': # override proxying for step method
                return getattr(self,'xla_step')
        # proxy everything else
        return getattr(self.opt,name)

# Cell
class XLAOptFuncWrapper:
    def __init__(self, f):
        self.f = f
    def __call__(self, *args, **kwargs):
        opt = self.f(*args, **kwargs)
        optim_proxy = XLAOptimProxy(opt)
        return optim_proxy
