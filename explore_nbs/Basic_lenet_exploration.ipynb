{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_lenet_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Basic_lenet_exploration.ipynb",
      "authorship_tag": "ABX9TyORfIqqMNwVl5/SwYVaBPKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/master/explore_nbs/Basic_lenet_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnUX_l8lQ6B",
        "colab_type": "text"
      },
      "source": [
        "# Install fastai2 from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5DZXcBNJoy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "169d4ea3-7503-4202-fde9-ff287e59d85f"
      },
      "source": [
        "!pip uninstall -y fastai fastai2 fastcore"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling fastai-2.0.2:\n",
            "  Successfully uninstalled fastai-2.0.2\n",
            "\u001b[33mWARNING: Skipping fastai2 as it is not installed.\u001b[0m\n",
            "Uninstalling fastcore-1.0.1:\n",
            "  Successfully uninstalled fastcore-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucdOzF7r6ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a0282b28-8ec8-44ee-df32-592aacfc4de4"
      },
      "source": [
        "VERSION = \"20200707\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5115  100  5115    0     0  91339      0 --:--:-- --:--:-- --:--:-- 91339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxoA3fJusV17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "ff7d8bba-7362-4411-ea16-1d0f5b089560"
      },
      "source": [
        "#!TORCH_SHOW_CPP_STACKTRACES=1 python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "!python pytorch-xla-env-setup.py  --version $VERSION --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200707 ...\n",
            "Uninstalling torch-1.6.0:\n",
            "  Successfully uninstalled torch-1.6.0\n",
            "Uninstalling torchvision-0.7.0:\n",
            "  Successfully uninstalled torchvision-0.7.0\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][107.5 MiB/107.5 MiB]                                                \n",
            "Operation completed over 1 objects/107.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][123.8 MiB/123.8 MiB]                                                \n",
            "Operation completed over 1 objects/123.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.2 MiB/  2.2 MiB]                                                \n",
            "Operation completed over 1 objects/2.2 MiB.                                      \n",
            "Processing ./torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (1.18.5)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.0a0+12b5bdc\n",
            "Processing ./torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Done updating TPU runtime\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+2b2085a\n",
            "    Uninstalling torch-xla-1.6+2b2085a:\n",
            "      Successfully uninstalled torch-xla-1.6+2b2085a\n",
            "Successfully installed torch-xla-1.6+5430aca\n",
            "Processing ./torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200707) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.0a0+86b6c3e\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ja-ah6qIEZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMhjxPPaPo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12ea55a2-acfc-4413-da72-96657e72c14e"
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastcore\n",
        "!pip install git+https://github.com/fastai/fastai"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fastai/fastcore\n",
            "  Cloning https://github.com/fastai/fastcore to /tmp/pip-req-build-hub8sk2b\n",
            "  Running command git clone -q https://github.com/fastai/fastcore /tmp/pip-req-build-hub8sk2b\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastcore==1.0.1) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastcore==1.0.1) (20.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from fastcore==1.0.1) (0.35.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore==1.0.1) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fastcore==1.0.1) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastcore==1.0.1) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastcore==1.0.1) (2.4.7)\n",
            "Building wheels for collected packages: fastcore\n",
            "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastcore: filename=fastcore-1.0.1-cp36-none-any.whl size=36911 sha256=29402479a22fa248ec9f9ecf6792b8a27bfb7d2d1abac6306a1eaedfb5b2f866\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rjehpy0s/wheels/8a/2a/23/bc50c8f5e28776b44ac837a01fcfa675724565d4813d8e51c7\n",
            "Successfully built fastcore\n",
            "Installing collected packages: fastcore\n",
            "Successfully installed fastcore-1.0.1\n",
            "Collecting git+https://github.com/fastai/fastai\n",
            "  Cloning https://github.com/fastai/fastai to /tmp/pip-req-build-wacu697c\n",
            "  Running command git clone -q https://github.com/fastai/fastai /tmp/pip-req-build-wacu697c\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (20.4)\n",
            "Requirement already satisfied: fastcore>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (1.0.1)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (0.8.0a0+86b6c3e)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (7.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (2.2.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.2) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==2.0.2) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==2.0.2) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore>=1.0.0->fastai==2.0.2) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fastcore>=1.0.0->fastai==2.0.2) (0.7)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from fastcore>=1.0.0->fastai==2.0.2) (0.35.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.0.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.0.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.0.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==2.0.2) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.2) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.2) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai==2.0.2) (0.16.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (49.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.2) (3.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai==2.0.2) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.2) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.2) (3.1.0)\n",
            "Building wheels for collected packages: fastai\n",
            "  Building wheel for fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai: filename=fastai-2.0.2-cp36-none-any.whl size=182227 sha256=7cdc349a38667d402296708cf68e1bad01eef3833bd5ae67946c8b03a96b6cbd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4roe09pb/wheels/83/30/a0/6fa8a74c9f5a5ab45cdc84e9f9ed56d8a72750e11ebf50a364\n",
            "Successfully built fastai\n",
            "Installing collected packages: fastai\n",
            "Successfully installed fastai-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlAKa0RsbOei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7QTq_ulNZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e583100-b1a2-434c-a642-da7b5fc2d67b"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "path.ls()[2].ls()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/mnist_sample/train/3'),Path('/root/.fastai/data/mnist_sample/train/7')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wHQmbWTpm9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_my_labels(fname):\n",
        "    return int(fname.parent.name[0])\n",
        "\n",
        "dblock = DataBlock(\n",
        "    splitter = RandomSplitter(),\n",
        "    #item_tfms = Resize(128),\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y = get_my_labels\n",
        ")\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq56ddzFZX-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3424c902-6d22-4c7b-c3eb-13ee49f5ad1e"
      },
      "source": [
        "dls_normal = dblock.dataloaders(path)\n",
        "dls_normal.vocab"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [3,7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoJrJqx8BO30",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with convs and F.max_pool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfJVAsAerFku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLenet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.hiden4 = nn.Linear(400, 2) # 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.hiden4(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "lenet = MyLenet()\n",
        "learn = Learner(dls_normal, lenet, metrics=[error_rate, accuracy])\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJpiJ4lr6WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "f76ff566-397b-435b-9eb6-bc8005783fc6"
      },
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(1)\n",
        "learn.validate()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.092843</td>\n",
              "      <td>0.051645</td>\n",
              "      <td>0.016979</td>\n",
              "      <td>0.983021</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.05164510756731033,0.016978517174720764,0.9830214977264404]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YujM_GLxBW4_",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RETI5TWYyn6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lenet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "\n",
        "lenet2 = Lenet2()\n",
        "learn2 = Learner(dls_normal, lenet2, metrics=[error_rate, accuracy])\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hVwXWH0DW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "55e3bd61-9aa4-4191-c5b9-1559d697f217"
      },
      "source": [
        "%%time\n",
        "learn2.fit_one_cycle(1)\n",
        "learn.validate()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.060191</td>\n",
              "      <td>0.034106</td>\n",
              "      <td>0.009009</td>\n",
              "      <td>0.990991</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.05164510756731033,0.016978517174720764,0.9830214977264404]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esGnoThVr5sm",
        "colab_type": "text"
      },
      "source": [
        "# Current TPU implementation callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zALipTPsKxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class XLAOptimProxy:\n",
        "    \"Proxy optimizer to override `opt.step` with Pytorch XLA sync method `xm.optimizer_step` \"  \n",
        "    def __init__(self,opt, barrier=True):\n",
        "        print(\"XLAOptimProxy#__init__\")\n",
        "        self.opt = opt\n",
        "        self._barrier = barrier\n",
        "        \n",
        "    def xla_step(self):\n",
        "        print(\"XLAOptimProxy#xla_step\")\n",
        "        xm.optimizer_step(self.opt,barrier=self._barrier) # sync on gradient update\n",
        "        \n",
        "    def __getattr__(self,name):\n",
        "        if name == 'step': # override proxying for step\n",
        "            return getattr(self,'xla_step')\n",
        "        if name in ('barrier','_barrier'):\n",
        "            return getattr(self,name)\n",
        "      \n",
        "        # proxy everything else\n",
        "        return getattr(self.opt,name)\n",
        "    @property\n",
        "    def barrier(self): return self._barrier\n",
        "    @barrier.setter\n",
        "    def barrier(self,v): self._barrier = v "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGYzZD3iF52x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from fastai.callback.core import Callback\n",
        "\n",
        "class XLAOptCallback(Callback):\n",
        "    'Callback to replace `opt.step` with `xm.optimizer_step(opt)` as required to run on TPU'\n",
        "    def __init__(self, barrier=True):\n",
        "        print(\"XLAOptCallback#__init__\")\n",
        "        self._barrier = barrier\n",
        "  \n",
        "    def before_fit(self):\n",
        "        'replace opt with proxy which calls `xm.optimizer_step` instead of `opt.step`'\n",
        "        print(\"XLAOptCallback#before_fit\")\n",
        "        if self.learn.opt is not None:\n",
        "            if not isinstance(self.learn.opt,XLAOptimProxy):\n",
        "                opt = self.learn.opt\n",
        "                self.learn.opt = XLAOptimProxy(opt, barrier=self._barrier)\n",
        "                \n",
        "    def after_fit(self):\n",
        "        'restore original opt '\n",
        "        print(\"XLAOptCallback#after_fit\")\n",
        "        if isinstance(self.learn.opt, XLAOptimProxy):\n",
        "            opt = self.learn.opt.opt\n",
        "            self.learn.opt = opt\n",
        "    @property\n",
        "    def barrier(self): return self._barrier\n",
        "    @barrier.setter\n",
        "    def barrier(self,v): self._barrier = v"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1MkLSk4rGXa",
        "colab_type": "text"
      },
      "source": [
        "# Load in TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXckuzpuxvWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "c4bebb92-6829-44b2-df18-2cff11c0058b"
      },
      "source": [
        "dblock.summary(path)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_sample\n",
            "Found 14434 items\n",
            "2 datasets of sizes 11548,2886\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: get_my_labels -> Categorize -- {'vocab': (#2) [3,7], 'add_na': False}\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/3/38445.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: get_my_labels -> Categorize -- {'vocab': (#2) [3,7], 'add_na': False}\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/3/38445.png\n",
            "    applying get_my_labels gives\n",
            "      3\n",
            "    applying Categorize -- {'vocab': (#2) [3,7], 'add_na': False} gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(0))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([0, 1, 0, 1]))\n",
            "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([0, 1, 0, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roY-hP7q_XzV",
        "colab_type": "text"
      },
      "source": [
        "# Use TPU device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BxRLBwEH9en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-rqfNkUM6qJ",
        "colab_type": "text"
      },
      "source": [
        "# Aquire a TPU device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9FuvQ7qrEqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "d99be2c3-61a5-4802-d68b-8217259b43f6"
      },
      "source": [
        "\n",
        "dede = xm.xla_device()\n",
        "dls_tpu = dblock.dataloaders(path, device=dede)\n",
        "dls_tpu.show_batch(), dls_tpu.vocab"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, (#2) [3,7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6edzLFvLxnTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_tpu.show([1])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFvkrNLuWH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sgd_xla_opt = XLAOptFuncWrapper(SGD)\n",
        "#adam_xla_opt = XLAOptFuncWrapper(Adam)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaLUPKrpNFD6",
        "colab_type": "text"
      },
      "source": [
        "## First training on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnNXHVhBukge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab8b7326-f936-430c-8f32-e0975377b47b"
      },
      "source": [
        "# from fastai.callback.all import *\n",
        "from fastai.test_utils import *\n",
        "lenet_tpu = Lenet2()\n",
        "tpu_learner = Learner(dls_tpu,\n",
        "                      lenet_tpu,\n",
        "                      device=dede,\n",
        "                      metrics=accuracy, \n",
        "                      loss_func=F.cross_entropy,\n",
        "                      cbs=[XLAOptCallback()])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XLAOptCallback#__init__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npau0oogyXRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "62201221-7cb3-4b72-d9bc-20ad8cbf7eb0"
      },
      "source": [
        "tpu_learner.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XLAOptCallback#before_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "XLAOptCallback#after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "Lenet2 (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 120             48,120     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 84              10,164     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               170        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 59,502\n",
              "Total trainable params: 59,502\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fe83e718ea0>\n",
              "Loss function: <function cross_entropy at 0x7fe85c3d48c8>\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - XLAOptCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-exyB0zrk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "a3edd725-e28a-4e6e-e290-eb9a893f22bf"
      },
      "source": [
        "tpu_learner.show_training_loop()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback, XLAOptCallback]\n",
            "  Start Epoch Loop\n",
            "     - before_epoch   : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - before_batch   : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - before_backward: []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [ProgressCallback, XLAOptCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sHdn1JVRSGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec53d4d1-d539-4ea8-844d-0d0cc9a84569"
      },
      "source": [
        "dls_tpu.device"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vRFNZts9GB",
        "colab_type": "text"
      },
      "source": [
        "# Call fit\n",
        "\n",
        "Will fail in `self.loss.backward(); `?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKrHpX9eu4S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1c4d66c-7003-4bcf-9597-d422087bc2a4"
      },
      "source": [
        "tpu_learner.fit(1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XLAOptCallback#before_fit\n",
            "XLAOptimProxy#__init__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.054927</td>\n",
              "      <td>0.037162</td>\n",
              "      <td>0.986486</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptCallback#after_fit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59-jZT0-vDcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f984ce27-cd14-46ad-f2a0-281f5f3b00f9"
      },
      "source": [
        "tpu_learner.lr_find()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XLAOptCallback#before_fit\n",
            "XLAOptimProxy#__init__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptimProxy#xla_step\n",
            "XLAOptCallback#after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=4.78630090583465e-07, lr_steep=6.309573450380412e-07)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIgeMadvAkSi",
        "colab_type": "text"
      },
      "source": [
        "reference for https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LSsf3k1pj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "786116c9-4a98-4bfb-9274-3a80baf78bb4"
      },
      "source": [
        "ob = tpu_learner.dls.train.one_batch()\n",
        "#print(ob)\n",
        "len(ob), ob[0].shape, ob[1].shape, F.cross_entropy, tpu_learner.pred"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " torch.Size([64, 3, 28, 28]),\n",
              " torch.Size([64]),\n",
              " <function torch.nn.functional.cross_entropy>,\n",
              " None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUiFHiAO6FmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "0e62f057-db01-4951-e3a5-184663307fb9"
      },
      "source": [
        "#the_loss = tpu_learner.loss_func(tpu_learner.pred, *tpu_learner.yb)\n",
        "the_loss = tpu_learner.loss_func(tpu_learner.dls, *tpu_learner.yb)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e520cde51513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#the_loss = tpu_learner.loss_func(tpu_learner.pred, *tpu_learner.yb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthe_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_attr_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_attr_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/data/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgather_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgather_attr_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/transform.py\u001b[0m in \u001b[0;36mgather_attrs\u001b[0;34m(o, k, nm)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: log_softmax"
          ]
        }
      ]
    }
  ]
}