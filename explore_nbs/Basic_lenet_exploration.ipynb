{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_lenet_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Basic_lenet_exploration.ipynb",
      "authorship_tag": "ABX9TyPLx5bLmzO5WZ/XCrLzzoVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Basic_lenet_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnUX_l8lQ6B",
        "colab_type": "text"
      },
      "source": [
        "# Install fastai2 from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMhjxPPaPo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8dfa03f2-abc3-46b4-e986-6f99342fd720"
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastcore\n",
        "!pip install git+https://github.com/fastai/fastai2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fastai/fastcore\n",
            "  Cloning https://github.com/fastai/fastcore to /tmp/pip-req-build-2r8z38b1\n",
            "  Running command git clone -q https://github.com/fastai/fastcore /tmp/pip-req-build-2r8z38b1\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastcore==0.1.18 from git+https://github.com/fastai/fastcore in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7' in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (0.7)\n",
            "Building wheels for collected packages: fastcore\n",
            "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastcore: filename=fastcore-0.1.18-cp36-none-any.whl size=28891 sha256=f319739a3a0079dfb6279dfc7669c0621892c50801f6334c7d9637385834b470\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-firtdulz/wheels/8a/2a/23/bc50c8f5e28776b44ac837a01fcfa675724565d4813d8e51c7\n",
            "Successfully built fastcore\n",
            "Collecting git+https://github.com/fastai/fastai2\n",
            "  Cloning https://github.com/fastai/fastai2 to /tmp/pip-req-build-yzit7jjo\n",
            "  Running command git clone -q https://github.com/fastai/fastai2 /tmp/pip-req-build-yzit7jjo\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastai2==0.0.18 from git+https://github.com/fastai/fastai2 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.1.18)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.7.0a0+a6073f0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.2.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (7.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2==0.0.18) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2==0.0.18) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2==0.0.18) (0.15.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (47.3.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->fastai2==0.0.18) (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (3.1.0)\n",
            "Building wheels for collected packages: fastai2\n",
            "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai2: filename=fastai2-0.0.18-cp36-none-any.whl size=193924 sha256=c3f0f530cad820a1b8af4b3e1d7d7eaba52b8bc76df4a5eac24373e770477dc0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dwituj1v/wheels/a1/59/9a/50335b36924b827e29d5f40b41fc3a008cc1f30dd80e560dfd\n",
            "Successfully built fastai2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlAKa0RsbOei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "c1a9676a-2c25-460f-8aac-316435f25acc"
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('__call__', <function LevelMapper.__call__ at 0x7f33eaa587b8>), ('__init__', <function LevelMapper.__init__ at 0x7f33eaa58730>)]\n",
            "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7f33ea920378>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7f33ea9202f0>)]\n",
            "[('__init__', <function BoxCoder.__init__ at 0x7f33ea920400>), ('decode', <function BoxCoder.decode at 0x7f33ea929510>), ('decode_single', <function BoxCoder.decode_single at 0x7f33ea9296a8>), ('encode', <function BoxCoder.encode at 0x7f33ea929598>), ('encode_single', <function BoxCoder.encode_single at 0x7f33ea929620>)]\n",
            "[('__call__', <function Matcher.__call__ at 0x7f33ea9297b8>), ('__init__', <function Matcher.__init__ at 0x7f33ea920268>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7f33ea929950>)]\n",
            "[('__init__', <function ImageList.__init__ at 0x7f33ea929a60>), ('to', <function ImageList.to at 0x7f33ea929b70>)]\n",
            "[('__init__', <function Timebase.__init__ at 0x7f33ea807ae8>)]\n",
            "[('__init__', <function VideoMetaData.__init__ at 0x7f33ea807840>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7QTq_ulNZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1b2965f-498b-466e-9e89-c0c437b2a0dc"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "path.ls()[2].ls()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/mnist_sample/valid/7'),Path('/root/.fastai/data/mnist_sample/valid/3')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wHQmbWTpm9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_my_labels(fname):\n",
        "    return int(fname.parent.name[0])\n",
        "\n",
        "dblock = DataBlock(\n",
        "    splitter = RandomSplitter(),\n",
        "    #item_tfms = Resize(128),\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y = get_my_labels\n",
        ")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq56ddzFZX-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f725e77-775b-46e4-828b-969f30e8f0bf"
      },
      "source": [
        "dls_normal = dblock.dataloaders(path)\n",
        "dls_normal.vocab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [3,7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoJrJqx8BO30",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with convs and F.max_pool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfJVAsAerFku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "08a6838c-03bc-4f9b-b971-522f8d52352f"
      },
      "source": [
        "class MyLenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLenet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.hiden4 = nn.Linear(400, 2) # 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.hiden4(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "lenet = MyLenet()\n",
        "learn = Learner(dls_normal, lenet, metrics=[error_rate, accuracy])\n",
        "\n",
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.096199</td>\n",
              "      <td>0.066584</td>\n",
              "      <td>0.022523</td>\n",
              "      <td>0.977477</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJpiJ4lr6WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "353dd718-1927-442a-9dae-054989929294"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.06658371537923813,0.022522522136569023,0.977477490901947]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YujM_GLxBW4_",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RETI5TWYyn6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "86e8b9f9-87da-4acc-811c-d5fa5dbe4df6"
      },
      "source": [
        "class Lenet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "\n",
        "lenet2 = Lenet2()\n",
        "learn2 = Learner(dls_normal, lenet2, metrics=[error_rate, accuracy])\n",
        "\n",
        "learn2.fit_one_cycle(1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.069667</td>\n",
              "      <td>0.044307</td>\n",
              "      <td>0.014207</td>\n",
              "      <td>0.985793</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hVwXWH0DW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d59f586-b9b3-45ce-a0b1-87bf28da9073"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.06658371537923813,0.022522522136569023,0.977477490901947]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esGnoThVr5sm",
        "colab_type": "text"
      },
      "source": [
        "# conectarse a TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucdOzF7r6ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d83d310a-ca72-432a-c183-61c4c8a61439"
      },
      "source": [
        "VERSION = \"20200325\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4994  100  4994    0     0  78031      0 --:--:-- --:--:-- --:--:-- 78031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxoA3fJusV17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "58543843-9cc5-418d-f64c-bf7ba4fe4aac"
      },
      "source": [
        "!TORCH_SHOW_CPP_STACKTRACES=1 python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Uninstalling torch-1.6.0a0+bf2bbd9:\n",
            "  Successfully uninstalled torch-1.6.0a0+bf2bbd9\n",
            "Uninstalling torchvision-0.7.0a0+a6073f0:\n",
            "  Successfully uninstalled torchvision-0.7.0a0+a6073f0\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n",
            "\u001b[31mERROR: fastai2 0.0.18 requires torchvision>=0.5, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Done updating TPU runtime\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+2b2085a\n",
            "    Uninstalling torch-xla-1.6+2b2085a:\n",
            "      Successfully uninstalled torch-xla-1.6+2b2085a\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zALipTPsKxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "class XLAOptFuncWrapper:\n",
        "    def __init__(self, f):\n",
        "        self.f = f\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        opt = self.f(*args, **kwargs)\n",
        "        optim_wrapper = OptimWrapper(opt)\n",
        "        def xla_step():\n",
        "            xm.optimizer_step(opt, barrier=True)\n",
        "        # monkeypatch optim_wrapper with xla_step\n",
        "        optim_wrapper.step = xla_step\n",
        "        return optim_wrapper"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1MkLSk4rGXa",
        "colab_type": "text"
      },
      "source": [
        "# Load in TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXckuzpuxvWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "7a96dbff-98d4-4dbc-93f7-c3f0aef9f6e6"
      },
      "source": [
        "dblock.summary(path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_sample\n",
            "Found 14434 items\n",
            "2 datasets of sizes 11548,2886\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: get_my_labels -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/valid/7/8891.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: get_my_labels -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/valid/7/8891.png\n",
            "    applying get_my_labels gives\n",
            "      7\n",
            "    applying Categorize gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(1))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 0]))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roY-hP7q_XzV",
        "colab_type": "text"
      },
      "source": [
        "# Use TPU device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9FuvQ7qrEqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "57fd2697-769c-453a-87a4-84f12e4272c4"
      },
      "source": [
        "tpu_device = xm.xla_device()\n",
        "dls_tpu = dblock.dataloaders(path, device=tpu_device)\n",
        "dls_tpu.show_batch(), dls_tpu.vocab"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, (#2) [3,7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6edzLFvLxnTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_tpu.show([1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFvkrNLuWH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_xla_opt = XLAOptFuncWrapper(SGD)\n",
        "adam_xla_opt = XLAOptFuncWrapper(Adam)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnNXHVhBukge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from fastai2.callback.all import *\n",
        "from fastai2.test_utils import *\n",
        "lenet_tpu = Lenet2()\n",
        "tpu_learner = Learner(dls_tpu, lenet_tpu, metrics=accuracy, \n",
        "                      loss_func=F.cross_entropy, opt_func=adam_xla_opt, cbs=VerboseCallback())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npau0oogyXRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "abd05ad6-0114-4ac3-b946-d41d0c64c324"
      },
      "source": [
        "tpu_learner.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Lenet2 (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 120             48,120     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 84              10,164     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               170        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 59,502\n",
              "Total trainable params: 59,502\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <__main__.XLAOptFuncWrapper object at 0x7f33d7202b00>\n",
              "Loss function: <function cross_entropy at 0x7f33f9953950>\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - VerboseCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-exyB0zrk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "a8a4100b-02a8-475e-91f1-20cf10c7985e"
      },
      "source": [
        "tpu_learner.show_training_loop()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - begin_fit      : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "  Start Epoch Loop\n",
            "     - begin_epoch    : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - begin_train    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - begin_batch    : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - begin_validate : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [ProgressCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vRFNZts9GB",
        "colab_type": "text"
      },
      "source": [
        "# Call fit\n",
        "\n",
        "Will fail in `self.loss.backward(); `?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKrHpX9eu4S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "aba5cef2-65d9-47a2-93be-fc426c899e37"
      },
      "source": [
        "tpu_learner.fit(1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.690310</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ec3b9c172e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59-jZT0-vDcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "78f254e6-ceff-4fdd-ef9a-0599e9d2a50c"
      },
      "source": [
        "tpu_learner.lr_find()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6a1ad10370bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIgeMadvAkSi",
        "colab_type": "text"
      },
      "source": [
        "reference for https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LSsf3k1pj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5692bf10-50d9-4531-8eb2-a196ab0f6f7a"
      },
      "source": [
        "ob = tpu_learner.dls.train.one_batch()\n",
        "#print(ob)\n",
        "len(ob), ob[0].shape, ob[1].shape, F.cross_entropy, tpu_learner.pred"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " torch.Size([64, 3, 28, 28]),\n",
              " torch.Size([64]),\n",
              " <function torch.nn.functional.cross_entropy>,\n",
              " None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdeNARoitRPW",
        "colab_type": "text"
      },
      "source": [
        "# patch one_batch with the code and some extra prints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUqCVrDa7hFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "220ec45e-1182-441c-ed0a-2430d172e345"
      },
      "source": [
        "import traceback\n",
        "\n",
        "@patch_to(Learner)\n",
        "def one_batch(self, i, b):\n",
        "        print(f\"******************** self is {self} i is {i}\")\n",
        "        self.iter = i\n",
        "        try:\n",
        "            self._split(b);                                  self('begin_batch')\n",
        "            self.pred = self.model(*self.xb);                self('after_pred')\n",
        "            if len(self.yb) == 0: return\n",
        "            self.loss = self.loss_func(self.pred, *self.yb); self('after_loss')\n",
        "            print(f\"******************** self.loss is {self.loss}\")\n",
        "            print(f\"******************** self.loss.device = {self.loss.device}\")\n",
        "            if not self.training: return\n",
        "            print(f\"******************** will calculate gradient for loss {type(self.loss)} {self.loss.shape}\")\n",
        "            try:\n",
        "              self.loss.backward()\n",
        "            except Exception as e:\n",
        "              print(f\"******************** did fail\")\n",
        "              print(f\"{e}\")\n",
        "              tb = sys.exc_info()[2]\n",
        "              #etype, value, tb = e\n",
        "              traceback.print_tb(tb) #print_exception(e)\n",
        "\n",
        "            self.loss.backward();                            self('after_backward')\n",
        "            print(f\"******************** PASSED\")\n",
        "            self.opt.step();                                 self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException:                         self('after_cancel_batch')\n",
        "        finally:                                             self('after_batch')\n",
        "\n",
        "#my_one_batch(tpu_learner, 0, 64)\n",
        "print(tpu_learner.splitter)\n",
        "print(tpu_learner._split)\n",
        "\n",
        "tpu_learner.fit(1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function trainable_params at 0x7f33f88e6f28>\n",
            "<bound method Learner._split of <fastai2.learner.Learner object at 0x7f33d6f80ac8>>\n",
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.693072</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "******************** self is <fastai2.learner.Learner object at 0x7f33d6f80ac8> i is 0\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "******************** self.loss is 0.693072497844696\n",
            "******************** self.loss.device = xla:1\n",
            "******************** will calculate gradient for loss <class 'torch.Tensor'> torch.Size([])\n",
            "******************** did fail\n",
            "vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"<ipython-input-27-4b36e6c15e89>\", line 17, in one_batch\n",
            "    self.loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 184, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 123, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4b36e6c15e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4b36e6c15e89>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print_exception(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"******************** PASSED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUiFHiAO6FmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3535c96d-28ec-4a2f-e504-2dc5e8fed883"
      },
      "source": [
        "#the_loss = tpu_learner.loss_func(tpu_learner.pred, *tpu_learner.yb)\n",
        "the_loss = tpu_learner.loss_func(tpu_learner.dls, *tpu_learner.yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-e520cde51513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#the_loss = tpu_learner.loss_func(tpu_learner.pred, *tpu_learner.yb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthe_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_attr_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_attr_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/data/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgather_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgather_attr_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/transform.py\u001b[0m in \u001b[0;36mgather_attrs\u001b[0;34m(o, k, nm)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: log_softmax"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6MZ1tYM6W23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}