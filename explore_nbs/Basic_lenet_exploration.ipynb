{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_lenet_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Basic_lenet_exploration.ipynb",
      "authorship_tag": "ABX9TyM0Vi1mDQ9Kt6YlKsh9FAhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Basic_lenet_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmnUX_l8lQ6B",
        "colab_type": "text"
      },
      "source": [
        "# Install fastai2 from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMhjxPPaPo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b456cdf6-3cfe-4053-ab6e-06adf061f74d"
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastcore\n",
        "!pip install git+https://github.com/fastai/fastai2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fastai/fastcore\n",
            "  Cloning https://github.com/fastai/fastcore to /tmp/pip-req-build-7570ayf4\n",
            "  Running command git clone -q https://github.com/fastai/fastcore /tmp/pip-req-build-7570ayf4\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastcore==0.1.18 from git+https://github.com/fastai/fastcore in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7' in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (0.7)\n",
            "Building wheels for collected packages: fastcore\n",
            "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastcore: filename=fastcore-0.1.18-cp36-none-any.whl size=28891 sha256=fd7dbfb54a1404410fc53106999eb2c3ac19240b9357c0c26c4bcf4a36867bf2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u0ypz3n8/wheels/8a/2a/23/bc50c8f5e28776b44ac837a01fcfa675724565d4813d8e51c7\n",
            "Successfully built fastcore\n",
            "Collecting git+https://github.com/fastai/fastai2\n",
            "  Cloning https://github.com/fastai/fastai2 to /tmp/pip-req-build-xqr0tee8\n",
            "  Running command git clone -q https://github.com/fastai/fastai2 /tmp/pip-req-build-xqr0tee8\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastai2==0.0.18 from git+https://github.com/fastai/fastai2 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.1.18)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.7.0a0+a6073f0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.2.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (7.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2==0.0.18) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2==0.0.18) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2==0.0.18) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.7.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (47.3.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->fastai2==0.0.18) (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (3.1.0)\n",
            "Building wheels for collected packages: fastai2\n",
            "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai2: filename=fastai2-0.0.18-cp36-none-any.whl size=193924 sha256=3813ed2532bd3d1ae0501054abfd5f124aa419918d7175260ab1489ee5f1a02f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-80zj4g80/wheels/a1/59/9a/50335b36924b827e29d5f40b41fc3a008cc1f30dd80e560dfd\n",
            "Successfully built fastai2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlAKa0RsbOei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0b2901c9-e740-44b9-9ff0-36fa316db567"
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('__call__', <function LevelMapper.__call__ at 0x7fa74cf6f8c8>), ('__init__', <function LevelMapper.__init__ at 0x7fa74cf6f840>)]\n",
            "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7fa74ceaf488>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7fa74ceaf400>)]\n",
            "[('__init__', <function BoxCoder.__init__ at 0x7fa74cebe8c8>), ('decode', <function BoxCoder.decode at 0x7fa74cebea60>), ('decode_single', <function BoxCoder.decode_single at 0x7fa74cebeae8>), ('encode', <function BoxCoder.encode at 0x7fa74cebe950>), ('encode_single', <function BoxCoder.encode_single at 0x7fa74cebe9d8>)]\n",
            "[('__call__', <function Matcher.__call__ at 0x7fa74cebe7b8>), ('__init__', <function Matcher.__init__ at 0x7fa74cebebf8>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7fa74cebe840>)]\n",
            "[('__init__', <function ImageList.__init__ at 0x7fa74cebed90>), ('to', <function ImageList.to at 0x7fa74cebed08>)]\n",
            "[('__init__', <function Timebase.__init__ at 0x7fa74cd99d08>)]\n",
            "[('__init__', <function VideoMetaData.__init__ at 0x7fa74cd99a60>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7QTq_ulNZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb7c2d5b-e378-4a7c-8a04-4e20eb56462b"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "path.ls()[2].ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/mnist_sample/train/7'),Path('/root/.fastai/data/mnist_sample/train/3')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wHQmbWTpm9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_my_labels(fname):\n",
        "    return int(fname.parent.name[0])\n",
        "\n",
        "dblock = DataBlock(\n",
        "    splitter = RandomSplitter(),\n",
        "    #item_tfms = Resize(128),\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y = get_my_labels\n",
        ")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq56ddzFZX-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82c0f73b-a978-4a57-be6a-d73bd5d6d20e"
      },
      "source": [
        "dls_normal = dblock.dataloaders(path)\n",
        "dls_normal.vocab"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [3,7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoJrJqx8BO30",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with convs and F.max_pool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfJVAsAerFku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "348ac0a2-a2b0-4dcf-c363-07e3277ebf02"
      },
      "source": [
        "class MyLenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLenet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.hiden4 = nn.Linear(400, 2) # 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.hiden4(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "lenet = MyLenet()\n",
        "learn = Learner(dls_normal, lenet, metrics=[error_rate, accuracy])\n",
        "\n",
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.096945</td>\n",
              "      <td>0.064774</td>\n",
              "      <td>0.021137</td>\n",
              "      <td>0.978863</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJpiJ4lr6WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "448ac8ad-be52-4688-efe8-0054a9ef29df"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.06477440148591995,0.02113652043044567,0.9788634777069092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YujM_GLxBW4_",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RETI5TWYyn6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "726ce077-a780-4b41-d87c-3d3a05d6c040"
      },
      "source": [
        "class Lenet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        print(f\"shapeeee {x.shape}\")\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "\n",
        "lenet2 = Lenet2()\n",
        "learn2 = Learner(dls_normal, lenet2, metrics=[error_rate, accuracy])\n",
        "\n",
        "learn2.fit_one_cycle(1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.066572</td>\n",
              "      <td>0.046531</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.985101</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "shapeeee torch.Size([6, 3, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hVwXWH0DW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "318fcb83-44d4-4314-bdb7-9d4c001ed5b0"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.06477440148591995,0.02113652043044567,0.9788634777069092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esGnoThVr5sm",
        "colab_type": "text"
      },
      "source": [
        "# conectarse a TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucdOzF7r6ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "b3eaab4c-5f2b-4f5e-9bc1-229e8007b42b"
      },
      "source": [
        "VERSION = \"20200325\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  22133      0 --:--:-- --:--:-- --:--:-- 22015\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Uninstalling torch-1.6.0a0+bf2bbd9:\n",
            "  Successfully uninstalled torch-1.6.0a0+bf2bbd9\n",
            "Uninstalling torchvision-0.7.0a0+a6073f0:\n",
            "  Successfully uninstalled torchvision-0.7.0a0+a6073f0\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "\u001b[31mERROR: fastai2 0.0.18 requires torchvision>=0.5, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Done updating TPU runtime\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+2b2085a\n",
            "    Uninstalling torch-xla-1.6+2b2085a:\n",
            "      Successfully uninstalled torch-xla-1.6+2b2085a\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zALipTPsKxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "class XLAOptFuncWrapper:\n",
        "    def __init__(self, f):\n",
        "        self.f = f\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        opt = self.f(*args, **kwargs)\n",
        "        optim_wrapper = OptimWrapper(opt)\n",
        "        def xla_step():\n",
        "            xm.optimizer_step(opt, barrier=True)\n",
        "        # monkeypatch optim_wrapper with xla_step\n",
        "        optim_wrapper.step = xla_step\n",
        "        return optim_wrapper"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1MkLSk4rGXa",
        "colab_type": "text"
      },
      "source": [
        "# Load in TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXckuzpuxvWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "61e97e80-6a74-4f16-b8bb-cab0243349d1"
      },
      "source": [
        "dblock.summary(path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_sample\n",
            "Found 14434 items\n",
            "2 datasets of sizes 11548,2886\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: get_my_labels -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/3/11010.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: get_my_labels -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/3/11010.png\n",
            "    applying get_my_labels gives\n",
            "      3\n",
            "    applying Categorize gives\n",
            "      TensorCategory(0)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(0))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(0))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(0))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([0, 1, 1, 0]))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([0, 1, 1, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9FuvQ7qrEqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e464d8f-74c8-4bb2-ae40-54e423f4debe"
      },
      "source": [
        "tpu_device = xm.xla_device()\n",
        "dls_tpu = dblock.dataloaders(path, device=tpu_device)\n",
        "dls_tpu.vocab"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [3,7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6edzLFvLxnTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_tpu.show([1])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFvkrNLuWH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_xla_opt = XLAOptFuncWrapper(SGD)\n",
        "adam_xla_opt = XLAOptFuncWrapper(Adam)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnNXHVhBukge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from fastai2.callback.all import *\n",
        "from fastai2.test_utils import *\n",
        "lenet_tpu = Lenet2()\n",
        "tpu_learner = Learner(dls_tpu, lenet_tpu, metrics=accuracy, \n",
        "                      loss_func=F.cross_entropy, opt_func=adam_xla_opt, cbs=VerboseCallback())"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npau0oogyXRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "2b1e2f36-110a-4615-faae-3a5570908e61"
      },
      "source": [
        "tpu_learner.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapeeee torch.Size([1, 3, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Lenet2 (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 120             48,120     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 84              10,164     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               170        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 59,502\n",
              "Total trainable params: 59,502\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <__main__.XLAOptFuncWrapper object at 0x7fa72ec3ca20>\n",
              "Loss function: <function cross_entropy at 0x7fa75be6ec80>\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - VerboseCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-exyB0zrk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "ee7e920b-157c-4288-9cdb-70736946991e"
      },
      "source": [
        "tpu_learner.show_training_loop()\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - begin_fit      : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "  Start Epoch Loop\n",
            "     - begin_epoch    : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - begin_train    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - begin_batch    : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - begin_validate : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [ProgressCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKrHpX9eu4S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2954e89e-a5e4-4252-f2d1-4954de3b52c4"
      },
      "source": [
        "tpu_learner.fit(1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.694571</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-ec3b9c172e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59-jZT0-vDcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99c6440a-afdd-4b1b-b852-c0dfae5a3c45"
      },
      "source": [
        "tpu_learner.lr_find()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "shapeeee torch.Size([64, 3, 28, 28])\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-6a1ad10370bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpu_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vector::_M_range_check: __n (which is 1) >= this->size() (which is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mno9PVMY1WoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94424284-945c-446b-9e8a-c15cff320b5d"
      },
      "source": [
        "dls_tpu.one_batch()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorImage([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              " \n",
              " \n",
              "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           ...,\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='xla:1'),\n",
              " TensorCategory([0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "         1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0], device='xla:1'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LSsf3k1pj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}