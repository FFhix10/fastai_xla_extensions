{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_test_TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMH3tgJW130D2XJ164tXEfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/RNN_test_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOXt0W3qS2xS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "acc26b96-804a-4349-b5dd-bd4a8a29394c"
      },
      "source": [
        "VERSION = \"20200707\" #\"nightly\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5115  100  5115    0     0  88189      0 --:--:-- --:--:-- --:--:-- 89736\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200707 ...\n",
            "Uninstalling torch-1.7.0a0+12b5bdc:\n",
            "  Successfully uninstalled torch-1.7.0a0+12b5bdc\n",
            "Uninstalling torchvision-0.8.0a0+86b6c3e:\n",
            "  Successfully uninstalled torchvision-0.8.0a0+86b6c3e\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][107.5 MiB/107.5 MiB]                                                \n",
            "Operation completed over 1 objects/107.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][123.8 MiB/123.8 MiB]                                                \n",
            "Operation completed over 1 objects/123.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.2 MiB/  2.2 MiB]                                                \n",
            "Operation completed over 1 objects/2.2 MiB.                                      \n",
            "Processing ./torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Done updating TPU runtime\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (1.18.5)\n",
            "\u001b[31mERROR: fastai2 0.0.21 requires torchvision>=0.7, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.0a0+12b5bdc\n",
            "Processing ./torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+5430aca\n",
            "    Uninstalling torch-xla-1.6+5430aca:\n",
            "      Successfully uninstalled torch-xla-1.6+5430aca\n",
            "Successfully installed torch-xla-1.6+5430aca\n",
            "Processing ./torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200707) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.0a0+86b6c3e\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHwGZXumIwMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "212ad0f4-9e71-410c-a9c5-54e47cd98386"
      },
      "source": [
        "!pip install https://github.com/butchland/fastai_xla_extensions/archive/master.zip\n",
        "import fastai_xla_extensions.core\n",
        "#XLA_AVAILABLE\n",
        "#!pip install fastai2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/butchland/fastai_xla_extensions/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/butchland/fastai_xla_extensions/archive/master.zip\n",
            "\u001b[K     / 11.3MB 4.1MB/s\n",
            "\u001b[?25hRequirement already satisfied: fastai2 in /usr/local/lib/python3.6/dist-packages (from fastai-xla-extensions==0.0.1) (0.0.21)\n",
            "Collecting nbdev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/e7/c71ab157a9c1fd530880b2adef8b0c77017ed5d9cbf3e15ab0abde8fb920/nbdev-0.2.20-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.2.4)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.8.0a0+86b6c3e)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.2.4)\n",
            "Requirement already satisfied: fastcore>=0.1.20 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.1.21)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.2.2)\n",
            "Collecting fastscript>=0.1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/ab/c7c4fdd6ae049e7f99341ed519fe46b837460cfe800edde2b9056c6c85b1/fastscript-0.1.5-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (20.4)\n",
            "Requirement already satisfied: nbconvert>=5.6.1 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.6.1)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.0.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->fastai2->fastai-xla-extensions==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai2->fastai-xla-extensions==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (49.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.1.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2->fastai-xla-extensions==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore>=0.1.20->fastai2->fastai-xla-extensions==0.0.1) (0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->nbdev->fastai-xla-extensions==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.11.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.6.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (3.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (2.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (1.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (3.1.0)\n",
            "Building wheels for collected packages: fastai-xla-extensions\n",
            "  Building wheel for fastai-xla-extensions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai-xla-extensions: filename=fastai_xla_extensions-0.0.1-cp36-none-any.whl size=10373 sha256=fc725fbae80b52bc224a430e5f0c293e3bce10a899b745227e8461db130de820\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ensoi6vn/wheels/51/0f/60/5f12ab7b94d39269cf077ca2678c20bbe97d4505fd82f81a04\n",
            "Successfully built fastai-xla-extensions\n",
            "Installing collected packages: fastscript, nbdev, fastai-xla-extensions\n",
            "Successfully installed fastai-xla-extensions-0.0.1 fastscript-0.1.5 nbdev-0.2.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq3MtOPVgqRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "dbbe4e90-273d-4575-fa14-969854b1c30c"
      },
      "source": [
        "!pip freeze | grep torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.7.0a0+12b5bdc\n",
            "torch-xla==1.6+5430aca\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.8.0a0+86b6c3e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4udp3ldiXB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "29f03c95-f67c-44d5-881c-1ff7b1f9e656"
      },
      "source": [
        "!pip freeze | grep fast"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai==1.0.61\n",
            "fastai-xla-extensions==0.0.1\n",
            "fastai2==0.0.21\n",
            "fastcore==0.1.21\n",
            "fastdtw==0.3.4\n",
            "fastprogress==0.2.4\n",
            "fastrlock==0.5\n",
            "fastscript==0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2U-EE2YW5vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install git+https://github.com/fastai/fastcore/archive/master.zip\n",
        "#!pip install git+https://github.com/fastai/fastai2\n",
        "#!pip install https://github.com/fastai/fastcore/archive/master.zip\n",
        "#!pip install https://github.com/fastai/fastai2/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDGd-CBSf0Oi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4efc84fe-9075-44c9-92fd-8aa45251eace"
      },
      "source": [
        "from fastai2.text.all import *\n",
        "default_device()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NSN8jKN_Jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class XLAOptimProxy:\n",
        "    def __init__(self,opt:Optimizer):\n",
        "        self.opt = opt\n",
        "\n",
        "    def xla_step(self):\n",
        "        xm.optimizer_step(self.opt,barrier=True) # sync on gradient update\n",
        "\n",
        "    def __getattr__(self,name):\n",
        "        if name == 'step': # override proxying for step method\n",
        "                return getattr(self,'xla_step')\n",
        "        # proxy everything else\n",
        "        return getattr(self.opt,name)\n",
        "@patch_to(Learner)\n",
        "def create_opt(self):\n",
        "        ooo = self.opt_func(self.splitter(self.model), lr=self.lr)\n",
        "        prox = XLAOptimProxy(ooo)\n",
        "        self.opt = prox\n",
        "        if not self.wd_bn_bias:\n",
        "            for p in self._bn_bias_state(True ): p['do_wd'] = False\n",
        "        if self.train_bn:\n",
        "            for p in self._bn_bias_state(False): p['force_train'] = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75n3w8rW9lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
        "        h = h + self.i_h(x[:,1])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgEp4MbIyQQe",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L9XQnUlW9iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "\n",
        "Path.BASE_PATH = path\n",
        "\n",
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "\n",
        "\n",
        "text = ' . '.join([l.strip() for l in lines])\n",
        "tokens = text.split(' ')\n",
        "tokens = text.split(' ')\n",
        "vocab = L(*tokens).unique()\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY62-jeyjR1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8872fff5-0be8-4fa6-e12e-e6737984ae64"
      },
      "source": [
        "default_device()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfILF0DQW9gQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "32a29530-c4ad-46fa-8136-a4b4826bcedd"
      },
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "d = default_device()\n",
        "print(f\"device is {d}\") # xm.xla_device()\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False, device=d, drop_last=True)\n",
        "dls.device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is xla:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_bB6uP6JTra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e34a366e-aab9-4b1b-f5ef-163959d00753"
      },
      "source": [
        "dls.device, default_device()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='xla', index=1), device(type='xla', index=1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkgqYI2OW9Z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "13feab45-c703-4f13-a34f-2b5d1254f936"
      },
      "source": [
        "%%time\n",
        "\n",
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-06a00064c308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nlearn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \\n                metrics=accuracy)\\nlearn.fit_one_cycle(1, 1e-3)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LMModel1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u52yN0dsUQ5y",
        "colab_type": "text"
      },
      "source": [
        "# Our first recurrent NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUK5nyq0W9V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S5Qf610W9Tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d2acb26-d2b6-4135-f5c9-304dacc9f9d6"
      },
      "source": [
        "dls.device"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LMTPydZUWzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "9e96e086-e5b5-427e-e0a2-5b1f1b1e90f8"
      },
      "source": [
        "%%time\n",
        "\n",
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.777648</td>\n",
              "      <td>1.765260</td>\n",
              "      <td>0.481816</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.23 s, sys: 703 ms, total: 4.94 s\n",
            "Wall time: 11.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjvBv3FHUh4t",
        "colab_type": "text"
      },
      "source": [
        "# Maintain state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T2qTk0CUakk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            w = self.h\n",
        "            w = tensor(w).to(default_device())\n",
        "            y = self.i_h(x[:,i])\n",
        "            if w.shape != y.shape:\n",
        "              print(f\"i={i} w={w.shape} y={y.shape}\")\n",
        "            self.h = w + y\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntFJQIsDUkG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "142bdc75-3548-447e-f1a5-a41c68761f21"
      },
      "source": [
        "%%time\n",
        "from fastai2.test_utils import VerboseCallback\n",
        "\n",
        "class CountBatches(Callback):\n",
        "  def begin_fit(self):\n",
        "    print(f\"begin_fit lenghts => {len(self.learn.dls.train)}, {len(self.learn.dls.valid)}\")\n",
        "  def begin_batch(self):\n",
        "    print(f\"b_b={self.learn.iter}\")\n",
        "    \n",
        "\n",
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                #metrics=None)\n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(1, 1e-3) #, cbs=[CountBatches(), VerboseCallback()])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.824986</td>\n",
              "      <td>1.787144</td>\n",
              "      <td>0.489423</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "CPU times: user 4.84 s, sys: 860 ms, total: 5.7 s\n",
            "Wall time: 13.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fWVvH7gUz7G",
        "colab_type": "text"
      },
      "source": [
        "# use ModelResetter Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS8aalodUm21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "45ecb86e-8767-4352-fbab-9f9620db4371"
      },
      "source": [
        "%%time\n",
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.906189</td>\n",
              "      <td>2.062968</td>\n",
              "      <td>0.464904</td>\n",
              "      <td>01:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.282850</td>\n",
              "      <td>1.831347</td>\n",
              "      <td>0.537981</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.074621</td>\n",
              "      <td>2.036061</td>\n",
              "      <td>0.529567</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.955263</td>\n",
              "      <td>1.737134</td>\n",
              "      <td>0.588221</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.888147</td>\n",
              "      <td>1.559431</td>\n",
              "      <td>0.608654</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.853906</td>\n",
              "      <td>1.491558</td>\n",
              "      <td>0.635817</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.821882</td>\n",
              "      <td>1.499270</td>\n",
              "      <td>0.644231</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.838244</td>\n",
              "      <td>1.307230</td>\n",
              "      <td>0.650240</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.848357</td>\n",
              "      <td>1.228000</td>\n",
              "      <td>0.653125</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.820257</td>\n",
              "      <td>1.232525</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "i=0 w=torch.Size([]) y=torch.Size([64, 64])\n",
            "CPU times: user 49.6 s, sys: 8.56 s, total: 58.1 s\n",
            "Wall time: 3min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvVfLgW2VAMM",
        "colab_type": "text"
      },
      "source": [
        "#Model4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DReTtlx4wwl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai_xla_extensions.core"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvAzXiBXw0LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.text.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anOxvxCKU52p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sl = 1 # TODO: this mismatch target and training size by a factor of `sl`\n",
        "\n",
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = tensor(0).to(default_device())\n",
        "        \n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(sl):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self): self.h = tensor(0).to(default_device())\n",
        "\n",
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9yqp97qxHcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1a72676-4685-4995-b2f0-54cd568cdf92"
      },
      "source": [
        "dls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai2.data.core.DataLoaders at 0x7f6dc21ed1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsEr00aQVCCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "5fcbf75e-61ba-49f2-b9d9-5c2033a68f19"
      },
      "source": [
        "%%time\n",
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(1, 3e-3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.145304</td>\n",
              "      <td>2.215637</td>\n",
              "      <td>0.310577</td>\n",
              "      <td>00:49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.29 s, sys: 1.11 s, total: 6.41 s\n",
            "Wall time: 49.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ5gPjnoWK-S",
        "colab_type": "text"
      },
      "source": [
        "# Model5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ACPCdkTyHLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai_xla_extensions.core\n",
        "from fastai2.text.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIa_hAZ8VKru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): self.h.zero_()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2JXLv7JWOMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "8cb3e8b6-1855-4749-aaba-ba221b4483a8"
      },
      "source": [
        "%%time\n",
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit(1, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/262 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76T902isWiIh",
        "colab_type": "text"
      },
      "source": [
        "# The above crashed my session with the following log:\n",
        "\n",
        "\n",
        "```\n",
        "Jul 31, 2020, 11:48:13 PM\tWARNING\tWARNING:root:kernel 3f9019c4-da8e-45f3-8546-44d6f18cb4f6 restarted\n",
        "Jul 31, 2020, 11:48:13 PM\tINFO\tKernelRestarter: restarting kernel (2/5), keep random ports\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tzmq.error.ZMQError: Address already in use\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"zmq/backend/cython/checkrc.pxd\", line 26, in zmq.backend.cython.checkrc._check_rc\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"zmq/backend/cython/socket.pyx\", line 550, in zmq.backend.cython.socket.Socket.bind\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\ts.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 181, in _bind_socket\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tself.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 239, in init_sockets\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tself.init_sockets()\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 469, in initialize\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\treturn method(app, *args, **kwargs)\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"<decorator-gen-121>\", line 2, in initialize\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tapp.initialize(argv)\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 663, in launch_instance\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tapp.launch_new_instance()\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\texec(code, run_globals)\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\t\"__main__\", mod_spec)\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tFile \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
        "Jul 31, 2020, 11:48:11 PM\tWARNING\tTraceback (most recent call last):\n",
        "Jul 31, 2020, 11:48:10 PM\tWARNING\tWARNING:root:kernel 3f9019c4-da8e-45f3-8546-44d6f18cb4f6 restarted\n",
        "Jul 31, 2020, 11:48:10 PM\tINFO\tKernelRestarter: restarting kernel (1/5), keep random ports\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\tcpu:0\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\t*** End stack trace ***\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttorch_xla::bridge::SetCurrentDevice(c10::Device const&)\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttorch_xla::bridge::AtenDeviceToXlaDevice(c10::Device const&)\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttensorflow::CurrentStackTrace[abi:cxx11]()\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\t*** Begin stack trace ***\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\twhat(): torch_xla/csrc/aten_xla_bridge.cpp:182 : Check failed: device.type() == at::kXLA (cpu vs. xla)\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\tterminate called after throwing an instance of 'std::runtime_error'\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\tcpu:0\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\t*** End stack trace ***\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttorch_xla::bridge::SetCurrentDevice(c10::Device const&)\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttorch_xla::bridge::AtenDeviceToXlaDevice(c10::Device const&)\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\ttensorflow::CurrentStackTrace[abi:cxx11]()\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\t*** Begin stack trace ***\n",
        "Jul 31, 2020, 11:48:08 PM\tWARNING\t2020-08-01 04:48:08.352531: E tensorflow/compiler/xla/xla_client/tf_logging.cc:11] Check failed: device.type() == at::kXLA (cpu vs. xla)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t(64, 64) and (64, 64)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t*** End stack trace ***\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyFunction_FastCallDict\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyFunction_FastCallDict\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyFunction_FastCallDict\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyFunction_FastCallDict\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyFunction_FastCallDict\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyNumber_Add\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyObject_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tPyCFunction_Call\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\tc10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, c10::Scalar), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, c10::Scalar> >, at::Tensor (at::Tensor const&, at::Tensor const&, c10::Scalar)>::call(c10::OperatorKernel*, at::Tensor const&, at::Tensor const&, c10::Scalar)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttorch_xla::AtenXlaType::add(at::Tensor const&, at::Tensor const&, c10::Scalar)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttorch_xla::XLATensor::add(torch_xla::XLATensor const&, torch_xla::XLATensor const&, c10::Scalar, c10::optional<c10::ScalarType>)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttorch_xla::ir::operator+(torch_xla::ir::Value const&, torch_xla::ir::Value const&)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttorch_xla::XlaHelpers::GetPromotedBinaryOpShape(xla::Shape const&, xla::Shape const&)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttorch_xla::XlaHelpers::GetPromotedShape(absl::lts_2020_02_25::Span<long long const>, absl::lts_2020_02_25::Span<long long const>)\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\ttensorflow::CurrentStackTrace[abi:cxx11]()\n",
        "Jul 31, 2020, 11:45:35 PM\tWARNING\t*** Begin stack trace ***\n",
        "Jul 31, 2020, 11:42:32 PM\tWARNING\t(64, 64) and (64, 64)\n",
        "Jul 31, 2020, 11:42:32 PM\tWARNING\t*** End stack trace ***\n",
        "Jul 31, 2020, 11:42:32 PM\tWARNING\t_PyEval_EvalFrameDefault\n",
        "Jul 31, 2020, 11:42:32 PM\tWARNING\tPyObject_Call\n",
        "\n",
        "```"
      ]
    }
  ]
}