{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explore_TPU_MNIST_Tiny_SGD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PuDt6tytOXvXck4ueBbNmsJD2fSUvFYJ",
      "authorship_tag": "ABX9TyODwl3+wJdz7Co/dZYhxgQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d84be679a9ff4e6e8ca00784250843d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2682324211ec43afb6bde92c791632c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a86faf8c5ee4cb9b286a0db82ddee27",
              "IPY_MODEL_18fcb9faad904f1584c4351436a967e6"
            ]
          }
        },
        "2682324211ec43afb6bde92c791632c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a86faf8c5ee4cb9b286a0db82ddee27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0362999bcc40408f88055b11df59d6ae",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8225532e46c43edabb3c36ee87cf403"
          }
        },
        "18fcb9faad904f1584c4351436a967e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b65e26a89414337acc55161712064e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [03:18&lt;00:00, 235kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba1a1b329c9f4a8f8782e9808af59a44"
          }
        },
        "0362999bcc40408f88055b11df59d6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8225532e46c43edabb3c36ee87cf403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b65e26a89414337acc55161712064e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba1a1b329c9f4a8f8782e9808af59a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/explore_nbs/Explore_TPU_MNIST_Tiny_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM703MEF1orN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c64dba9f-89d5-4429-a106-7c7a9f0397d3"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzDnzKRe2sp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9fDYfqv3Cj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hATs2eDr3RTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d011cac-f851-48bb-c85d-cc1d745cd921"
      },
      "source": [
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4139  100  4139    0     0  72614      0 --:--:-- --:--:-- --:--:-- 72614\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200325 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Uninstalling torch-1.5.1+cu101:\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (47.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.5.1+cu101\n",
            "Uninstalling torchvision-0.6.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
            "Operation completed over 1 objects/83.4 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+d6149a7\n",
            "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+e788e5b\n",
            "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (391 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNXNmzw3daU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai2 --upgrade > /dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy-t6zpR3gu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ce7f11e-72a5-4456-fd4b-6b9f783f5d4e"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/fastai_xla_extensions"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fastai_xla_extensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9icnTUa3076",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f4f947b-c305-4aff-8acb-3118bcfc9699"
      },
      "source": [
        "!pip install -e \".[dev]\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/fastai_xla_extensions\n",
            "\u001b[33m  WARNING: fastai-xla-extensions 0.0.1 does not provide the extra 'dev'\u001b[0m\n",
            "Requirement already satisfied: fastai2 in /usr/local/lib/python3.6/dist-packages (from fastai-xla-extensions==0.0.1) (0.0.17)\n",
            "Collecting nbdev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/54/f39f9050f0e1610c4c5f764872812ef72615dac70ea7f1c9bc20948acb04/nbdev-0.2.18-py3-none-any.whl (45kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.2.3)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.6.0a0+3c254fb)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (7.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (1.0.5)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (0.1.18)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->fastai-xla-extensions==0.0.1) (2.2.4)\n",
            "Collecting fastscript\n",
            "  Downloading https://files.pythonhosted.org/packages/55/0e/ecdc0213646bc82986884121109a38b50bbc2cd2c491bbbfdc7ae39228e3/fastscript-0.1.4-py3-none-any.whl\n",
            "Requirement already satisfied: nbconvert>=5.6.1 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (20.4)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev->fastai-xla-extensions==0.0.1) (5.0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2->fastai-xla-extensions==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2->fastai-xla-extensions==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2->fastai-xla-extensions==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5->fastai2->fastai-xla-extensions==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2->fastai-xla-extensions==0.0.1) (0.15.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->fastai-xla-extensions==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2->fastai-xla-extensions==0.0.1) (2018.9)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2->fastai-xla-extensions==0.0.1) (0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (47.3.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->fastai-xla-extensions==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (2.11.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.6.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (3.1.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev->fastai-xla-extensions==0.0.1) (2.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (1.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (0.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert>=5.6.1->nbdev->fastai-xla-extensions==0.0.1) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->fastai-xla-extensions==0.0.1) (3.1.0)\n",
            "Installing collected packages: fastscript, nbdev, fastai-xla-extensions\n",
            "  Running setup.py develop for fastai-xla-extensions\n",
            "Successfully installed fastai-xla-extensions fastscript-0.1.4 nbdev-0.2.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBMaggEHGbzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZzGjv7B5dJf",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpyaqUC5ibo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5aaUEx-5nNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mNGiOC5yKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai_xla_extensions.core import *"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4THQ3Hk056iJ",
        "colab_type": "text"
      },
      "source": [
        "### Setup data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMPe61C25_33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "19b803ed-d081-4433-97ee-9f57883283c8"
      },
      "source": [
        "path = untar_data(URLs.MNIST_TINY)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChXTdufM6MXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock = DataBlock(\n",
        "    blocks=(ImageBlock(cls=PILImageBW),CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(),\n",
        "    item_tfms=Resize(28),\n",
        "    batch_tfms=[]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6wBIWOB6WGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "f9a8c527-cc6b-43b3-bfd0-79ad6bfb9cb3"
      },
      "source": [
        "datablock.summary(path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_tiny\n",
            "Found 1428 items\n",
            "2 datasets of sizes 709,699\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_tiny/train/7/7644.png\n",
            "    applying PILBase.create gives\n",
            "      PILImageBW mode=L size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_tiny/train/7/7644.png\n",
            "    applying parent_label gives\n",
            "      7\n",
            "    applying Categorize gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "    applying Resize gives\n",
            "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImageBW of size 1x28x28, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWfuYAsw7AGZ",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbY91nOu7HFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu = xm.xla_device()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34YlwcCt7kcK",
        "colab_type": "text"
      },
      "source": [
        "### Setup DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyuC8el56a73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = datablock.dataloaders(path, device=tpu)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgz8KcJ6g7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "b6af965e-496d-4711-c787-7f17092702bd"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6UnAd4n7UZS",
        "colab_type": "text"
      },
      "source": [
        "### Create Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0qOorI67vLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = XLAOptFuncWrapper(SGD)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OQAeuRf6jgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "d84be679a9ff4e6e8ca00784250843d8",
            "2682324211ec43afb6bde92c791632c6",
            "7a86faf8c5ee4cb9b286a0db82ddee27",
            "18fcb9faad904f1584c4351436a967e6",
            "0362999bcc40408f88055b11df59d6ae",
            "d8225532e46c43edabb3c36ee87cf403",
            "1b65e26a89414337acc55161712064e9",
            "ba1a1b329c9f4a8f8782e9808af59a44"
          ]
        },
        "outputId": "c06399c1-54e0-4c1d-e464-3db738af4f6e"
      },
      "source": [
        "learner = cnn_learner(dls,resnet18,metrics=accuracy,opt_func=opt_func)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d84be679a9ff4e6e8ca00784250843d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbP18tG276-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "321fe2d0-f502-4b5c-9b83-66d42e4daea3"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 14 x 14    0          False     \n",
              "________________________________________________________________\n",
              "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Flatten              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 1024            2,048      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 512             524,288    True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 512             1,024      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               1,024      True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 11,704,896\n",
              "Total trainable params: 537,984\n",
              "Total non-trainable params: 11,166,912\n",
              "\n",
              "Optimizer used: <fastai_xla_extensions.core.XLAOptFuncWrapper object at 0x7f47896ea2b0>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model frozen up to parameter group number 2\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3g5czi8CF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "f3879fdd-fb21-473d-ccf9-39458a0fc65d"
      },
      "source": [
        "learner.fit(1,lr=1e-3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.204985</td>\n",
              "      <td>0.783838</td>\n",
              "      <td>0.472103</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otb9ibVk8Ii8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c66aa6fa-6bc4-49f5-a9d6-49e9b53e6502"
      },
      "source": [
        "learner.fit(100,lr=1e-3)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.164773</td>\n",
              "      <td>0.681727</td>\n",
              "      <td>0.596566</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.123665</td>\n",
              "      <td>0.635740</td>\n",
              "      <td>0.678112</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.072286</td>\n",
              "      <td>0.632413</td>\n",
              "      <td>0.646638</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.018789</td>\n",
              "      <td>0.602366</td>\n",
              "      <td>0.682403</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.980534</td>\n",
              "      <td>0.572350</td>\n",
              "      <td>0.698140</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.928412</td>\n",
              "      <td>0.544947</td>\n",
              "      <td>0.722461</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.882788</td>\n",
              "      <td>0.515706</td>\n",
              "      <td>0.755365</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.864587</td>\n",
              "      <td>0.492994</td>\n",
              "      <td>0.763949</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.827504</td>\n",
              "      <td>0.477547</td>\n",
              "      <td>0.772532</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.793454</td>\n",
              "      <td>0.455634</td>\n",
              "      <td>0.789700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.751708</td>\n",
              "      <td>0.444459</td>\n",
              "      <td>0.791130</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.736782</td>\n",
              "      <td>0.433631</td>\n",
              "      <td>0.808298</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.710238</td>\n",
              "      <td>0.413349</td>\n",
              "      <td>0.815451</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.682113</td>\n",
              "      <td>0.408958</td>\n",
              "      <td>0.812589</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.656808</td>\n",
              "      <td>0.394260</td>\n",
              "      <td>0.825465</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.629433</td>\n",
              "      <td>0.379468</td>\n",
              "      <td>0.834049</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.599368</td>\n",
              "      <td>0.369399</td>\n",
              "      <td>0.844063</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.588433</td>\n",
              "      <td>0.362759</td>\n",
              "      <td>0.849785</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.569059</td>\n",
              "      <td>0.356816</td>\n",
              "      <td>0.856938</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.552299</td>\n",
              "      <td>0.342540</td>\n",
              "      <td>0.854077</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.529413</td>\n",
              "      <td>0.337551</td>\n",
              "      <td>0.856938</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.511610</td>\n",
              "      <td>0.328124</td>\n",
              "      <td>0.862661</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.505315</td>\n",
              "      <td>0.323095</td>\n",
              "      <td>0.859800</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.489634</td>\n",
              "      <td>0.314257</td>\n",
              "      <td>0.868383</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.480884</td>\n",
              "      <td>0.302994</td>\n",
              "      <td>0.871245</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.471745</td>\n",
              "      <td>0.293188</td>\n",
              "      <td>0.875537</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.454339</td>\n",
              "      <td>0.283102</td>\n",
              "      <td>0.875537</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.442669</td>\n",
              "      <td>0.274601</td>\n",
              "      <td>0.885551</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.429145</td>\n",
              "      <td>0.270167</td>\n",
              "      <td>0.888412</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.423001</td>\n",
              "      <td>0.261142</td>\n",
              "      <td>0.886981</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.407226</td>\n",
              "      <td>0.256794</td>\n",
              "      <td>0.889843</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.389315</td>\n",
              "      <td>0.247083</td>\n",
              "      <td>0.901288</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.381957</td>\n",
              "      <td>0.244225</td>\n",
              "      <td>0.902718</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.370153</td>\n",
              "      <td>0.243611</td>\n",
              "      <td>0.904149</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.356497</td>\n",
              "      <td>0.239290</td>\n",
              "      <td>0.904149</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.355532</td>\n",
              "      <td>0.230218</td>\n",
              "      <td>0.908441</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.351062</td>\n",
              "      <td>0.227958</td>\n",
              "      <td>0.911302</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.336589</td>\n",
              "      <td>0.221159</td>\n",
              "      <td>0.914163</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.324830</td>\n",
              "      <td>0.218043</td>\n",
              "      <td>0.911302</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.321750</td>\n",
              "      <td>0.219541</td>\n",
              "      <td>0.908441</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.313898</td>\n",
              "      <td>0.216239</td>\n",
              "      <td>0.917024</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.304839</td>\n",
              "      <td>0.215981</td>\n",
              "      <td>0.912732</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.302341</td>\n",
              "      <td>0.208292</td>\n",
              "      <td>0.918455</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.298176</td>\n",
              "      <td>0.200812</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.288356</td>\n",
              "      <td>0.198518</td>\n",
              "      <td>0.924177</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.285304</td>\n",
              "      <td>0.200405</td>\n",
              "      <td>0.917024</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.275841</td>\n",
              "      <td>0.193308</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.280131</td>\n",
              "      <td>0.191629</td>\n",
              "      <td>0.922747</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.265897</td>\n",
              "      <td>0.187805</td>\n",
              "      <td>0.914163</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.255203</td>\n",
              "      <td>0.183880</td>\n",
              "      <td>0.925608</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.248140</td>\n",
              "      <td>0.182761</td>\n",
              "      <td>0.928469</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.249522</td>\n",
              "      <td>0.182339</td>\n",
              "      <td>0.931330</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.243824</td>\n",
              "      <td>0.177104</td>\n",
              "      <td>0.929900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.245820</td>\n",
              "      <td>0.180045</td>\n",
              "      <td>0.925608</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.244148</td>\n",
              "      <td>0.175641</td>\n",
              "      <td>0.929900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.235518</td>\n",
              "      <td>0.175357</td>\n",
              "      <td>0.927039</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.232816</td>\n",
              "      <td>0.171576</td>\n",
              "      <td>0.929900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.229802</td>\n",
              "      <td>0.171659</td>\n",
              "      <td>0.932761</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.220157</td>\n",
              "      <td>0.168458</td>\n",
              "      <td>0.935622</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.211709</td>\n",
              "      <td>0.162015</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.211804</td>\n",
              "      <td>0.158258</td>\n",
              "      <td>0.937053</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.204792</td>\n",
              "      <td>0.158123</td>\n",
              "      <td>0.942775</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.203354</td>\n",
              "      <td>0.157617</td>\n",
              "      <td>0.932761</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.198710</td>\n",
              "      <td>0.152619</td>\n",
              "      <td>0.938484</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.190786</td>\n",
              "      <td>0.156479</td>\n",
              "      <td>0.934192</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.191047</td>\n",
              "      <td>0.154170</td>\n",
              "      <td>0.939914</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.190990</td>\n",
              "      <td>0.153738</td>\n",
              "      <td>0.934192</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.184379</td>\n",
              "      <td>0.151348</td>\n",
              "      <td>0.938484</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.190403</td>\n",
              "      <td>0.146847</td>\n",
              "      <td>0.941345</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.187464</td>\n",
              "      <td>0.149692</td>\n",
              "      <td>0.942775</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.181990</td>\n",
              "      <td>0.147070</td>\n",
              "      <td>0.949928</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.175008</td>\n",
              "      <td>0.144042</td>\n",
              "      <td>0.945637</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.174971</td>\n",
              "      <td>0.143724</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.171217</td>\n",
              "      <td>0.140034</td>\n",
              "      <td>0.944206</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.172583</td>\n",
              "      <td>0.138106</td>\n",
              "      <td>0.951359</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.174690</td>\n",
              "      <td>0.139567</td>\n",
              "      <td>0.948498</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.169465</td>\n",
              "      <td>0.139004</td>\n",
              "      <td>0.947067</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.170293</td>\n",
              "      <td>0.133714</td>\n",
              "      <td>0.952790</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.164358</td>\n",
              "      <td>0.131656</td>\n",
              "      <td>0.952790</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.163591</td>\n",
              "      <td>0.132065</td>\n",
              "      <td>0.949928</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.162108</td>\n",
              "      <td>0.130891</td>\n",
              "      <td>0.952790</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.159129</td>\n",
              "      <td>0.131662</td>\n",
              "      <td>0.951359</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.156211</td>\n",
              "      <td>0.128954</td>\n",
              "      <td>0.954220</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.152108</td>\n",
              "      <td>0.124836</td>\n",
              "      <td>0.954220</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.146862</td>\n",
              "      <td>0.126803</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.145604</td>\n",
              "      <td>0.127061</td>\n",
              "      <td>0.949928</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.141843</td>\n",
              "      <td>0.123352</td>\n",
              "      <td>0.954220</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.138402</td>\n",
              "      <td>0.124616</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.133937</td>\n",
              "      <td>0.119206</td>\n",
              "      <td>0.954220</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.131821</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.128904</td>\n",
              "      <td>0.121630</td>\n",
              "      <td>0.958512</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.125589</td>\n",
              "      <td>0.123854</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.120686</td>\n",
              "      <td>0.123141</td>\n",
              "      <td>0.961373</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.120315</td>\n",
              "      <td>0.122267</td>\n",
              "      <td>0.959943</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.122109</td>\n",
              "      <td>0.118911</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.125432</td>\n",
              "      <td>0.118419</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.125856</td>\n",
              "      <td>0.117789</td>\n",
              "      <td>0.959943</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.122496</td>\n",
              "      <td>0.113786</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.124653</td>\n",
              "      <td>0.111835</td>\n",
              "      <td>0.955651</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.119973</td>\n",
              "      <td>0.117063</td>\n",
              "      <td>0.957082</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmmNsJqF9ujS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "75c86db1-fbbe-432e-9987-abeacb29f655"
      },
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpDqEdVw-tnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('100epoch-tpu')\n",
        "# not saving?"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIhW7ens-3pI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "327e6bf8-04db-4e23-ab8b-457a03f85dc3"
      },
      "source": [
        "!mkdir -p /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18\n",
        "!cp /content/data/mnist_tiny/models/100epoch-tpu.pth /content/drive/My\\ Drive/fastai_v4/models/mnist_tiny_resnet18/."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/data/mnist_tiny/models/100epoch-tpu.pth': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzXvY_zg_rJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72332f7f-bcfa-4a17-bfd9-e648c1f51494"
      },
      "source": [
        "!ls /root/.torch/models/*"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/root/.torch/models/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "974gZp_K_D1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = learner.model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HorfUfkg_3Si",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e064055-bbc2-4c03-82cb-5e8f47c899ec"
      },
      "source": [
        "dir(model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_backward_hooks',\n",
              " '_buffers',\n",
              " '_forward_hooks',\n",
              " '_forward_pre_hooks',\n",
              " '_get_item_by_idx',\n",
              " '_get_name',\n",
              " '_load_from_state_dict',\n",
              " '_load_state_dict_pre_hooks',\n",
              " '_modules',\n",
              " '_named_members',\n",
              " '_parameters',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_replicate_for_data_parallel',\n",
              " '_save_to_state_dict',\n",
              " '_slow_forward',\n",
              " '_state_dict_hooks',\n",
              " '_version',\n",
              " 'add_module',\n",
              " 'apply',\n",
              " 'bfloat16',\n",
              " 'buffers',\n",
              " 'children',\n",
              " 'cpu',\n",
              " 'cuda',\n",
              " 'double',\n",
              " 'dump_patches',\n",
              " 'eval',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'forward',\n",
              " 'half',\n",
              " 'has_children',\n",
              " 'load_state_dict',\n",
              " 'modules',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'parameters',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_parameter',\n",
              " 'requires_grad_',\n",
              " 'share_memory',\n",
              " 'state_dict',\n",
              " 'summary',\n",
              " 'to',\n",
              " 'train',\n",
              " 'training',\n",
              " 'type',\n",
              " 'zero_grad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iAkY9vABBzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = dls.one_batch()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGzlAmz4_5vw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf140ffe-26dd-4b5e-efd1-1a67c022c6f0"
      },
      "source": [
        "model.summary(xb)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 14 x 14    0          False     \n",
              "________________________________________________________________\n",
              "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Flatten              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 1024            2,048      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 512             524,288    True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 512             1,024      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               1,024      True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 11,704,896\n",
              "Total trainable params: 537,984\n",
              "Total non-trainable params: 11,166,912\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17XdJdDKABmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = model.state_dict()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZNM_58RB5Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdc5323e-0ffa-487e-fcf8-714ba4f62337"
      },
      "source": [
        "type(state)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CLhOXT2CM4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sk = state.keys()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2pp6RN_CZ_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = {'model': state, 'opt': learner.opt.state_dict()}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9cqupdxCcCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9eefbeec-0d1d-4c09-8c6a-759bc20ad310"
      },
      "source": [
        "learner.model_dir"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bRlko-sEf0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dfd7ae3-157e-4c4e-ea19-c9122c318753"
      },
      "source": [
        "dls.path"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwfxHn9CE38z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52415fd8-c368-4bc0-d253-0bf677b6c860"
      },
      "source": [
        "path"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/mnist_tiny')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0cHUQuZFE9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}