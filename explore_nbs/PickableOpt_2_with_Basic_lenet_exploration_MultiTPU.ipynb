{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "PickableOpt 2 with Basic_lenet_exploration_MultiTPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/fix_prev_lenet/explore_nbs/PickableOpt_2_with_Basic_lenet_exploration_MultiTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BmnUX_l8lQ6B"
      },
      "source": [
        "# Install fastai2 from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5DZXcBNJoy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "97cfdcb3-1cdf-4f80-d18f-e20693996cf4"
      },
      "source": [
        "!pip install -U pandas --upgrade\n",
        "!pip install -U fastcore --upgrade\n",
        "!pip install -U fastai --upgrade \n",
        "#!pip install -Uqq git+https://github.com/tyoc213/fastai_xla_extensions@fix_prev_lenet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already up-to-date: fastcore in /usr/local/lib/python3.6/dist-packages (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from fastcore) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastcore) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastcore) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastcore) (1.15.0)\n",
            "Requirement already up-to-date: fastai in /usr/local/lib/python3.6/dist-packages (2.0.10)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: fastcore>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8.0a0+86b6c3e)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GucdOzF7r6ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d35ae08a-b8ca-48ed-ebc3-504cfcd62e9a"
      },
      "source": [
        "VERSION = \"20200707\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5115  100  5115    0     0  33000      0 --:--:-- --:--:-- --:--:-- 33000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxoA3fJusV17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "20e3134b-a774-4b25-cc4e-86c2effeca08"
      },
      "source": [
        "#!TORCH_SHOW_CPP_STACKTRACES=1 python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "!python pytorch-xla-env-setup.py  --version $VERSION --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200707 ...\n",
            "Uninstalling torch-1.7.0a0+12b5bdc:\n",
            "  Successfully uninstalled torch-1.7.0a0+12b5bdc\n",
            "Uninstalling torchvision-0.8.0a0+86b6c3e:\n",
            "  Successfully uninstalled torchvision-0.8.0a0+86b6c3e\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][107.5 MiB/107.5 MiB]                                                \n",
            "Operation completed over 1 objects/107.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][123.8 MiB/123.8 MiB]                                                \n",
            "Operation completed over 1 objects/123.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.2 MiB/  2.2 MiB]                                                \n",
            "Operation completed over 1 objects/2.2 MiB.                                      \n",
            "Processing ./torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Done updating TPU runtime\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (1.18.5)\n",
            "\u001b[31mERROR: fastai 2.0.10 requires torchvision>=0.7, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.0a0+12b5bdc\n",
            "Processing ./torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+5430aca\n",
            "    Uninstalling torch-xla-1.6+5430aca:\n",
            "      Successfully uninstalled torch-xla-1.6+5430aca\n",
            "Successfully installed torch-xla-1.6+5430aca\n",
            "Processing ./torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200707) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.0a0+86b6c3e\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJMhjxPPaPo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fc14704f-7257-4967-bc72-fcdb55a867fa"
      },
      "source": [
        "!pip freeze | grep torch \n",
        "!pip freeze | grep fast"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.7.0a0+12b5bdc\n",
            "torch-xla==1.6+5430aca\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.8.0a0+86b6c3e\n",
            "fastai==2.0.10\n",
            "fastcore==1.0.9\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5vVQw3JM7yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import fastai_xla_extensions.core"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlAKa0RsbOei",
        "colab": {}
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHE_YF1_wHeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b27c40d7-7c86-475c-e7eb-a068236bcd92"
      },
      "source": [
        "default_device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OD7QTq_ulNZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ff2f046-cc14-47c9-9c34-da99a2f09fe0"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path; path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('labels.csv'),Path('valid'),Path('train')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZHPPO8I8RbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9295e7e-7a9f-4743-8342-c8361fb85847"
      },
      "source": [
        "(path/'train').ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('train/3'),Path('train/7')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obb_HBYU4wM0",
        "colab_type": "text"
      },
      "source": [
        "# multi TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqEIE9aA9ZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a28254a-5412-4894-c1f8-dba5413464bd"
      },
      "source": [
        "# Configures training (and evaluation) parameters\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from fastai.vision.all import *\n",
        "import time\n",
        "from fastai.test_utils import *\n",
        "print(f'torch version {torch.__version__}')\n",
        "\n",
        "import pdb\n",
        "\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path; path.ls()\n",
        "\n",
        "\n",
        "def debug_on(*exceptions):\n",
        "    if not exceptions:\n",
        "        exceptions = (AssertionError, )\n",
        "    def decorator(f):\n",
        "        @functools.wraps(f)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            try:\n",
        "                return f(*args, **kwargs)\n",
        "            except exceptions:\n",
        "                pdb.post_mortem(sys.exc_info()[2])\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "class Lenet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs instead of 10\n",
        "    @debug_on(KeyError)\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    @debug_on(KeyError)\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# third level patch... alll!!!!\n",
        "\n",
        "class _BaseOptimizer():\n",
        "    \"Common functionality between `Optimizer` and `OptimWrapper`\"\n",
        "    @debug_on(KeyError)\n",
        "    def __getattr__(self, name):\n",
        "      #print(f\"================= = = = = = ORIGINAL BASE OPTIMIZER {name}  = = = = = =================\")\n",
        "      return getattr(self, name)\n",
        "    @debug_on(KeyError)\n",
        "    def all_params(self, n=slice(None), with_grad=False):\n",
        "        #print(f\"================= = = = = = ORIGINAL BASE OPTIMIZER def all_params(self, n=slice(None), with_grad=False):  = = = = = =================\")\n",
        "        #print(f\"================= = = = = = {type(self)} {dir(self)}  = = = = = =================\")\n",
        "        #print(f\"================= = = = = = {type(self.param_groups)} {dir(self.param_groups)}  = = = = = =================\")\n",
        "        ###print(f\"================= = = = = = {self.param_groups}  = = = = = =================\")\n",
        "        # TODO: unroll this loop\n",
        "        res = L((p,pg,self.state[p],hyper) for pg,hyper in zip(self.param_lists[n],self.hypers[n]) for p in pg)        \n",
        "        \n",
        "        return L(o for o in res if o[0].grad is not None) if with_grad else res\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def _set_require_grad(self, rg, p,pg,state,h): p.requires_grad_(rg or state.get('force_train', False))\n",
        "    @debug_on(KeyError)\n",
        "    def freeze_to(self, n):\n",
        "        self.frozen_idx = n if n >= 0 else len(self.param_lists) + n\n",
        "        if self.frozen_idx >= len(self.param_lists):\n",
        "            warn(f\"Freezing {self.frozen_idx} groups; model has {len(self.param_lists)}; whole model is frozen.\")\n",
        "        for o in self.all_params(slice(n, None)): self._set_require_grad(True,  *o)\n",
        "        for o in self.all_params(slice(None, n)): self._set_require_grad(False, *o)\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def freeze(self):\n",
        "        assert(len(self.param_lists)>1)\n",
        "        self.freeze_to(-1)\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def set_freeze(self, n, rg, ignore_force_train=False):\n",
        "        for p in self.param_lists[n]: p.requires_grad_(rg or (state.get('force_train', False) and not ignore_force_train))\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def unfreeze(self): self.freeze_to(0)\n",
        "    @debug_on(KeyError)\n",
        "    def set_hypers(self, **kwargs): L(kwargs.items()).starmap(self.set_hyper)\n",
        "    @debug_on(KeyError)\n",
        "    def _set_hyper(self, k, v):\n",
        "        for v_,h in zip(v, self.hypers): h[k] = v_\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def set_hyper(self, k, v):\n",
        "        if isinstance(v, slice):\n",
        "            if v.start: v = even_mults(v.start, v.stop, len(self.param_lists))\n",
        "            else: v = [v.stop/10]*(len(self.param_lists)-1) + [v.stop]\n",
        "        v = L(v, use_list=None)\n",
        "        if len(v)==1: v = v*len(self.param_lists)\n",
        "        assert len(v) == len(self.hypers), f\"Trying to set {len(v)} values for {k} but there are {len(self.param_lists)} parameter groups.\"\n",
        "        self._set_hyper(k, v)\n",
        "\n",
        "    @property\n",
        "    def param_groups(self):\n",
        "      #print('%%%%%%%%%%%%%%%%%%%% P A R A M     G R O U P S %%%%%%%%%%%%%%%%%%%%')\n",
        "      return [{**{'params': pg}, **hp} for pg,hp in zip(self.param_lists, self.hypers)]\n",
        "    \n",
        "    @param_groups.setter\n",
        "    def param_groups(self, v):\n",
        "        #print('%%%%%%%%%%%%%%%%%%%% P A R A M     G R O U P S      S E T T E R %%%%%%%%%%%%%%%%%%%%')\n",
        "        for pg,v_ in zip(self.param_lists,v): pg = v_['params']\n",
        "        for hyper,v_ in zip(self.hypers,v):\n",
        "            for k,t in v_.items():\n",
        "                if k != 'params': hyper[k] = t\n",
        "    @debug_on(KeyError)\n",
        "    def __setstate__(self, d):\n",
        "      #print('%%%%%%%%%%%%%%%%%%%%****** ####### set state baseeeeee')\n",
        "      self.__dict__.update(d) # \n",
        "      #print('%%%%%%%%%%%%%%%%%%%%****** ####### set state ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "    @debug_on(KeyError)\n",
        "    def __getstate__(self):\n",
        "      #print('%%%%%%%%%%%%%%%%%%%%****** ####### get state baseeeeee')\n",
        "      d = dict(self.__dict__)\n",
        "      return d\n",
        "# Cell\n",
        "@debug_on(KeyError)\n",
        "def _update(state, new=None):\n",
        "    if new is None: return state\n",
        "    if isinstance(new, dict): state.update(new)\n",
        "    return state\n",
        "\n",
        "# Cell\n",
        "@log_args(but='params,cbs,defaults')\n",
        "class Optimizer(_BaseOptimizer):\n",
        "    \"Base optimizer class for the fastai library, updating `params` with `cbs`\"\n",
        "    _keep_on_clear = ['force_train', 'do_wd']\n",
        "    @debug_on(KeyError)\n",
        "    def __getattr__(self, name):\n",
        "      #print(f\"================= = = = = = BASE OPTIMIZER {name}  = = = = = =================\")\n",
        "      return getattr(self, name)\n",
        "    def __init__(self, params, cbs, train_bn=True, **defaults):\n",
        "        #print(f\"================= = = = = = OPTIMIZER(_BaseOptimizer)  = = = = = =================\\n\"*10)\n",
        "        params = L(params)\n",
        "        self.cbs,self.state,self.train_bn = L(cbs),defaultdict(dict),train_bn\n",
        "        defaults = merge(*self.cbs.attrgot('defaults'), defaults)\n",
        "        self.param_lists = L(L(p) for p in params) if isinstance(params[0], (L,list)) else L([params])\n",
        "        self.hypers = L({} for _ in range_of(self.param_lists))\n",
        "        self.set_hypers(**defaults)\n",
        "        self.frozen_idx = 0\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def zero_grad(self):\n",
        "        for p,*_ in self.all_params(with_grad=True):\n",
        "            p.grad.detach_()\n",
        "            p.grad.zero_()\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def step(self):\n",
        "        #print(f\"================= = = = = = BASE OPTIMIZER STEPPPPPPPPPPP P P P  P PP P P P P  = = = = = =================\")\n",
        "        for p,pg,state,hyper in self.all_params(with_grad=True):\n",
        "            for cb in self.cbs: state = _update(state, cb(p, **{**state, **hyper}))\n",
        "            self.state[p] = state\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def clear_state(self):\n",
        "        for p,pg,state,hyper in self.all_params():\n",
        "            self.state[p] = {k: state[k] for k in self._keep_on_clear if k in state}\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def state_dict(self):\n",
        "        state = [self.state[p] for p,*_ in self.all_params()]\n",
        "        return {'state': state, 'hypers': self.hypers}\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def load_state_dict(self, sd):\n",
        "        assert len(sd[\"hypers\"]) == len(self.param_lists)\n",
        "        assert len(sd[\"state\"])  == sum([len(pg) for pg in self.param_lists])\n",
        "        self.hypers = sd['hypers']\n",
        "        self.state = {p: s for p,s in zip(self.all_params().itemgot(0), sd['state'])}\n",
        "\n",
        "\n",
        "### second patch\n",
        "#@patch\n",
        "#def param_groups(self:Optimizer): return [{**{'params': pg}, **hp} for pg,hp in zip(self.param_lists, self.hypers)]\n",
        "#@patch\n",
        "#def param_groups(self:Optimizer, v):\n",
        "#        for pg,v_ in zip(self.param_lists,v): pg = v_['params']\n",
        "#        for hyper,v_ in zip(self.hypers,v):\n",
        "#            for k,t in v_.items():\n",
        "#                if k != 'params': hyper[k] = t\n",
        "\n",
        "\n",
        "\n",
        "# created to copy optimizer and have `__get_state__` and `__set_state__`\n",
        "@debug_on(KeyError)\n",
        "@patch\n",
        "def step(self:Optimizer):\n",
        "  #print(f'=========== * = ⁰ = * = * = step optimizer 0')\n",
        "  for p,pg,state,hyper in self.all_params(with_grad=True):\n",
        "    #print(f'=========== * = ⁰ = * = * = step optimizer 1')\n",
        "    for cb in self.cbs:\n",
        "      #print(f'=========== * = ⁰ = * = * = step optimizer INTERNAL')\n",
        "      state = _update(state, cb(p, **{**state, **hyper}))\n",
        "    #print(f'=========== * = ⁰ = * = * = step optimizer UPDATE')\n",
        "    self.state[p] = state\n",
        "    #print(f'=========== * = ⁰ = * = * = step optimizer ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD ENDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# the new thing!!!! a PiclableOptimizer that has __getstate__() and __setstate__() this last is not needed AFAIK\n",
        "\n",
        "class PickableOpt(Optimizer):\n",
        "  def __init__(self, opt):\n",
        "    #print('############## %%%%%%%%%%%%%%%%%%%%%%%%%%% deep copy from optimizer!!!!')\n",
        "    self.__dict__ = deepcopy(opt.__dict__)\n",
        "    self.opt = opt\n",
        "\n",
        "  def __getstate__(self):\n",
        "    #print('############## %%%%%%%%%%%%%%%%%%%%%%%%%%% PickableOpt#__getstate__!!! get state xla opt callback')\n",
        "    v = vars(self)\n",
        "#    v['param_groups'] = lambda x: return torch.zeros(7)\n",
        "    #print(f'vars type are: {type(v)}')\n",
        "    #print(f'vars type are: {len(v)}')\n",
        "    #print(f'vars type are: {v.keys()}')\n",
        "    #print(f'vars are: {v}')\n",
        "    #print(f'vars are: {v}')\n",
        "    v = self.state_dict()\n",
        "    v['param_groups'] = self.param_groups\n",
        "    return v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### first patch\n",
        "\n",
        "class XLAOptimProxy2:\n",
        "    \"Proxy optimizer to override `opt.step` with Pytorch XLA sync method `xm.optimizer_step` \"  \n",
        "    def __init__(self,opt, barrier=True):\n",
        "        #print(f\"================= = = = = = XLAOptimProxy2 = = = = = =================\")\n",
        "        self.opt = PickableOpt(opt)\n",
        "        self._barrier = barrier\n",
        "\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def xla_step(self):\n",
        "        #print('step....')\n",
        "        xm.optimizer_step(self.opt,barrier=self._barrier) # sync on gradient update\n",
        "\n",
        "    @debug_on(KeyError)        \n",
        "    def __getattr__(self,name):\n",
        "        #print('*** *** ***',name)\n",
        "#        print(f'***** ***** {name} {getattr(self.op, name, \"*** no lo tiene\")}')\n",
        "        if name == 'step': # override proxying for step\n",
        "            return getattr(self,'xla_step')\n",
        "        if name in ('barrier','_barrier'):\n",
        "            return getattr(self,name)\n",
        "      \n",
        "        # proxy everything else\n",
        "        return getattr(self.opt,name)\n",
        "\n",
        "    @property\n",
        "    def barrier(self): return self._barrier\n",
        "\n",
        "    @barrier.setter\n",
        "    def barrier(self,v): self._barrier = v\n",
        "  \n",
        "class XLAOptCallback2(Callback):\n",
        "    'Callback to replace `opt.step` with `xm.optimizer_step(opt)` as required to run on TPU'\n",
        "    def __init__(self, barrier=True):\n",
        "        self._barrier = barrier\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def before_fit(self):\n",
        "        'replace opt with proxy which calls `xm.optimizer_step` instead of `opt.step` and set `dls.device` and model to `xla_device`'\n",
        "        to_device(self.dls, device=xm.xla_device())\n",
        "        self.model.to(self.dls.device)\n",
        "        if self.learn.opt is not None:\n",
        "            if not isinstance(self.learn.opt,XLAOptimProxy2):\n",
        "                opt = self.learn.opt\n",
        "                self.learn.opt = XLAOptimProxy2(opt, barrier=self._barrier)\n",
        "\n",
        "    @debug_on(KeyError)\n",
        "    def after_fit(self):\n",
        "        'restore original opt '\n",
        "        if isinstance(self.learn.opt, XLAOptimProxy2):\n",
        "            opt = self.learn.opt.opt\n",
        "            self.learn.opt = opt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def map_fn(index, flags):\n",
        "  # from fastai.callback.all import *\n",
        "  dede = xm.xla_device()\n",
        "  print(f'index is {index} and flags are {flags}')\n",
        "  #xm.rendezvous('init')\n",
        "\n",
        "  if not xm.is_master_ordinal():\n",
        "    print(f\"this is {dede}:{index} entering download once\")\n",
        "    xm.rendezvous('download_only_once')\n",
        "    \n",
        "  dblock = DataBlock(\n",
        "    splitter = GrandparentSplitter(),\n",
        "    item_tfms = Resize(28),\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y = parent_label,\n",
        "    batch_tfms = []\n",
        "  )\n",
        "  if xm.is_master_ordinal():\n",
        "    xm.master_print(f'this is {dede} exiting download once')\n",
        "    xm.rendezvous('download_only_once')\n",
        "  xm.master_print('creating lenet_tpu')\n",
        "  lenet_tpu = Lenet2()\n",
        "  xm.master_print('lenet created, goiing for dls_tpu')\n",
        "  dls_tpu = dblock.dataloaders(path, device=dede)\n",
        "  xm.master_print(f'creating learner!!! for {dede}')\n",
        "  \n",
        "\n",
        "  tpu_learner = Learner(dls_tpu,\n",
        "                      lenet_tpu,\n",
        "                      metrics=accuracy, \n",
        "                      loss_func=F.cross_entropy,\n",
        "                      cbs=[])\n",
        "  print(f\"################ fit for {dede}\")\n",
        "  xm.master_print(f'***** fit for {dede}')\n",
        "  tpu_learner.fit(1, cbs=[XLAOptCallback2()])\n",
        "  xm.master_print(f'***** end fit for {dede}')\n",
        "  t = torch.randn((2, 2), device=dede)\n",
        "  print(\"################Process\", index ,\"is using\", xm.xla_real_devices([str(dede)])[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/9929970/682603\n",
        "# excepthook\n",
        "# \n",
        "import traceback\n",
        "import logging\n",
        "import os, sys\n",
        "\n",
        "def my_excepthook(excType, excValue, traceback, logger):\n",
        "    print(\"=== *** @@@ ### %%% === *** @@@ ### %%% === *** @@@ ### %%% === *** @@@ ### %%% === *** @@@ ### %%% === *** @@@ ### %%% Logging an uncaught exception\",\n",
        "                 exc_info=(excType, excValue, traceback))\n",
        "\n",
        "sys.excepthook = my_excepthook\n",
        "sys.unraisablehook = my_excepthook\n",
        "##############threading.excepthook\n",
        "#https://docs.python.org/3/library/sys.html#sys.excepthook\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('launching n procs')\n",
        "\n",
        "flags={}\n",
        "flags['batch_size'] = 32\n",
        "flags['num_workers'] = 8\n",
        "flags['num_epochs'] = 1\n",
        "flags['seed'] = 1234\n",
        "\n",
        "xmp.spawn(map_fn, args=(flags,), nprocs=8, start_method='fork')\n",
        "print('end of launch')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch version 1.7.0a0+12b5bdc\n",
            "launching n procs\n",
            "index is 0 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:1 exiting download once\n",
            "index is 5 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:5 entering download once\n",
            "index is 7 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:7 entering download once\n",
            "index is 6 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:6 entering download once\n",
            "index is 1 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:1 entering download once\n",
            "index is 3 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:3 entering download once\n",
            "index is 2 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:2 entering download once\n",
            "index is 4 and flags are {'batch_size': 32, 'num_workers': 8, 'num_epochs': 1, 'seed': 1234}\n",
            "this is xla:0:4 entering download once\n",
            "creating lenet_tpu\n",
            "lenet created, goiing for dls_tpu\n",
            "creating learner!!! for xla:1\n",
            "################ fit for xla:1\n",
            "################ fit for xla:0\n",
            "***** fit for xla:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699662</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699113</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################ fit for xla:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699263</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################ fit for xla:0\n",
            "################ fit for xla:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699774</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################ fit for xla:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699421</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699490</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################ fit for xla:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699018</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################ fit for xla:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.701533</td>\n",
              "      <td>0.699772</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>03:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "################Process 1 is using TPU:1\n",
            "***** end fit for xla:1\n",
            "################Process 0 is using TPU:0\n",
            "################Process 2 is using TPU:2\n",
            "################Process 4 is using TPU:4\n",
            "################Process 7 is using TPU:7\n",
            "################Process 3 is using TPU:3\n",
            "################Process 6 is using TPU:6\n",
            "################Process 5 is using TPU:5\n",
            "end of launch\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}