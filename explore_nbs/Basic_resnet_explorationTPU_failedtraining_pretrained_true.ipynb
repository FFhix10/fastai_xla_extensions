{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Basic_resnet_explorationTPU-failedtraining-pretrained-true.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/explore_nbs/Basic_resnet_explorationTPU_failedtraining_pretrained_true.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BmnUX_l8lQ6B"
      },
      "source": [
        "# Install fastai2 from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5DZXcBNJoy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2a72744f-175d-4bed-bfa7-7513ba8c389e"
      },
      "source": [
        "!pip install -Uqq fastcore --upgrade\n",
        "!pip install -Uqq fastai --upgrade \n",
        "!pip install -Uqq git+https://github.com/butchland/fastai_xla_extensions"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 3.3MB/s \n",
            "\u001b[?25h  Building wheel for fastai-xla-extensions (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GucdOzF7r6ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "05f45541-b138-4fc2-ef7b-432c7df202ea"
      },
      "source": [
        "VERSION = \"20200707\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5115  100  5115    0     0  32169      0 --:--:-- --:--:-- --:--:-- 32169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxoA3fJusV17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ebb13df-569d-4b5c-c111-2d8657fae916"
      },
      "source": [
        "#!TORCH_SHOW_CPP_STACKTRACES=1 python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "!python pytorch-xla-env-setup.py  --version $VERSION --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200707 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (49.6.0)\n",
            "Uninstalling torch-1.6.0+cu101:\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.6.0+cu101\n",
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][107.5 MiB/107.5 MiB]                                                \n",
            "Operation completed over 1 objects/107.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][123.8 MiB/123.8 MiB]                                                \n",
            "Operation completed over 1 objects/123.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.2 MiB/  2.2 MiB]                                                \n",
            "Operation completed over 1 objects/2.2 MiB.                                      \n",
            "Processing ./torch-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200707) (1.18.5)\n",
            "\u001b[31mERROR: fastai 2.0.0 requires torchvision>=0.7, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.0a0+12b5bdc\n",
            "Processing ./torch_xla-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+5430aca\n",
            "Processing ./torchvision-nightly+20200707-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.7.0a0+12b5bdc)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200707) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200707) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.8.0a0+86b6c3e\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (393 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJMhjxPPaPo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e8c617ea-92fd-4134-ba8c-8a0e4a5263c5"
      },
      "source": [
        "!pip freeze | grep torch \n",
        "!pip freeze | grep fastcore\n",
        "!pip freeze | grep fastai"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.7.0a0+12b5bdc\n",
            "torch-xla==1.6+5430aca\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.8.0a0+86b6c3e\n",
            "fastcore==1.0.0\n",
            "fastai==2.0.0\n",
            "fastai-xla-extensions==0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5vVQw3JM7yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai_xla_extensions.core"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlAKa0RsbOei",
        "colab": {}
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP0SuTY0xBrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai_xla_extensions.core import default_device, to_device"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OD7QTq_ulNZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70b367d8-37f9-4ca1-9755-4bb90be6bc7f"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path; path.ls()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('valid'),Path('train'),Path('labels.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p1MkLSk4rGXa"
      },
      "source": [
        "# Load in TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGGltCFpN0Gs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEERTzNRN5qh",
        "colab": {}
      },
      "source": [
        "dblock = DataBlock(\n",
        "    splitter = GrandparentSplitter(),\n",
        "    item_tfms = Resize(28),\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y = parent_label,\n",
        "    batch_tfms = []\n",
        ")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H9FuvQ7qrEqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a327d2a1-ce91-4ae9-daba-a75f15f4ac2b"
      },
      "source": [
        "dls_tpu = dblock.dataloaders(path, device=default_device())\n",
        "dls_tpu.device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6V8S-tq40vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu_learner = cnn_learner(dls_tpu, resnet18, pretrained=True, metrics=accuracy)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "npau0oogyXRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96ae7461-b396-4a8f-ec06-aa22052373b8"
      },
      "source": [
        "tpu_learner.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 14 x 14    0          False     \n",
              "________________________________________________________________\n",
              "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 64 x 7 x 7      0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 128 x 4 x 4     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 256 x 2 x 2     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
              "________________________________________________________________\n",
              "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
              "________________________________________________________________\n",
              "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
              "________________________________________________________________\n",
              "Flatten              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 1024            2,048      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 1024            0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 512             524,288    True      \n",
              "________________________________________________________________\n",
              "ReLU                 64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "BatchNorm1d          64 x 512             1,024      True      \n",
              "________________________________________________________________\n",
              "Dropout              64 x 512             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               1,024      True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 11,704,896\n",
              "Total trainable params: 537,984\n",
              "Total non-trainable params: 11,166,912\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f1865955ae8>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model frozen up to parameter group #2\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - XLAOptCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Z-exyB0zrk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "6169cf82-8751-4135-cee6-362455dfaf84"
      },
      "source": [
        "tpu_learner.show_training_loop()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - before_fit     : [TrainEvalCallback, XLAOptCallback, Recorder, ProgressCallback]\n",
            "  Start Epoch Loop\n",
            "     - before_epoch   : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - before_batch   : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - before_backward: []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [XLAOptCallback, ProgressCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f_vRFNZts9GB"
      },
      "source": [
        "# Call fit\n",
        "\n",
        "Will fail in `self.loss.backward(); `?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKrHpX9eu4S_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "25e13710-8517-42eb-f7a4-0510cd461a3e"
      },
      "source": [
        "tpu_learner.fit(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.137379</td>\n",
              "      <td>0.833501</td>\n",
              "      <td>0.585868</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "59-jZT0-vDcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d012126f-b695-4005-cef7-b8b239613be6"
      },
      "source": [
        "tpu_learner.recorder.plot_loss()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uei-_fSpP2VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu_learner.unfreeze()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4afo3XOZzFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "15e62ab6-bb60-45e9-90ce-422dbbd2dbef"
      },
      "source": [
        "%%time\n",
        "tpu_learner.fit_one_cycle(1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.121667</td>\n",
              "      <td>0.840853</td>\n",
              "      <td>0.580962</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.11 s, sys: 876 ms, total: 7.99 s\n",
            "Wall time: 23.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chSdvdcZQGqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b84dd81f-9be3-4b2b-c978-1a97f0c64bf7"
      },
      "source": [
        "tpu_learner.fit_one_cycle(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.119356</td>\n",
              "      <td>0.845768</td>\n",
              "      <td>0.577036</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.108155</td>\n",
              "      <td>0.823684</td>\n",
              "      <td>0.582434</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.143584</td>\n",
              "      <td>0.835649</td>\n",
              "      <td>0.589303</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.112138</td>\n",
              "      <td>0.856550</td>\n",
              "      <td>0.574583</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.103486</td>\n",
              "      <td>0.843878</td>\n",
              "      <td>0.578999</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.108675</td>\n",
              "      <td>0.857935</td>\n",
              "      <td>0.571148</td>\n",
              "      <td>00:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.139158</td>\n",
              "      <td>0.836596</td>\n",
              "      <td>0.580962</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.126376</td>\n",
              "      <td>0.846665</td>\n",
              "      <td>0.583415</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.141315</td>\n",
              "      <td>0.837974</td>\n",
              "      <td>0.578508</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.119917</td>\n",
              "      <td>0.826240</td>\n",
              "      <td>0.581943</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0U9lv0gNX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeviceCheckCallback(Callback):\n",
        "    \n",
        "    def after_pred(self):\n",
        "        print(f'xb device: {first(self.learn.xb).device}')\n",
        "        print(f'model device: {one_param(self.learn.model).device}')\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vv__tRKAyqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d133cc20-e86f-41cd-d6ab-87cab8403d7c"
      },
      "source": [
        "tpu_learner.fit_one_cycle(1, cbs=[DeviceCheckCallback()])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.019918</td>\n",
              "      <td>0.005847</td>\n",
              "      <td>0.998037</td>\n",
              "      <td>00:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n",
            "xb device: xla:1\n",
            "model device: xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqEIE9aA9ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}