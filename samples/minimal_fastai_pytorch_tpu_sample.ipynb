{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "minimal-fastai-pytorch-tpu-sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e5cd68ea074e48890d9b14881d82af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bacbd62dae04ebb9b5d949870a199ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45c0ed0825c24d12813fc96c75eb3120",
              "IPY_MODEL_ef5fe4236f0e461cb71c4edf0e77c4f1"
            ]
          }
        },
        "7bacbd62dae04ebb9b5d949870a199ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45c0ed0825c24d12813fc96c75eb3120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03e0235291ef4af0a926e03f02ee9385",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cca159081b154c84a2d0a9746314cd4a"
          }
        },
        "ef5fe4236f0e461cb71c4edf0e77c4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dafa4154890a465180de1610289c1f9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:41&lt;00:00, 4103432.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e42b952d048a49489196d5e04e523886"
          }
        },
        "03e0235291ef4af0a926e03f02ee9385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cca159081b154c84a2d0a9746314cd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dafa4154890a465180de1610289c1f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e42b952d048a49489196d5e04e523886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/minimal_fastai_pytorch_tpu_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ZrLFo_ay71"
      },
      "source": [
        "# Minimal fastai torch tpu training example\n",
        "\n",
        "> Train models using plain pytorch models, datasets and dataloaders using the fastai training loop on TPUs.\n",
        "\n",
        "Using pytorch datasets and dataloaders, we train plain pytorch models using fastai's training loop on TPUs using `torch-xla` and the `fastai_xla_extensions` package.\n",
        "\n",
        "Inspired by Zach Mueller's minimal fastai example\n",
        "from the [fastai-minima package](https://pypi.org/project/fastai-minima/) and [Pytorchtofastai blog post](https://muellerzr.github.io/fastblog/2021/02/14/Pytorchtofastai.html) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YDh4iGsaY8L"
      },
      "source": [
        "Assumptions:\n",
        " * python 3.7 install (Google Colab default)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwTOM4iacHI5"
      },
      "source": [
        "## Installation and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElSIfo9DcHBa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5a94zblabdT"
      },
      "source": [
        "Install torch 1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2g1lEnkOXg5",
        "outputId": "1523c5cd-ecde-46ab-d992-66ef14bc9587"
      },
      "source": [
        "!pip install -qqq --no-cache-dir torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchtext==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 735.4MB 1.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.8MB 20.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.0MB 6.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-13iUm5bK2v"
      },
      "source": [
        "Install torch-xla 1.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53lrJMDn9Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6620ce-daa9-4eb4-842e-93e123178397"
      },
      "source": [
        "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133.6MB 28kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.7MB/s \n",
            "\u001b[31mERROR: earthengine-api 0.1.254 has requirement google-api-python-client>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeiNT5NsbQM0"
      },
      "source": [
        "Install fastai  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5brhMy3uzfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1dcdf3-cb6b-4793-b318-7257e6566fc9"
      },
      "source": [
        "!pip install -Uqq fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 6.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 5.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE_jBC6cbXTm"
      },
      "source": [
        "Install fastai_xla_extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrVR2QGNFj9-"
      },
      "source": [
        "!pip install -Uqq fastai_xla_extensions\n",
        "# !pip install -Uqq git+https://github.com/butchland/fastai_xla_extensions.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ureS9yUvbdiq"
      },
      "source": [
        "(Optional) Link fastai data and model dirs to content dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-maBHnlmDPVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d3803f-3a53-42ca-863e-084801e9cb79"
      },
      "source": [
        "!curl -s https://course19.fast.ai/setup/colab | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjjpMkDQbspu"
      },
      "source": [
        "Document package versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLJEMVZFS2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb6071d-3feb-46d9-cec9-9aa27ec3c121"
      },
      "source": [
        "!pip freeze | grep torch\n",
        "!pip freeze | grep fast"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.7.1+cu101\n",
            "torch-xla==1.7\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.8.0\n",
            "torchvision==0.8.2+cu101\n",
            "fastai==2.2.7\n",
            "fastai-xla-extensions==0.0.11\n",
            "fastcore==1.3.19\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC6tkQ3abzWU"
      },
      "source": [
        "## Model Training\n",
        "\n",
        "Import `fastai` and `fastai_xla_extensions` packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBSZSW_rcojV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30529c17-9c98-4535-977a-b1e5707590b6"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai_xla_extensions.all import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osgVf37JXD-v"
      },
      "source": [
        "Use plain pytorch datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZjfh3YAfZFC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "a4e5cd68ea074e48890d9b14881d82af",
            "7bacbd62dae04ebb9b5d949870a199ef",
            "45c0ed0825c24d12813fc96c75eb3120",
            "ef5fe4236f0e461cb71c4edf0e77c4f1",
            "03e0235291ef4af0a926e03f02ee9385",
            "cca159081b154c84a2d0a9746314cd4a",
            "dafa4154890a465180de1610289c1f9a",
            "e42b952d048a49489196d5e04e523886"
          ]
        },
        "outputId": "30b11457-f6d7-4fea-a7fb-823fb71cac4a"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "norm = transforms.Normalize(\n",
        "    mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     norm])\n",
        "\n",
        "dset_train = torchvision.datasets.CIFAR10(root='/content/data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "dset_test = torchvision.datasets.CIFAR10(root='/content/data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=64,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "testloader = torch.utils.data.DataLoader(dset_test, batch_size=64,\n",
        "                                         shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e5cd68ea074e48890d9b14881d82af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /content/data/cifar-10-python.tar.gz to /content/data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIyEaohiXOyc"
      },
      "source": [
        "Use plain pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJOcMZaQfZFD"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T8bZRlCXVID"
      },
      "source": [
        "Use plain pytorch loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSjlUupFfZFE"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4o7n9V8XlXl"
      },
      "source": [
        "Comment out fastai-minima code, as this example relies on fastai code directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_BtPmnmfZFE"
      },
      "source": [
        "# from torch import optim\n",
        "# from fastai_minima.optimizer import OptimWrapper\n",
        "# # from fastai_minima.learner import Learner, DataLoaders\n",
        "# from fastai_minima.callback.training import CudaCallback, ProgressCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61NclRy6X49p"
      },
      "source": [
        "Wrap the pytorch SGD optimizer with fastai's `OptimWrapper`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qie8oiIEolor"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "def opt_func(params, **kwargs): \n",
        "    return OptimWrapper(optim.SGD(params, **kwargs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC5ZhWCMYrbg"
      },
      "source": [
        "Wrap the pytorch train and test dataloaders with fastai's `DataLoaders` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzQEYsmCXgL_"
      },
      "source": [
        "dls = DataLoaders(trainloader, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN45xLT2Y4F1"
      },
      "source": [
        "Create a fastai `Learner` which ties together the dataloaders, model, loss function and optimizer.\n",
        "\n",
        "Also add in a fastai metrics function to monitor performance during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGbj_MDAfZFF"
      },
      "source": [
        "learn = Learner(dls, Net(), loss_func=criterion, opt_func=opt_func, metrics=accuracy)\n",
        "\n",
        "# To use the GPU, do \n",
        "# learn = Learner(dls, Net(), loss_func=criterion, opt_func=opt_func, cbs=[CudaCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H4qKdjQZV9c"
      },
      "source": [
        "You can use the fastai_xla_extensions `xla_` functions to train it on the TPU (by default it uses 8 TPU cores for multi tpu training).\n",
        "\n",
        "Notice the number of batches per epoch is divided by 8 (as the batches shown are per TPU core). \n",
        "\n",
        "Instead of using the fastai's plain `fit` method, we opt to use `fit_one_cycle` for cyclic training, which improves convergence by varying the learning rate during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmGk76FfZFF"
      },
      "source": [
        "# learn.fit(2, lr=0.001)\n",
        "# learn.xla_fit(20, lr=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krf8PAd9aR5x"
      },
      "source": [
        "We also include fastai's `SaveModelCallback` which will save the best performing model during training.\n",
        "\n",
        "Note that the `SaveModelCallback` is set to run only on the master ordinal process because running save model callback will overwrite each other if run on multiple processes at the same time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OuliXss4qT7Y",
        "outputId": "dd874ac4-56b7-46fb-e244-7b5c9d7d5335"
      },
      "source": [
        "# learn.fit(2, lr=0.001)\n",
        "learn.xla_fit_one_cycle(20, lr_max=slice(2e-1), master_cbs=[SaveModelCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.784843</td>\n",
              "      <td>1.803286</td>\n",
              "      <td>0.352800</td>\n",
              "      <td>00:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.613264</td>\n",
              "      <td>1.449180</td>\n",
              "      <td>0.472100</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.471380</td>\n",
              "      <td>1.459623</td>\n",
              "      <td>0.482100</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.423505</td>\n",
              "      <td>1.418017</td>\n",
              "      <td>0.499400</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.318982</td>\n",
              "      <td>1.364406</td>\n",
              "      <td>0.517600</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.241266</td>\n",
              "      <td>1.247894</td>\n",
              "      <td>0.570100</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.168899</td>\n",
              "      <td>1.252408</td>\n",
              "      <td>0.570700</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.102138</td>\n",
              "      <td>1.207525</td>\n",
              "      <td>0.590500</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.065755</td>\n",
              "      <td>1.229783</td>\n",
              "      <td>0.587500</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.033118</td>\n",
              "      <td>1.192548</td>\n",
              "      <td>0.595700</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.973906</td>\n",
              "      <td>1.171590</td>\n",
              "      <td>0.611300</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.910888</td>\n",
              "      <td>1.231431</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.862316</td>\n",
              "      <td>1.205836</td>\n",
              "      <td>0.610800</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.803260</td>\n",
              "      <td>1.203483</td>\n",
              "      <td>0.613600</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.721708</td>\n",
              "      <td>1.278981</td>\n",
              "      <td>0.617300</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.636913</td>\n",
              "      <td>1.290403</td>\n",
              "      <td>0.618900</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.558345</td>\n",
              "      <td>1.363473</td>\n",
              "      <td>0.631100</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.461113</td>\n",
              "      <td>1.420826</td>\n",
              "      <td>0.624600</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.394418</td>\n",
              "      <td>1.489249</td>\n",
              "      <td>0.627100</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.358670</td>\n",
              "      <td>1.499850</td>\n",
              "      <td>0.628300</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Better model found at epoch 0 with valid_loss value: 1.8032864332199097.\n",
            "Better model found at epoch 1 with valid_loss value: 1.4491798877716064.\n",
            "Better model found at epoch 3 with valid_loss value: 1.4180173873901367.\n",
            "Better model found at epoch 4 with valid_loss value: 1.3644063472747803.\n",
            "Better model found at epoch 5 with valid_loss value: 1.247894287109375.\n",
            "Better model found at epoch 7 with valid_loss value: 1.2075252532958984.\n",
            "Better model found at epoch 9 with valid_loss value: 1.192548155784607.\n",
            "Better model found at epoch 10 with valid_loss value: 1.1715904474258423.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVFhk9Y_a-nv"
      },
      "source": [
        "## Model Checkpointing and Performance Evaluation\n",
        "\n",
        "We can check that the best performing model has been saved to the learner by comparing the best performing model (stored in `model.pth` by the `SaveModelCallback`) is also the one loaded in the learner even though it is not the last one made during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OIYqa5Zztz1j",
        "outputId": "2d9c19ca-7772-4bc1-bc19-2d795164a32d"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [1.171569585800171,0.6114000082015991]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byi8vKNVxq-X",
        "outputId": "4c25d62c-7023-4643-a0bc-e3459679176f"
      },
      "source": [
        "learn.save('stage-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/stage-1.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwRIuQTvxwRj",
        "outputId": "b8700072-268a-4b33-e8c3-346427732629"
      },
      "source": [
        "learn.load('model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/learner.py:56: UserWarning: Saved filed doesn't contain an optimizer state.\n",
            "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f6a7895ba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR7vrA-MbeDu"
      },
      "source": [
        "The validation performance of the best model should be the same as the validation performance of the model after training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bcdB02MZxzH7",
        "outputId": "5ba28c04-410f-4b4e-9373-1717005c83dd"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [1.171569585800171,0.6114000082015991]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsVJPKtRx10Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}