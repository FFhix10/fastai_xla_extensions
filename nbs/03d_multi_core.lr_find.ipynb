{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# attach gdrive holding repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core.lr_find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Core LR Find XLA Extensions\n",
    "\n",
    "> Classes to replace LRFinder and patches to Learner\n",
    "to support running lr_find using multi core TPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifications to existing callback `LRFinder` are needed in order to run `lr_find` using multiple TPU cores. An equivalent `xla_lr_find` method is patched to `Learner` so it can run on multiple TPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 6.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 3.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/butchland/fastai_xla_extensions.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/butchland/my_timesaver_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5116  100  5116    0     0  39658      0 --:--:-- --:--:-- --:--:-- 39658\n",
      "Updating... This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-nightly ...\n",
      "Collecting cloud-tpu-client\n",
      "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
      "Collecting google-api-python-client==1.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (1.15.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (4.7.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.27.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (53.0.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
      "Uninstalling torch-1.7.0+cu101:\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
      "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
      "  Found existing installation: google-api-python-client 1.7.12\n",
      "    Uninstalling google-api-python-client-1.7.12:\n",
      "      Successfully uninstalled google-api-python-client-1.7.12\n",
      "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
      "Done updating TPU runtime\n",
      "  Successfully uninstalled torch-1.7.0+cu101\n",
      "Uninstalling torchvision-0.8.1+cu101:\n",
      "  Successfully uninstalled torchvision-0.8.1+cu101\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp37-cp37m-linux_x86_64.whl...\n",
      "- [1 files][122.6 MiB/122.6 MiB]                                                \n",
      "Operation completed over 1 objects/122.6 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\n",
      "|\n",
      "Operation completed over 1 objects/132.6 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\n",
      "/ [1 files][  4.5 MiB/  4.5 MiB]                                                \n",
      "Operation completed over 1 objects/4.5 MiB.                                      \n",
      "Processing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==nightly) (3.7.4.3)\n",
      "\u001b[31mERROR: fastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 2.2.7 has requirement torch<1.8,>=1.7.0, but you'll have torch 1.9.0a0+958d9a8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.9.0a0+958d9a8\n",
      "Processing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: torch-xla\n",
      "Successfully installed torch-xla-1.9+7671584\n",
      "Processing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly) (7.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly) (1.9.0a0+958d9a8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly) (3.7.4.3)\n",
      "\u001b[31mERROR: fastai 2.2.7 has requirement torch<1.8,>=1.7.0, but you'll have torch 1.9.0a0+958d9a8 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 2.2.7 has requirement torchvision<0.9,>=0.8, but you'll have torchvision 0.9.0a0+fc33c46 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.9.0a0+fc33c46\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libomp5\n",
      "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
      "Need to get 234 kB of archives.\n",
      "After this operation, 774 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
      "Fetched 234 kB in 1s (334 kB/s)\n",
      "Selecting previously unselected package libomp5:amd64.\n",
      "(Reading database ... 149414 files and directories currently installed.)\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl\n",
    "VERSION = \"nightly\"  #@param [\"1.5\", \"1.7\" , \"20200325\", \"nightly\"]\n",
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content\n",
    "!ln -s /content/drive/MyDrive/fastai_xla_extensions fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.9.0a0+958d9a8\n",
      "torch-xla==1.9+7671584\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.9.0a0+fc33c46\n",
      "fastai==2.2.7\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrelease==0.1.11\n",
      "fastrlock==0.5\n",
      "nbdev==1.1.13\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep timesaver\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# start of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastai_xla_extensions.utils import xla_imported\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "from fastai_xla_extensions.multi_core.callback import *\n",
    "from fastai_xla_extensions.multi_core.learner import *\n",
    "from fastai_xla_extensions.misc_utils import *\n",
    "from fastai_xla_extensions.core import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "try:\n",
    "    import torch_xla\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "if xla_imported():\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#local\n",
    "# fake out torch_xla modules if not running on xla supported envs\n",
    "if not xla_imported():\n",
    "    # replace torch xla modules with fake equivalents\n",
    "    from types import SimpleNamespace\n",
    "    torch_xla = SimpleNamespace (\n",
    "    )\n",
    "    from typing import Union,BinaryIO\n",
    "    import os\n",
    "    import pickle\n",
    "    import torch.cuda\n",
    "\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "        \n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        if gpu_available:\n",
    "            return torch.device(torch.cuda.current_device()) \n",
    "        return torch.device('cpu')\n",
    "\n",
    "    def fake_save(obj, f: Union[str, os.PathLike, BinaryIO], \n",
    "                master_only=True, global_master=False): \n",
    "        return torch.save(obj,f,pickle_module=pickle, \n",
    "                        pickle_protocol=2, \n",
    "                        _use_new_zipfile_serialization=True)\n",
    "    def fake_rate():\n",
    "        return 230.20\n",
    "\n",
    "    def fake_global_rate():\n",
    "        return 830.10\n",
    "\n",
    "    def fake_add(*args,**kwargs):\n",
    "        pass\n",
    "\n",
    "    def fake_RateTracker():\n",
    "        return SimpleNamespace(\n",
    "            rate = fake_rate,\n",
    "            global_rate = fake_global_rate,\n",
    "            add = fake_add\n",
    "        )\n",
    "    def fake_xrt_world_size():\n",
    "        return 1\n",
    "    def fake_get_ordinal():\n",
    "        return 0\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device,\n",
    "        save = fake_save,\n",
    "        RateTracker = fake_RateTracker,\n",
    "        master_print = print,\n",
    "        xrt_world_size = fake_xrt_world_size,\n",
    "        get_ordinal = fake_get_ordinal\n",
    "    )\n",
    "\n",
    "    def fake_metrics_report():\n",
    "        return \"Fake Metrics Report \\n\\n\\n\\n\"\n",
    "    met = SimpleNamespace (\n",
    "        metrics_report = fake_metrics_report\n",
    "    )\n",
    "\n",
    "    class FakeParallelLoader:\n",
    "        def __init__(self, loader, *args):\n",
    "            self.loader = loader\n",
    "        def per_device_loader(self,device):\n",
    "            return self.loader\n",
    "        \n",
    "    pl = SimpleNamespace(\n",
    "        ParallelLoader = FakeParallelLoader\n",
    "    )\n",
    "\n",
    "    def fake_MpModelWrapper(o):\n",
    "        return o\n",
    "\n",
    "    def fake_run(f,*args, **kwargs):\n",
    "            return f(*args,**kwargs)\n",
    "        \n",
    "    def fake_MpSerialExecutor():\n",
    "        return SimpleNamespace(\n",
    "            run = fake_run\n",
    "        )\n",
    "    def fake_spawn(f, args=None, nprocs=0, start_method=None):\n",
    "        return f(0,*args)\n",
    "\n",
    "    xmp = SimpleNamespace (\n",
    "        MpModelWrapper = fake_MpModelWrapper,\n",
    "        MpSerialExecutor = fake_MpSerialExecutor,\n",
    "        spawn = fake_spawn\n",
    "    )\n",
    "\n",
    "    xu = SimpleNamespace (\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.learner import CancelValidException\n",
    "class SkipValidationCallback(Callback):\n",
    "    order,run_valid = -9, False\n",
    "    # raise CancelValidException before XLATrainingCallback.before_validate\n",
    "    # to prevent call to wrap_parallel_loader on before_validate\n",
    "    def before_validate(self): \n",
    "        raise CancelValidException()\n",
    "\n",
    "    def after_cancel_validate(self):\n",
    "        xm.mark_step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastai.callback.schedule import ParamScheduler, SchedExp\n",
    "\n",
    "class XLALRFinder(ParamScheduler):\n",
    "    \"Training with exponentially growing learning rate\"\n",
    "    def __init__(self, start_lr=1e-7, end_lr=10, num_it=100, stop_div=True):\n",
    "        if is_listy(start_lr):\n",
    "            self.scheds = {'lr': [SchedExp(s, e) for (s,e) in zip(start_lr,end_lr)]}\n",
    "        else: self.scheds = {'lr': SchedExp(start_lr, end_lr)}\n",
    "        self.num_it,self.stop_div = num_it,stop_div\n",
    "        self.skip_batch = False\n",
    "        \n",
    "\n",
    "\n",
    "    def before_fit(self):\n",
    "        super().before_fit()\n",
    "        # no need to save orig weights \n",
    "        # since learner instances are transient on spawned procs\n",
    "        # self.learn.save('_tmp')\n",
    "        self.best_loss = float('inf')\n",
    "        self.skip_batch = False\n",
    "\n",
    "    def before_epoch(self):\n",
    "        # dont report losses while running lrfind (override sync_recorder)\n",
    "        if not xm.is_master_ordinal():\n",
    "            return\n",
    "        if hasattr(self.learn, 'sync_recorder'):\n",
    "            self.learn.logger = noop\n",
    "            self.learn.sync_recorder._sync_stats_log = noop\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.skip_batch:\n",
    "            return\n",
    "        self._update_val(self.train_iter/self.num_it)\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.skip_batch:\n",
    "            return\n",
    "        super().after_batch()\n",
    "        smooth_loss = self.smooth_loss.item() # move xla tensor to cpu\n",
    "        if smooth_loss < self.best_loss:\n",
    "            self.best_loss = smooth_loss\n",
    "\n",
    "        # handle continuation of batch iteration until all batches exhausted\n",
    "        if smooth_loss > 4*self.best_loss and self.stop_div:\n",
    "            # print(f'xla {xm.get_ordinal()}: stop stats collection due to loss')\n",
    "            self.skip_batch = True\n",
    "            self.copy_losses_and_lrs()\n",
    "            return\n",
    "            \n",
    "\n",
    "        if self.train_iter >= self.num_it:\n",
    "            # print(f'xla {xm.get_ordinal()}: stop stats collection due to num_iter')\n",
    "            # return and stop updating losses\n",
    "            self.skip_batch = True\n",
    "            self.copy_losses_and_lrs()\n",
    "            return\n",
    "\n",
    "    def copy_losses_and_lrs(self):\n",
    "        if xm.is_master_ordinal():     \n",
    "            losses = [loss.item() for loss in self.recorder.losses]\n",
    "            iters = self.recorder.iters[:]\n",
    "            values = self.recorder.values[:]\n",
    "        \n",
    "            self.plot_data = {'lrs': self.recorder.lrs[:],\n",
    "                              'losses': losses,\n",
    "                              'iters': iters,\n",
    "                              'values': values}\n",
    "            if hasattr(self,'hps'):\n",
    "                self.plot_data['hps']  = {**self.hps}\n",
    "\n",
    "    def after_fit(self):\n",
    "        super().after_fit()\n",
    "        # no need to load old weights since these will be transient\n",
    "        # self.learn.opt.zero_grad() #Need to zero the gradients of the model before detaching the optimizer for future fits\n",
    "        # tmp_f = self.path/self.model_dir/'_tmp.pth'\n",
    "        # if tmp_f.exists():\n",
    "        #     self.learn.load('_tmp', with_opt=True)\n",
    "        #     os.remove(tmp_f)\n",
    "        if not self.skip_batch:\n",
    "            self.copy_losses_and_lrs()\n",
    "        if xm.is_master_ordinal():\n",
    "            with open('_plt_loss.pkl','wb') as f:\n",
    "                pickle.dump(self.plot_data,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.schedule import SuggestedLRs\n",
    "from fastcore.basics import patch\n",
    "from fastai.torch_core import tensor\n",
    "@patch\n",
    "def get_suggested_lrs(self:Learner, num_it):\n",
    "    'compute Suggested LRs'\n",
    "    lrs,losses = tensor(self.recorder.lrs[num_it//10:-5]),tensor(self.recorder.losses[num_it//10:-5])\n",
    "    if len(losses) == 0: return\n",
    "    lr_min = lrs[losses.argmin()].item()\n",
    "    grads = (losses[1:]-losses[:-1]) / (lrs[1:].log()-lrs[:-1].log())\n",
    "    lr_steep = lrs[grads.argmin()].item()\n",
    "    return SuggestedLRs(lr_min/10.,lr_steep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"Learner.get_suggested_lrs\" class=\"doc_header\"><code>Learner.get_suggested_lrs</code><a href=\"__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>Learner.get_suggested_lrs</code>(**`num_it`**)\n\ncompute Suggested LRs",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "show_doc(Learner.get_suggested_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch   \n",
    "@patch\n",
    "def reload_lr_find_attrs(self:Recorder, fn='_plt_loss.pkl'):\n",
    "    if isinstance(fn,str):\n",
    "        fn = Path(fn)\n",
    "\n",
    "    if not fn.is_file():\n",
    "        return\n",
    "       \n",
    "    with open(fn,'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        self.lrs,self.losses = d['lrs'],d['losses']\n",
    "        self.values, self.iters = d['values'], d['iters']\n",
    "        if 'hps' in d:\n",
    "            self.hps = d['hps']\n",
    "    # delete file after\n",
    "    if fn.is_file():\n",
    "        fn.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def xla_run_lr_find(rank, learner_args, add_args, lr_find_args, ctrl_args):\n",
    "    xm.rendezvous('start_xla_run_lr_find')\n",
    "    # print(f'xla {rank} : start run lrfind')\n",
    "    sync_valid = True\n",
    "    learner = make_xla_child_learner(rank, sync_valid, learner_args, add_args, ctrl_args)\n",
    "\n",
    "    num_it = lr_find_args['num_it']\n",
    "    n_epoch = num_it//len(learner.dls.train) + 1\n",
    "    learner.opt = None\n",
    "    learner.create_opt()\n",
    "    cb = XLALRFinder(**lr_find_args) \n",
    " \n",
    "    skip_valid_cb = SkipValidationCallback()\n",
    "    \n",
    "    with learner.no_logging(): \n",
    "        learner.fit(n_epoch, cbs=[cb, skip_valid_cb])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from pathlib import Path\n",
    "from fastai.learner import Learner\n",
    "from fastcore.basics import patch\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "@patch\n",
    "@delegates(Learner.lr_find)\n",
    "def xla_lr_find(self:Learner, num_cores=8, start_method='fork', **kwargs):\n",
    "    lr_find_args = {\n",
    "        'start_lr': 1e-7,\n",
    "        'end_lr': 10.,\n",
    "        'num_it': 100,\n",
    "        'stop_div': True\n",
    "    }\n",
    "    fn = Path('_plt_loss.pkl')\n",
    "    if fn.is_file():\n",
    "        fn.unlink()\n",
    "    # remove show_plot and suggestions param\n",
    "    show_plot = kwargs.pop('show_plot', True)\n",
    "    suggestions = kwargs.pop('suggestions',True)\n",
    "    # override default with kwargs\n",
    "    lr_find_args = {**lr_find_args, **kwargs}    \n",
    "\n",
    "    ctrl_args = self.pre_xla_fit()\n",
    "    learner_args, add_args = self.pack_learner_args()\n",
    "    xmp.spawn(xla_run_lr_find,\n",
    "              args=(learner_args, add_args, lr_find_args, ctrl_args),\n",
    "              nprocs=num_cores,\n",
    "              start_method=start_method)\n",
    "    self.post_xla_fit(ctrl_args)\n",
    "    self.recorder.reload_lr_find_attrs()\n",
    "    if show_plot:\n",
    "        # show_loss()\n",
    "        self.recorder.plot_lr_find()\n",
    "    if suggestions:\n",
    "        return self.get_suggested_lrs(lr_find_args['num_it'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out `xla_lr_find`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "from fastai.vision.all import *\n",
    "# path = untar_data(URLs.MNIST_TINY)\n",
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    # splitter=GrandparentSplitter(),\n",
    "    splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "    item_tfms=Resize(28),\n",
    "    batch_tfms=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# dls = data.dataloaders(path, bs=8)\n",
    "dls = data.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e39ec5a2fd4ccaa4a922715cf93a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "learner = cnn_learner(dls, resnet18, metrics=accuracy, concat_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 368 ms, total: 3.47 s\n",
      "Wall time: 51.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.02089296132326126, lr_steep=0.0006918309954926372)"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "learner.xla_lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
