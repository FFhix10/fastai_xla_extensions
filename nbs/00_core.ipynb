{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core XLA extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "#colab\n",
    "IN_COLAB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "import os\n",
    "if IN_COLAB:\n",
    "    assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "![ -d /content ] && [ ! -d /content/data ] && curl -s https://course19.fast.ai/setup/colab | bash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fastai\n",
    "\n",
    "Use latest fastai and fastcore versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "#colab\n",
    "![ -d /content ] && pip install -Uqq fastcore --upgrade\n",
    "![ -d /content ] && pip install -Uqq fastai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup torch XLA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the official way to install Pytorch-XLA 1.7 [instructions here](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=CHzziBW5AoZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "#colab\n",
    "![ -d /content ] && pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "# use this for getting pytorch XLA nightly version\n",
    "# VERSION = \"20200707\"  #@param [\"1.5\" , \"20200325\",\"20200707\", \"nightly\"]\n",
    "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.0+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.8.1+cu101\n",
      "fastai==2.1.9\n",
      "fastcore==1.3.12\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/drive/MyDrive/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if XLA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "DEBUG = False # set to false for prod release\n",
    "TRACE = False # set to false for prod release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "if DEBUG:\n",
    "    from pdb import set_trace\n",
    "else:\n",
    "    from fastcore.imports import noop\n",
    "    set_trace = noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide_output\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def xla_imported(): return 'torch_xla' in sys.modules\n",
    "# currently unused, might be deleted later?\n",
    "def xla_available_config(): return os.environ.get(\"XRT_DEVICE_MAP\", False) and os.environ.get(\"XRT_WORKERS\", False)\n",
    "def xla_module_exist(): return importlib.util.find_spec('torch_xla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code routine handles the possibility of running the package when the environment does not provide a TPU (e.g. CI env, local, etc) by providing mock implementations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#exporti\n",
    "import warnings\n",
    "try:\n",
    "    import torch_xla\n",
    "except ImportError as e:\n",
    "    if DEBUG: warnings.warn('TPU environment not available')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "if not xla_imported():\n",
    "    from types import SimpleNamespace\n",
    "    import torch.cuda\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        return torch.device(torch.cuda.current_device()) if gpu_available else torch.device('cpu')\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device\n",
    "    )\n",
    "else:\n",
    "    import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching BaseOptimizer to be Pickable\n",
    "Patching Base Optimizer `__getstate__` and `__setstate__` whichi is used in pickling\n",
    "the optimizer which should fix the bug in running the learner in multiple TPU cores\n",
    "in XLA by which the  `def _fetch_gradients(optimizer)` in `for param_group in optimizer.__getstate__()['param_groups']:` fails, and this patch fixes the \"copy constructor\" to include the param_groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from fastcore.foundation import GetAttr\n",
    "# from fastai.optimizer import Optimizer\n",
    "# from copy import deepcopy\n",
    "\n",
    "# Right now deciding to patch BaseOptimizer instead of add with a PickableOpt(Optimizer) class like in previous versions\n",
    "from fastcore.basics import patch_to\n",
    "from fastai.optimizer import _BaseOptimizer\n",
    "\n",
    "@patch_to(_BaseOptimizer)\n",
    "def __getstate__(self):\n",
    "    # https://github.com/pytorch/pytorch/blob/46b252b83a97bba0926cead050d76fcef129cb6b/torch/optim/optimizer.py#L54\n",
    "    d = {\n",
    "            'defaults': self.defaults,\n",
    "            'state': self.state_dict(),\n",
    "            'param_groups': self.param_groups,\n",
    "        }\n",
    "    return d\n",
    "\n",
    "@patch_to(_BaseOptimizer)\n",
    "def __setstate__(self, data):\n",
    "    # https://github.com/pytorch/pytorch/blob/46b252b83a97bba0926cead050d76fcef129cb6b/torch/optim/optimizer.py#L61\n",
    "    self.defaults = data['defaults']\n",
    "    self.load_state_dict(data['state'])\n",
    "    self.param_groups = data['param_groups']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLA Optim Proxy\n",
    "`XLAOptimProxy` is a class which has overridden the `step` method to call the Pytorch-XLA function `xm.optimizer_step` which synchronizes the XLA graph. All other calls to `XLAOptimProxy` just forward it to the internal `self.opt` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#colab\n",
    "# import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.foundation import GetAttr\n",
    "\n",
    "class XLAOptimProxy(GetAttr):\n",
    "    _default='opt'\n",
    "    \"Proxy optimizer to override `opt.step` with Pytorch XLA sync method `xm.optimizer_step` \"\n",
    "    def __init__(self,opt, barrier):\n",
    "        self.opt = opt # because not using PickableOpt(opt) for the moment\n",
    "        self._barrier = barrier\n",
    "\n",
    "    def step(self):\n",
    "        xm.optimizer_step(self.opt,barrier=self._barrier) \n",
    "\n",
    "    @property\n",
    "    def barrier(self): return self._barrier\n",
    "    @barrier.setter\n",
    "    def barrier(self,v): self._barrier = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeviceMoverTransform\n",
    "`DeviceMoverTransform` is a simple transform that moves the batch input from the CPU to the XLA device. \n",
    "\n",
    "This is in lieu of the normal mechanism of the DataLoader implementation where the dls.device is set to the XLA device before the start of any batch transformations in the dataloaders.\n",
    "\n",
    "Unfortunately, the AffineCoordTfm which is used for data augmentation (all the batch Zoom, Warp, Rotate augmentations) cause a problem when run on the TPU due to some affine operations not currently implemented in the Pytorch XLA) which triggers a lowering of the XLA Tensors to the CPU to perform the affine operation and causes a massive slowdown, even much slower than just doing the affine transform in the CPU in the first place.\n",
    "\n",
    "The solution is then to postpone the moving of the input batch to TPU after the affine transformation, by setting the dls.device to None, which is done in the before_fit method of the XLAOptCallback. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.transform import DisplayedTransform\n",
    "from torch import Tensor\n",
    "import torch\n",
    "class DeviceMoverTransform(DisplayedTransform):\n",
    "    \"Transform to move input to new device and reverse to cpu\"\n",
    "    def __init__(self, device_to, device_from=torch.device('cpu')):\n",
    "        store_attr('device_to,device_from')\n",
    "    def encodes(self, o:Tensor):\n",
    "        return o.to(self.device_to)\n",
    "    def decodes(self, o:Tensor):\n",
    "        return o.to(self.device_from)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.transform import Transform\n",
    "from fastai.vision.augment import AffineCoordTfm, RandomResizedCropGPU\n",
    "from fastai.data.core import DataLoaders,DataLoader\n",
    "\n",
    "def _isAffineCoordTfm(o:Transform):\n",
    "    return isinstance(o,(AffineCoordTfm,RandomResizedCropGPU))\n",
    "\n",
    "def _isDeviceMoverTransform(o:Transform):\n",
    "    return isinstance(o,DeviceMoverTransform)\n",
    "\n",
    "def has_affinecoord_tfm(dls: DataLoaders) -> bool:\n",
    "    \"returns true if train dataloader has an AffineCoordTfm in the batch_tfms\"\n",
    "    idxs = dls.train.after_batch.fs.argwhere(_isAffineCoordTfm)\n",
    "    return len(idxs) > 0\n",
    "def has_devicemover_tfm(dl: DataLoader) -> bool:\n",
    "    \"returns true if train dataloader has a DeviceMoverTransform in the batch_tfms\"\n",
    "    idxs = dl.after_batch.fs.argwhere(_isDeviceMoverTransform)\n",
    "    return len(idxs) > 0\n",
    "\n",
    "def get_last_affinecoord_tfm_idx(dl:DataLoader)-> int: # -1 if none\n",
    "    \"returns index of last AffineCoordTfm if it exists, otherwise returns -1\"\n",
    "    idxs = dl.after_batch.fs.argwhere(_isAffineCoordTfm)\n",
    "    return -1 if len(idxs) == 0 else idxs[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_batch_tfm(dl:DataLoader, batch_tfm:Transform, idx:int):\n",
    "    \"adds a batch_tfm in the batch_tfms for the dataloader at idx location\"\n",
    "    dl.after_batch.fs.insert(idx, batch_tfm)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#export\n",
    "from fastai.learner import Learner\n",
    "\n",
    "def setup_input_device_mover(learn: Learner, new_device):\n",
    "    \"setup batch_tfms to use cpu if dataloader batch_tfms has AffineCoordTfms\"\n",
    "    if not has_affinecoord_tfm(learn.dls):\n",
    "        learn.dls.device = new_device\n",
    "        return\n",
    "    learn.dls.device = None\n",
    "    if has_devicemover_tfm(learn.dls.train):\n",
    "        return # skip adding device mover if already added\n",
    "    dm_tfm = DeviceMoverTransform(new_device)\n",
    "    for dl in learn.dls.loaders:\n",
    "        if not has_devicemover_tfm(dl):\n",
    "            idx = get_last_affinecoord_tfm_idx(dl)\n",
    "            if DEBUG: print(f'setup device mover dl: {dl} idx: {idx}')\n",
    "            if idx != -1:\n",
    "                insert_batch_tfm(dl, dm_tfm, idx+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLA Opt Callback\n",
    "This callback replaces the learner's `opt` with an instance of `XLAOptimProxy` that proxies the original `opt` during the beginning of the `fit` method and restores the original `opt` after the `fit`.\n",
    "\n",
    "It also sets the `dataloaders.device` and the `learn.model` to use a TPU core using the device returned by the `xm.xla_device()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.vision.all import to_device\n",
    "from fastai.callback.core import TrainEvalCallback\n",
    "from fastai.learner import Recorder\n",
    "\n",
    "class XLAOptCallback(Callback):\n",
    "    'Callback to replace `opt.step` with `xm.optimizer_step(opt)` as required to run on TPU'\n",
    "    run_after,run_before = TrainEvalCallback,Recorder\n",
    "    def __init__(self, barrier=True):\n",
    "        self._barrier = barrier\n",
    "\n",
    "    def before_fit(self):\n",
    "        'replace opt with proxy which calls `xm.optimizer_step` instead of `opt.step` and set `dls.device` and model to `xla_device`'\n",
    "        # set dls device to none so prevent trigger of moving to batch input to XLA device\n",
    "        # as this move will be done by the DeviceMoverTransform which has been added to the dls after_batch tfms\n",
    "        if has_affinecoord_tfm(self.dls):\n",
    "            self.dls.device = None\n",
    "\n",
    "        if self.learn.opt is not None:\n",
    "            if not isinstance(self.learn.opt,XLAOptimProxy):\n",
    "                # force opt to reinitialize its parameters and make sure its parameters\n",
    "                opt = self.learn.opt\n",
    "                self.learn.opt = XLAOptimProxy(opt, barrier=self._barrier)\n",
    "        \n",
    "    def after_fit(self):\n",
    "        'restore original opt '\n",
    "        if isinstance(self.learn.opt, XLAOptimProxy):\n",
    "            opt = self.learn.opt.opt\n",
    "            self.learn.opt = opt\n",
    "    @property\n",
    "    def barrier(self): return self._barrier\n",
    "    @barrier.setter\n",
    "    def barrier(self,v): self._barrier = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If XLA is available, then it is assumed that XLA is intended \n",
    "to be used -- this requires the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The `XLAOptCallback` (which enables the `Learner` to call `xm.optimizer_step` via the `XLAOptimProxy`) is not automatically added as a default callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from fastcore.foundation import defaults\n",
    "# if hasattr(defaults,'callbacks'):\n",
    "#     if XLAOptCallback not in defaults.callbacks:\n",
    "#         defaults.callbacks.append(XLAOptCallback)\n",
    "# else:\n",
    "#     defaults.callbacks = [XLAOptCallback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Override the `Learner.summary` method to set the `learner.dls` to use an `xla_device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# if xla_imported():\n",
    "#     from fastcore.foundation import patch\n",
    "#     from fastai.learner import Learner\n",
    "#     @patch\n",
    "#     def move2_xla_device(self:Learner):\n",
    "#         if DEBUG: print('call move2_xla_device')\n",
    "#         if TRACE: set_trace()\n",
    "#         if not hasattr(self,'xla_model_device'):\n",
    "#             xla_model_device = xm.xla_device() \n",
    "#             if DEBUG: print(f'move2_xla_device: moving dls, model to {xla_model_device}')\n",
    "#             self.model.to(xla_model_device)\n",
    "#             self.dls.device = xla_model_device\n",
    "#             self.xla_model_device = xla_model_device\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# if xla_imported():\n",
    "#     from fastcore.foundation import patch\n",
    "#     from fastai.learner import Learner\n",
    "#     from fastai.callback.hook import *\n",
    "#     orig_summary = Learner.summary\n",
    "#     @patch\n",
    "#     def summary(self:Learner):\n",
    "#         self.move2_xla_device()\n",
    "#         return orig_summary(self)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure the model and dataloader has been moved to the xla device prior to creating the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# if xla_imported():\n",
    "#     from fastai.learner import Learner\n",
    "#     orig_create_opt = Learner.create_opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# if xla_imported():\n",
    "#     @patch\n",
    "#     def create_opt(self:Learner):        \n",
    "#         if DEBUG: print('creating opt')\n",
    "#         self.move2_xla_device()\n",
    "#         orig_create_opt(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.foundation import patch\n",
    "#export\n",
    "@patch\n",
    "def to_xla(self:Learner, new_device=None):\n",
    "    self.add_cb(XLAOptCallback())\n",
    "    if new_device is None:\n",
    "        new_device = xm.xla_device()\n",
    "    self.model.to(new_device)\n",
    "    setup_input_device_mover(self, new_device)\n",
    "    self.opt = None\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def detach_xla(self:Learner):\n",
    "    self.remove_cb(XLAOptCallback)\n",
    "    self.dls.device = torch.device('cpu')\n",
    "    self.model.to(self.dls.device)\n",
    "    self.opt = None\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Create an MNIST classifier\n",
    "This is an example of the fastai_xla_extensions library\n",
    "in action.\n",
    "\n",
    "First, we import fastai libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.training import GradientAccumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datablock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock,CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(),\n",
    "    item_tfms=Resize(28),\n",
    "    batch_tfms=aug_transforms(do_flip=False, min_scale=0.8) # trigger usage of RandomResizedCropGPU\n",
    "    # batch_tfms=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dataloader to load the batches to the cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = datablock.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       ",Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "(TensorBBox,object) -> encodes\n",
       "(TensorPoint,object) -> encodes\n",
       "decodes: ,RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.after_batch.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "# learner = cnn_learner(dls, resnet18, pretrained=False, metrics=accuracy) # see current bug re pretrained https://github.com/butchland/fastai_xla_extensions/issues/14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       ",Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "(TensorBBox,object) -> encodes\n",
       "(TensorPoint,object) -> encodes\n",
       "decodes: ,RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Normalize -- {'mean': tensor([[[[0.4850]],\n",
       "\n",
       "         [[0.4560]],\n",
       "\n",
       "         [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n",
       "\n",
       "         [[0.2240]],\n",
       "\n",
       "         [[0.2250]]]]), 'axes': (0, 2, 3)}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.train.after_batch.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup device mover dl: <fastai.data.core.TfmdDL object at 0x7ff3028a9a90> idx: 2\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "learner.to_xla(xm.xla_device());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       ",Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "(TensorBBox,object) -> encodes\n",
       "(TensorPoint,object) -> encodes\n",
       "decodes: ,RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,DeviceMoverTransform -- {'device_to': device(type='xla', index=1), 'device_from': device(type='cpu')}:\n",
       "encodes: (Tensor,object) -> encodes\n",
       "decodes: (Tensor,object) -> decodes\n",
       ",Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Normalize -- {'mean': tensor([[[[0.4850]],\n",
       "\n",
       "         [[0.4560]],\n",
       "\n",
       "         [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n",
       "\n",
       "         [[0.2240]],\n",
       "\n",
       "         [[0.2250]]]]), 'axes': (0, 2, 3)}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.train.after_batch.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       ",Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "(TensorBBox,object) -> encodes\n",
       "(TensorPoint,object) -> encodes\n",
       "decodes: ,RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,DeviceMoverTransform -- {'device_to': device(type='xla', index=1), 'device_from': device(type='cpu')}:\n",
       "encodes: (Tensor,object) -> encodes\n",
       "decodes: (Tensor,object) -> decodes\n",
       ",Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Normalize -- {'mean': tensor([[[[0.4850]],\n",
       "\n",
       "         [[0.4560]],\n",
       "\n",
       "         [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n",
       "\n",
       "         [[0.2240]],\n",
       "\n",
       "         [[0.2250]]]]), 'axes': (0, 2, 3)}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.valid.after_batch.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `learner` object should have an `xla_opt` attribute which confirms that `XLAOptCallback` has been added to the list of callbacks for this learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLAOptCallback"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.xla_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "learner.xla_opt.barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.opt is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='xla', index=1)"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_param(learner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_affinecoord_tfm(learner.dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_devicemover_tfm(learner.dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# currently an unrelated bug : https://github.com/fastai/fastai/issues/3011\n",
    "# learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# learner.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.opt is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "class CheckXLADeviceCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if self.dls.device is not None:\n",
    "            print(f'dls device: {self.dls.device} model device: {one_param(self.learn.model).device}')\n",
    "        else:\n",
    "            print(f'dls device: None model device: {one_param(self.learn.model).device}')\n",
    "        if self.learn.opt is not None:\n",
    "            param = first(self.learn.opt.all_params())[0]\n",
    "            print(f'opt param device: {param.device}')\n",
    "\n",
    "    def before_epoch(self):\n",
    "        if self.dls.device is not None:\n",
    "            print(f'dls device: {self.dls.device} model device: {one_param(self.learn.model).device}')\n",
    "        else:\n",
    "            print(f'dls device: None model device: {one_param(self.learn.model).device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `fit` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dls device: None model device: xla:1\n",
      "opt param device: xla:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.044283</td>\n",
       "      <td>0.589799</td>\n",
       "      <td>0.586552</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>0.333799</td>\n",
       "      <td>0.852647</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710016</td>\n",
       "      <td>0.321834</td>\n",
       "      <td>0.865522</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.624200</td>\n",
       "      <td>0.324638</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "opt param device: xla:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.465133</td>\n",
       "      <td>0.254103</td>\n",
       "      <td>0.912732</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.388323</td>\n",
       "      <td>0.191366</td>\n",
       "      <td>0.925608</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324011</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.108739</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230670</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.201774</td>\n",
       "      <td>0.100754</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n",
      "dls device: None model device: xla:1\n"
     ]
    }
   ],
   "source": [
    "learner.fine_tune(6,freeze_epochs=4, cbs=CheckXLADeviceCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6) [IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       ",Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "(TensorMask,object) -> encodes\n",
       "(TensorBBox,object) -> encodes\n",
       "(TensorPoint,object) -> encodes\n",
       "decodes: ,RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,DeviceMoverTransform -- {'device_to': device(type='xla', index=1), 'device_from': device(type='cpu')}:\n",
       "encodes: (Tensor,object) -> encodes\n",
       "decodes: (Tensor,object) -> decodes\n",
       ",Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: ,Normalize -- {'mean': tensor([[[[0.4850]],\n",
       "\n",
       "         [[0.4560]],\n",
       "\n",
       "         [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n",
       "\n",
       "         [[0.2240]],\n",
       "\n",
       "         [[0.2250]]]]), 'axes': (0, 2, 3)}:\n",
       "encodes: (TensorImage,object) -> encodes\n",
       "decodes: (TensorImage,object) -> decodes\n",
       "]"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.train.after_batch.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.detach_xla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.opt is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='xla', index=1)"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_param(learner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/stage-1.pth')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(dls,resnet18, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7ff2fcf59ba8>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7ff2fcf59ba8>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.to_xla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.dls.device is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dls device: None model device: xla:1\n",
      "opt param device: xla:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.148499</td>\n",
       "      <td>0.091807</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dls device: None model device: xla:1\n"
     ]
    }
   ],
   "source": [
    "learner.fit_flat_cos(1,cbs=CheckXLADeviceCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7ff2fcf59ba8>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.detach_xla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-1fb6be3579a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, fname, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m#To avoid the warning that come from PyTorch about model not being checked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__reduce_ex__\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce_ex__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_has_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_zero_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fa_rebuild_qtensor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m \u001b[0;32melse\u001b[0m  \u001b[0m_fa_rebuild_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;31m#         if func.__name__[0]!='_': print(func, types, args, kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;31m#         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch_xla/csrc/tensor_impl.cpp:144 : XLA tensors do not have storage"
     ]
    }
   ],
   "source": [
    "learner.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_param(learner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = get_image_files(path/'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fine_tune(6, freeze_epochs=4, cbs=CheckXLADeviceCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.dls.train.after_batch.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.debugger import set_trace\n",
    "# def call_fit(learner,epochs=1):\n",
    "#     set_trace()\n",
    "#     learner.fit(epochs, cbs=[CheckXLADeviceCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(5, lr_max=slice(2e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(5, lr_max=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_fit(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.fine_tune(1, freeze_epochs=4, cbs=[CheckXLADeviceCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.fit_one_cycle(5,lr_max=slice(2e-6,7e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.fit_one_cycle(4, lr_max=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Accum callback (which calls CancelBatchException) should still work.\n",
    "\n",
    "An alternative design for the XLA Opt Callback which raises the CancelBatchException in the `after_backward` method (after executing `xm.optimizer_step` and `opt.zero_grad`) would interfere with the Gradient Accum callback (which raises `CancelBatchException` in the `after_backward` method to [skip the gradient updates](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L22) in order to accumulate the gradients).\n",
    "\n",
    "The current design (add/remove `XLAOptimProxy` during `before_fit` and `after_fit` callback lifecycle methods) is less disruptive and more compatible with other callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.fit_one_cycle(4,cbs=[GradientAccumulation(n_acc=2),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid loss has kind of plateaued so this look ok.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot moms and lr across batches/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.recorder.plot_sched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Classification Interpretation for more details on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples where model was most confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "interp.plot_top_losses(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
