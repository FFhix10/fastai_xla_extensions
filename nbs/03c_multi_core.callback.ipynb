{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# attach gdrive holding repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core.callback    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Core Callback XLA Extensions\n",
    "\n",
    "> Patches to Recorder and ParamScheduler Callbacks\n",
    "to support Multi Core XLA Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifications to existing callback `Recorder`, `ParamScheduler` are needed in order to store extra attributes to a temporary file after running the multi core TPU training as spawned processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 735.4MB 1.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 12.8MB 55.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 7.0MB 4.7MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# install pytorch 1.7.1 b/c fastai doesn't support pytorch 1.8 just yet\n",
    "!pip install -Uqq --no-cache-dir torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchtext==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 80kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
      "\u001b[31mERROR: earthengine-api 0.1.254 has requirement google-api-python-client>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 5.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/butchland/fastai_xla_extensions.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/butchland/my_timesaver_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content\n",
    "!ln -s /content/drive/MyDrive/fastai_xla_extensions  fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.1+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.8.0\n",
      "torchvision==0.8.2+cu101\n",
      "fastai==2.2.7\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrelease==0.1.11\n",
      "fastrlock==0.5\n",
      "nbdev==1.1.13\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep timesaver\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# start of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#exporti\n",
    "from fastai_xla_extensions.utils import xla_imported\n",
    "from fastai_xla_extensions.misc_utils import *\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "# from fastai_xla_extensions.multi_core.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "try:\n",
    "    import torch_xla\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "if xla_imported():\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#local\n",
    "# fake out torch_xla modules if not running on xla supported envs\n",
    "if not xla_imported():\n",
    "    # replace torch xla modules with fake equivalents\n",
    "    from types import SimpleNamespace\n",
    "    torch_xla = SimpleNamespace (\n",
    "    )\n",
    "    from typing import Union,BinaryIO\n",
    "    import os\n",
    "    import pickle\n",
    "    import torch.cuda\n",
    "\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "        \n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        if gpu_available:\n",
    "            return torch.device(torch.cuda.current_device()) \n",
    "        return torch.device('cpu')\n",
    "\n",
    "    def fake_save(obj, f: Union[str, os.PathLike, BinaryIO], \n",
    "                master_only=True, global_master=False): \n",
    "        return torch.save(obj,f,pickle_module=pickle, \n",
    "                        pickle_protocol=2, \n",
    "                        _use_new_zipfile_serialization=True)\n",
    "    def fake_rate():\n",
    "        return 230.20\n",
    "\n",
    "    def fake_global_rate():\n",
    "        return 830.10\n",
    "\n",
    "    def fake_add(*args,**kwargs):\n",
    "        pass\n",
    "\n",
    "    def fake_RateTracker():\n",
    "        return SimpleNamespace(\n",
    "            rate = fake_rate,\n",
    "            global_rate = fake_global_rate,\n",
    "            add = fake_add\n",
    "        )\n",
    "    def fake_xrt_world_size():\n",
    "        return 1\n",
    "    def fake_get_ordinal():\n",
    "        return 0\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device,\n",
    "        save = fake_save,\n",
    "        RateTracker = fake_RateTracker,\n",
    "        master_print = print,\n",
    "        xrt_world_size = fake_xrt_world_size,\n",
    "        get_ordinal = fake_get_ordinal\n",
    "    )\n",
    "\n",
    "    def fake_metrics_report():\n",
    "        return \"Fake Metrics Report \\n\\n\\n\\n\"\n",
    "    met = SimpleNamespace (\n",
    "        metrics_report = fake_metrics_report\n",
    "    )\n",
    "\n",
    "    class FakeParallelLoader:\n",
    "        def __init__(self, loader, *args):\n",
    "            self.loader = loader\n",
    "        def per_device_loader(self,device):\n",
    "            return self.loader\n",
    "        \n",
    "    pl = SimpleNamespace(\n",
    "        ParallelLoader = FakeParallelLoader\n",
    "    )\n",
    "\n",
    "    def fake_MpModelWrapper(o):\n",
    "        return o\n",
    "\n",
    "    def fake_run(f,*args, **kwargs):\n",
    "            return f(*args,**kwargs)\n",
    "        \n",
    "    def fake_MpSerialExecutor():\n",
    "        return SimpleNamespace(\n",
    "            run = fake_run\n",
    "        )\n",
    "    def fake_spawn(f, args=None, nprocs=0, start_method=None):\n",
    "        return f(0,*args)\n",
    "\n",
    "    xmp = SimpleNamespace (\n",
    "        MpModelWrapper = fake_MpModelWrapper,\n",
    "        MpSerialExecutor = fake_MpSerialExecutor,\n",
    "        spawn = fake_spawn\n",
    "    )\n",
    "\n",
    "    xu = SimpleNamespace (\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from fastcore.xtras import is_listy\n",
    "def maybe_item(o):\n",
    "    '''extract scalar values from a tensor, lists and dicts of tensors \n",
    "    (and pulling it out of gpu/tpu into cpu) else if not tensor just \n",
    "    use orig value'''\n",
    "    if isinstance(o,torch.Tensor): return o.item()\n",
    "    if is_listy(o):\n",
    "        kls = o.__class__\n",
    "        k = [maybe_item(i) for i in o]\n",
    "        return kls(k)\n",
    "    if isinstance(o,dict):\n",
    "        return {k:maybe_item(v) for k,v in o.items()}\n",
    "    # maybe scalar or object\n",
    "    return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "t1 = torch.tensor(5.)\n",
    "test_eq(maybe_item(t1), 5.)\n",
    "test_eq(maybe_item(float(5)),5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a tensor, `maybe_item` converts it to a scalar. If given is not a tensor (e.g. already a scalar), it just returns the scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "from fastai.torch_core import tensor\n",
    "tl1 = [tensor(2.)] * 5\n",
    "test_eq(maybe_item(tl1), [2.] * 5)\n",
    "dt1 = { 'd1': tensor(3.),\n",
    "        'd2': [tensor(1.)] * 3}\n",
    "df1 = { 'd1': 3.,\n",
    "        'd2': [1.] * 3}\n",
    "test_eq(maybe_item(dt1), df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`maybe_item` should also work for lists of tensors and dicts of tensors\n",
    "and/or list of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch\n",
    "\n",
    "@patch\n",
    "def get_extra_attrs(self:Recorder):\n",
    "    'Extract state attrs of Recorder into a dict (suitable for pickling)'\n",
    "    # state_attrs = lrs','iters','losses','values'\n",
    "    d = {}\n",
    "    for attr in self._stateattrs:\n",
    "        if hasattr(self,attr):\n",
    "            value = getattr(self,attr)\n",
    "            d[attr] = maybe_item(value)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Recorder.get_extra_attrs\" class=\"doc_header\"><code>Recorder.get_extra_attrs</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Recorder.get_extra_attrs</code>()\n",
       "\n",
       "Extract state attrs of Recorder into a dict (suitable for pickling)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "show_doc(Recorder.get_extra_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.862452</td>\n",
       "      <td>10.961300</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.377245</td>\n",
       "      <td>7.764143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.707360</td>\n",
       "      <td>5.063774</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.145759</td>\n",
       "      <td>3.160653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.798985</td>\n",
       "      <td>1.907360</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "from fastai.test_utils import *\n",
    "learner = synth_learner()\n",
    "learner.fit(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# setup checks\n",
    "assert hasattr(learner,'recorder')\n",
    "assert len(learner.recorder.lrs)  == 5 * 10\n",
    "assert len(learner.recorder.losses) == 5 * 10\n",
    "assert len(learner.recorder.iters) == 5\n",
    "assert len(learner.recorder.values) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attrs = learner.recorder.get_extra_attrs()\n",
    "test_eq(extra_attrs['lrs'], learner.recorder.lrs)\n",
    "test_eq(extra_attrs['losses'], learner.recorder.losses)\n",
    "test_eq(extra_attrs['iters'], learner.recorder.iters)\n",
    "test_eq(extra_attrs['values'], learner.recorder.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.get_extra_attrs` should copy the state attrs (`lrs`,`losses`,`iters` and `values`) into\n",
    "a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch\n",
    "\n",
    "@patch\n",
    "def dump_attrs(self:Recorder, fn='_rec_attr.pkl'):\n",
    "    'dump state attrs to a file'\n",
    "    d = self.get_extra_attrs()\n",
    "    with open(fn,'wb') as f:\n",
    "        pickle.dump(d,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch\n",
    "from pathlib import Path\n",
    "\n",
    "@patch\n",
    "def reload_attrs(self:Recorder, fn='_rec_attr.pkl'):\n",
    "    'reload attrs from file `fn`'\n",
    "    if isinstance(fn,str):\n",
    "        fn = Path(fn)\n",
    "    if not fn.is_file():\n",
    "        return\n",
    "    with open(fn,'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        for k,v in d.items():\n",
    "            setattr(self,k,v)\n",
    "    fn.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fn = 'test_rec_attrs.pkl'\n",
    "!rm -f {test_fn}\n",
    "learner.recorder.dump_attrs(fn=test_fn)\n",
    "f = Path(test_fn)\n",
    "assert f.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delattr(learner.recorder,'lrs')\n",
    "delattr(learner.recorder,'losses')\n",
    "delattr(learner.recorder,'iters')\n",
    "delattr(learner.recorder,'values')\n",
    "assert not hasattr(learner.recorder,'lrs')\n",
    "assert not hasattr(learner.recorder,'losses')\n",
    "assert not hasattr(learner.recorder,'iters')\n",
    "assert not hasattr(learner.recorder,'values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learner.recorder.reload_attrs(fn=test_fn)\n",
    "assert hasattr(learner.recorder,'lrs')\n",
    "assert hasattr(learner.recorder,'losses')\n",
    "assert hasattr(learner.recorder,'iters')\n",
    "assert hasattr(learner.recorder,'values')\n",
    "!rm -f {test_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch\n",
    "\n",
    "@patch\n",
    "def after_fit(self: Recorder):\n",
    "    'after fit dump extra attrs to file'\n",
    "    if getattr(self.learn,'inner_xla',False) and self.learn.xla_rank == 0:\n",
    "        self.dump_attrs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.schedule import ParamScheduler\n",
    "from fastcore.basics import patch\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "@patch\n",
    "def dump_hps(self:ParamScheduler, fn='_paramsched_hps.pkl'):\n",
    "    'dump `hps` to a file `fn`'\n",
    "    if not hasattr(self, 'hps'): \n",
    "        return\n",
    "\n",
    "    if isinstance(fn,str):\n",
    "        fn = Path(fn)\n",
    "\n",
    "    d = maybe_item(self.hps)\n",
    "    with open(fn,'wb') as f:\n",
    "        pickle.dump(d,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ParamScheduler.dump_hps\" class=\"doc_header\"><code>ParamScheduler.dump_hps</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ParamScheduler.dump_hps</code>(**`fn`**=*`'_paramsched_hps.pkl'`*)\n",
       "\n",
       "dump `hps` to a file `fn`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "show_doc(ParamScheduler.dump_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import Recorder\n",
    "from fastcore.basics import patch\n",
    "from pathlib import Path\n",
    "\n",
    "@patch\n",
    "def reload_hps(self:Recorder, fn='_paramsched_hps.pkl'):\n",
    "    'Load hyperparameters saved by ParamScheduler to recorder'\n",
    "    if isinstance(fn,str):\n",
    "        fn = Path(fn)\n",
    "    if not fn.is_file():\n",
    "        return\n",
    "    with open(fn,'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        setattr(self,'hps',d)\n",
    "    fn.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.callback.schedule import ParamScheduler\n",
    "from fastcore.basics import patch\n",
    "\n",
    "@patch\n",
    "def after_fit(self:ParamScheduler):\n",
    "    \"save hps to file\"\n",
    "    if not hasattr(self,'hps'):\n",
    "        return\n",
    "\n",
    "    if hasattr(self.learn, 'recorder'): \n",
    "        self.recorder.hps = self.hps\n",
    "\n",
    "    if getattr(self.learn,'inner_xla',False) and self.learn.xla_rank == 0:\n",
    "        self.dump_hps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ParamScheduler.after_fit\" class=\"doc_header\"><code>ParamScheduler.after_fit</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ParamScheduler.after_fit</code>()\n",
       "\n",
       "save hps to file"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "show_doc(ParamScheduler.after_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.703755</td>\n",
       "      <td>1.439683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.424732</td>\n",
       "      <td>1.078809</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.253089</td>\n",
       "      <td>1.007215</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "#colab\n",
    "param_fn = '_paramsched_hps.pkl'\n",
    "!rm -f {param_fn}\n",
    "learner.inner_xla = True # simulate spawned process learner\n",
    "learner.xla_rank = 0\n",
    "learner.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "param_f = Path(param_fn)\n",
    "assert param_f.is_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "delattr(learner.recorder,'hps')\n",
    "assert not hasattr(learner.recorder,'hps')\n",
    "learner.recorder.reload_hps()\n",
    "assert hasattr(learner.recorder,'hps')\n",
    "!rm -f {param_fn}\n",
    "!rm -f _rec_attr.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test ParamScheduler (`fit_one_cycle` uses `ParamScheduler`) which means it should create a pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.928667</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.785133</td>\n",
       "      <td>0.567121</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.662554</td>\n",
       "      <td>0.433650</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.572687</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.510633</td>\n",
       "      <td>0.367608</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "from fastcore.foundation import L\n",
    "if 'progress' not in L(learner.cbs).attrgot('name'):\n",
    "    learner.add_cbs(ProgressCallback)\n",
    "learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "assert param_f.is_file()\n",
    "rec_attr_f = Path('_rec_attr.pkl')\n",
    "assert rec_attr_f.is_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
