{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# attach gdrive holding repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Core XLA Inference \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/03e_multi_core.inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Multi Core XLA Extensions for inference\n",
    "\n",
    "Multi-core TPU implementation for inference is enabled by importing this module.\n",
    "```\n",
    "from fastai_xla_extensions.multi_core.inference import *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 735.4MB 1.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 12.8MB 43.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 7.0MB 5.3MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# install pytorch 1.7.1 b/c fastai doesn't support pytorch 1.8 just yet\n",
    "!pip install -Uqq --no-cache-dir torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchtext==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 85kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 2.6MB/s \n",
      "\u001b[31mERROR: earthengine-api 0.1.254 has requirement google-api-python-client>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 5.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai==2.3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for my-timesaver-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq git+https://github.com/butchland/my_timesaver_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 2.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 3.1MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.1+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.8.0\n",
      "torchvision==0.8.2+cu101\n",
      "fastai==2.2.7\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrelease==0.1.11\n",
      "fastrlock==0.5\n",
      "my-timesaver-utils==0.0.2\n",
      "nbdev==1.1.13\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep timesaver\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# link repo to work dir\n",
    "%cd /content\n",
    "!ln -s /content/drive/MyDrive/fastai_xla_extensions fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# <!-- Start of kernel -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "try:\n",
    "    import torch_xla\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai_xla_extensions.utils import xla_imported\n",
    "from fastai_xla_extensions.misc_utils import *\n",
    "from fastai_xla_extensions.core import XLAOptCallback\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "from fastai_xla_extensions.multi_core.learner import *\n",
    "from fastai_xla_extensions.multi_core.callback import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#local\n",
    "\n",
    "# fake out torch_xla modules if not running on xla supported envs\n",
    "if not xla_imported():\n",
    "    # replace torch xla modules with fake equivalents\n",
    "    from types import SimpleNamespace\n",
    "    torch_xla = SimpleNamespace (\n",
    "    )\n",
    "    from typing import Union,BinaryIO\n",
    "    import os\n",
    "    import pickle\n",
    "    import torch.cuda\n",
    "\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "        \n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        if gpu_available:\n",
    "            return torch.device(torch.cuda.current_device()) \n",
    "        return torch.device('cpu')\n",
    "\n",
    "    def fake_save(obj, f: Union[str, os.PathLike, BinaryIO], \n",
    "                master_only=True, global_master=False): \n",
    "        return torch.save(obj,f,pickle_module=pickle, \n",
    "                        pickle_protocol=2, \n",
    "                        _use_new_zipfile_serialization=True)\n",
    "    def fake_rate():\n",
    "        return 230.20\n",
    "\n",
    "    def fake_global_rate():\n",
    "        return 830.10\n",
    "\n",
    "    def fake_add(*args,**kwargs):\n",
    "        pass\n",
    "\n",
    "    def fake_RateTracker():\n",
    "        return SimpleNamespace(\n",
    "            rate = fake_rate,\n",
    "            global_rate = fake_global_rate,\n",
    "            add = fake_add\n",
    "        )\n",
    "    def fake_xrt_world_size():\n",
    "        return 1\n",
    "    def fake_get_ordinal():\n",
    "        return 0\n",
    "    def fake_is_master_ordinal(*args,**kwargs): \n",
    "        return True\n",
    "    def fake_maybe_convert_to_cpu(data,*args,**kwargs):\n",
    "        return data\n",
    "\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device,\n",
    "        save = fake_save,\n",
    "        RateTracker = fake_RateTracker,\n",
    "        master_print = print,\n",
    "        xrt_world_size = fake_xrt_world_size,\n",
    "        get_ordinal = fake_get_ordinal,\n",
    "        is_master_ordinal = fake_is_master_ordinal,\n",
    "        _maybe_convert_to_cpu = fake_maybe_convert_to_cpu\n",
    "    )\n",
    "\n",
    "    def fake_metrics_report():\n",
    "        return \"Fake Metrics Report \\n\\n\\n\\n\"\n",
    "    met = SimpleNamespace (\n",
    "        metrics_report = fake_metrics_report\n",
    "    )\n",
    "\n",
    "    class FakePerDeviceLoader:\n",
    "        def __init__(self, *args):\n",
    "            pass\n",
    "        def close(self):\n",
    "            pass\n",
    "            \n",
    "    class FakeParallelLoader:\n",
    "        def __init__(self, loader, *args):\n",
    "            self.loader = loader\n",
    "        def per_device_loader(self,device):\n",
    "            return self.loader\n",
    "        \n",
    "    pl = SimpleNamespace(\n",
    "        ParallelLoader = FakeParallelLoader,\n",
    "        PerDeviceLoader = FakePerDeviceLoader\n",
    "\n",
    "    )\n",
    "\n",
    "    def fake_MpModelWrapper(o):\n",
    "        return o\n",
    "\n",
    "    def fake_run(f,*args, **kwargs):\n",
    "            return f(*args,**kwargs)\n",
    "        \n",
    "    def fake_MpSerialExecutor():\n",
    "        return SimpleNamespace(\n",
    "            run = fake_run\n",
    "        )\n",
    "    def fake_spawn(f, args=None, nprocs=0, start_method=None):\n",
    "        return f(0,*args)\n",
    "\n",
    "    xmp = SimpleNamespace (\n",
    "        MpModelWrapper = fake_MpModelWrapper,\n",
    "        MpSerialExecutor = fake_MpSerialExecutor,\n",
    "        spawn = fake_spawn\n",
    "    )\n",
    "\n",
    "    xu = SimpleNamespace (\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "if xla_imported():\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Multi Core TPU Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import _ConstantFunc\n",
    "# from fastcore.basics import patch\n",
    "# from fastai.learner import Learner\n",
    "\n",
    "@patch\n",
    "def inner_get_preds(self:Learner, ds_idx=1, dl=None, with_input=False, with_decoded=False, with_loss=False, act=None,\n",
    "                inner=False, reorder=True, cbs=None, **kwargs):\n",
    "    \n",
    "    xla_rank = getattr(self,'xla_rank',None)\n",
    "    if xla_rank is None:\n",
    "        return\n",
    "\n",
    "    if dl is None: \n",
    "        dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "    else:\n",
    "        try: len(dl)\n",
    "        except TypeError as e:\n",
    "            raise TypeError(\"`dl` is something other than a single `DataLoader` object\")\n",
    "        if not isinstance(dl, TPUDistributedDL):            \n",
    "            world_size = kwargs.pop('world_size', xm.xrt_world_size())\n",
    "            seed = kwargs.pop('dl_seed',42)\n",
    "            dl = TPUDistributedDL(dl, xla_rank, world_size=world_size, seed=seed)\n",
    "\n",
    "    if reorder and hasattr(dl, 'get_idxs'):\n",
    "        idxs = dl.dl.get_idxs()\n",
    "        dl = dl.new(get_idxs = _ConstantFunc(idxs))\n",
    "        rank_idxs = dl.get_idxs()\n",
    "        rank_idxs_len = len(rank_idxs)\n",
    "        \n",
    "    #handle save_preds and save_targs across ranks\n",
    "    save_preds = kwargs.pop('save_preds',None)\n",
    "    if save_preds is not None:\n",
    "        if isinstance(save_preds, str):\n",
    "            kwargs['save_preds'] = Path(save_preds + str(xla_rank)) # add rank to filename\n",
    "        elif isinstance(save_preds, Path):\n",
    "            kwargs['save_preds'] = Path(str(save_preds) + str(xla_rank)) \n",
    "        kwargs['save_preds'].mkdir(parents=True,exist_ok=True)\n",
    "    save_targs = kwargs.pop('save_targs',None)\n",
    "    if save_targs is not None:\n",
    "        if isinstance(save_targs, str):\n",
    "            kwargs['save_targs'] = Path(save_targs + str(xla_rank)) # add rank to filename\n",
    "        elif isinstance(save_preds, Path):\n",
    "            kwargs['save_targs'] = Path(str(save_targs) + str(xla_rank)) \n",
    "        kwargs['save_targs'].mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    cb = GatherPredsCallback(with_input=with_input, with_loss=with_loss, **kwargs)\n",
    "    ctx_mgrs = self.validation_context(cbs=L(cbs)+[cb], inner=inner)\n",
    "    if with_loss: \n",
    "        ctx_mgrs.append(self.loss_not_reduced())\n",
    "    \n",
    "    with ContextManagers(ctx_mgrs):\n",
    "        self._do_epoch_validate(dl=dl)\n",
    "       \n",
    "        if act is None: \n",
    "            act = getattr(self.loss_func, 'activation', noop)\n",
    "\n",
    "        res = cb.all_tensors()\n",
    "        \n",
    "        pred_i = 1 if with_input else 0\n",
    "        if res[pred_i] is not None:\n",
    "            if act != noop:                \n",
    "                # compute activation on tpu device and detach after\n",
    "                tmp_pred = res[pred_i].to(xm.xla_device())\n",
    "                tmp_res = act(tmp_pred)\n",
    "                res[pred_i] = self.to_detach(tmp_res)\n",
    "                \n",
    "            if with_decoded:\n",
    "                res.insert(pred_i+2, getattr(self.loss_func, 'decodes', noop)(res[pred_i]))\n",
    "\n",
    "        if reorder and hasattr(dl, 'get_idxs'):\n",
    "            t_idxs = tensor(rank_idxs)\n",
    "            start_idx = xla_rank * rank_idxs_len\n",
    "            t_idxs = t_idxs - tensor(start_idx) # broadcast\n",
    "            sorted_idxs = t_idxs.argsort()\n",
    "            res = nested_reorder(res, sorted_idxs )\n",
    "        \n",
    "        return tuple(res)\n",
    "    self._end_cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def setup_inference_args(rank, inference_args):\n",
    "    master_cbs = ifnone(inference_args.pop('master_cbs', None),[])\n",
    "    return inference_args, master_cbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pickle\n",
    "def save_pred_results(rank, results):\n",
    "    fn = f'preds{rank}.pkl'\n",
    "    fn = Path(fn)\n",
    "    with open(fn,'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def xla_run_inference(rank, learner_args, add_args, inference_args, ctrl_args):\n",
    "    sync_valid = True\n",
    "    learner = make_xla_child_learner(rank, sync_valid, learner_args, add_args, ctrl_args)\n",
    "    pred_args, master_cbs = setup_inference_args(rank, inference_args)\n",
    "\n",
    "    if rank == 0 and len(master_cbs) > 0:\n",
    "        learner.add_cbs(master_cbs)\n",
    "\n",
    "    # learner.synced_cancel.before_fit()\n",
    "\n",
    "    if rank == 0:\n",
    "        learner.sync_recorder.orig_logger = learner.logger\n",
    "\n",
    "    results = learner.inner_get_preds(**pred_args)\n",
    "    xm.rendezvous('xla_run_inference')\n",
    "\n",
    "    save_pred_results(rank, results)\n",
    "    xm.mark_step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.foundation import L\n",
    "\n",
    "def reload_pred_results(num_files, n_samples):\n",
    "    all_preds = L()\n",
    "    for rank in range(num_files):\n",
    "        fn = f'preds{rank}.pkl'\n",
    "\n",
    "        fn = Path(fn)\n",
    "        if fn.is_file():\n",
    "            with open(fn,'rb') as f:\n",
    "                rank_preds = pickle.load(f)\n",
    "                all_preds.append(rank_preds)\n",
    "        else:\n",
    "            raise RuntimeException(f'Missing preds file for rank {rank}')\n",
    "\n",
    "    for rank in range(num_files):\n",
    "        fn = f'preds{rank}.pkl'\n",
    "        fn = Path(fn)\n",
    "        fn.unlink()\n",
    "\n",
    "    n_items = len(all_preds[0]) # num items per preds\n",
    "\n",
    "    all_res = []\n",
    "    for i in range(n_items):\n",
    "        items = all_preds.itemgot(i)\n",
    "\n",
    "        if isinstance(items[0], torch.Tensor):\n",
    "            all_items = torch.cat(tuple(items))\n",
    "        elif is_listy(items[0]):\n",
    "            all_items = [*items]\n",
    "        else:\n",
    "            all_items = items\n",
    "        all_res.append(all_items)\n",
    "    res = []\n",
    "    for i, pred in enumerate(all_res):\n",
    "        pred = pred[:n_samples] # take only first \n",
    "        res.append(pred)  \n",
    "    return res\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def pre_xla_inference(self:Learner):\n",
    "    ctrl_args = {}\n",
    "    progress_removed = False\n",
    "    if 'progress' in L(self.cbs).attrgot('name'):\n",
    "        self.remove_cbs(ProgressCallback)\n",
    "        progress_removed = True\n",
    "    ctrl_args['use_progress'] = progress_removed\n",
    "    return ctrl_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def post_xla_inference(self:Learner, ctrl_args):\n",
    "    if ctrl_args['use_progress']:\n",
    "        self.add_cbs(ProgressCallback)\n",
    "    self.recorder.reload_attrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def prep_inference_args(**kwargs):\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#export\n",
    "\n",
    "@patch\n",
    "@delegates(Learner.get_preds, but='num_cores,start_method,master_cbs')\n",
    "def xla_get_preds(self:Learner, ds_idx=1, dl=None, \n",
    "                  with_input=False, with_decoded=False, \n",
    "                  with_loss=False, act=None, inner=False, \n",
    "                  reorder=True, cbs=None, num_cores=8, \n",
    "                  start_method='fork', master_cbs=None,**kwargs):\n",
    "    ctrl_args = self.pre_xla_inference()\n",
    "    learner_args, add_args = self.pack_learner_args()\n",
    "\n",
    "    inference_args = prep_inference_args(ds_idx=ds_idx, dl=dl, \n",
    "                                         with_input=with_input, with_decoded=with_decoded, \n",
    "                                         with_loss=with_loss,\n",
    "                                         act=act, inner=inner, \n",
    "                                         reorder=reorder, \n",
    "                                         cbs=cbs, master_cbs=master_cbs, **kwargs)\n",
    "    if dl:\n",
    "        n_results = len(dl.dataset)\n",
    "    else:\n",
    "        n_results = len(self.dls.loaders[ds_idx].dataset)\n",
    "\n",
    "    xmp.spawn(xla_run_inference,\n",
    "              args=(learner_args, add_args, inference_args, ctrl_args),\n",
    "              nprocs=num_cores,\n",
    "              start_method=start_method)\n",
    "\n",
    "    all_results = reload_pred_results(num_cores, n_results)\n",
    "    self.post_xla_inference(ctrl_args)\n",
    "    return all_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "path = untar_data(URLs.MNIST)\n",
    "# path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock,CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "    item_tfms=Resize(28),\n",
    "    batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n",
    ")\n",
    "# pat = r'(.+)_\\d+.jpg$'\n",
    "# data = DataBlock(\n",
    "#     blocks=(ImageBlock,CategoryBlock),\n",
    "#     get_items=get_image_files,\n",
    "#     get_y=using_attr(RegexLabeller(pat),'name'),\n",
    "#     splitter=RandomSplitter(seed=42),\n",
    "#     item_tfms=Resize(224),\n",
    "#     batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "dls = data.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# loss_func=nn.CrossEntropyLoss()\n",
    "loss_func=CrossEntropyLossFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a80e40740a4c23a3d79a2e662e25a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "learner = cnn_learner(dls, resnet18, metrics=accuracy, loss_func=loss_func, concat_pool=False)\n",
    "# learner = cnn_learner(dls, resnet34, metrics=accuracy, loss_func=loss_func, concat_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.177223</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.224954</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144529</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>02:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "learner.xla_fit_one_cycle(3, lr_max=slice(3e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load('pets-stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('pets-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.091381</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>02:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055593</td>\n",
       "      <td>0.067667</td>\n",
       "      <td>0.978500</td>\n",
       "      <td>02:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083875</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.059680</td>\n",
       "      <td>0.979900</td>\n",
       "      <td>02:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078803</td>\n",
       "      <td>0.058656</td>\n",
       "      <td>0.980800</td>\n",
       "      <td>02:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "learner.xla_fit_one_cycle(5,lr_max=slice(1e-6,2e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('pets-stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 1.77 s, total: 37.5 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "res = learner.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10000, 10]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(res))\n",
    "print(res[0].shape, res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9816)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "res[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 s, sys: 2.02 s, total: 37.9 s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "res2 = learner.get_preds(reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10000, 10]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(res2))\n",
    "print(res2[0].shape, res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "res2[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9816)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 ms, sys: 117 ms, total: 166 ms\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "xla_res = learner.xla_get_preds(reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(xla_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]), torch.Size([10000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "(xla_res[0].shape, xla_res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9997e-01, 1.2037e-06, 2.2819e-07, 9.6082e-08, 5.1155e-08, 2.5031e-07,\n",
       "         2.1356e-05, 7.4675e-07, 1.8351e-07, 4.7405e-06],\n",
       "        [9.9949e-01, 9.3674e-07, 9.9061e-07, 2.3419e-07, 4.0992e-07, 6.5995e-07,\n",
       "         5.0583e-04, 8.3670e-08, 7.9095e-07, 2.8556e-06],\n",
       "        [8.7443e-01, 1.1864e-03, 1.4634e-05, 5.5702e-05, 3.1255e-03, 3.9448e-02,\n",
       "         8.0691e-02, 1.3605e-04, 2.0612e-04, 7.0657e-04],\n",
       "        [9.9999e-01, 9.1822e-07, 7.4076e-08, 1.3242e-07, 3.8235e-08, 9.4999e-08,\n",
       "         5.3028e-06, 8.0097e-07, 3.6222e-08, 9.3102e-07],\n",
       "        [9.9996e-01, 6.0875e-07, 9.9508e-08, 1.6203e-06, 2.5617e-07, 1.3026e-06,\n",
       "         2.4092e-05, 1.4711e-06, 3.8553e-06, 3.5397e-06],\n",
       "        [9.9967e-01, 2.5601e-06, 7.9427e-06, 7.0779e-07, 2.9737e-05, 6.6313e-07,\n",
       "         2.7755e-04, 8.1741e-07, 1.5646e-06, 5.0701e-06],\n",
       "        [9.9988e-01, 4.0136e-06, 4.6879e-06, 1.0828e-06, 1.6936e-06, 2.4147e-06,\n",
       "         7.2721e-05, 3.8035e-06, 1.4383e-06, 3.1155e-05],\n",
       "        [9.9994e-01, 5.1368e-07, 1.0097e-06, 1.6207e-07, 4.7854e-07, 1.5919e-07,\n",
       "         1.1031e-05, 8.6520e-06, 3.0814e-07, 3.5142e-05],\n",
       "        [9.9932e-01, 9.1196e-06, 2.2332e-06, 5.8100e-06, 1.6907e-05, 4.3462e-05,\n",
       "         5.6675e-04, 1.5917e-05, 5.3773e-06, 1.0780e-05],\n",
       "        [9.9997e-01, 4.1387e-06, 1.7671e-07, 6.1776e-08, 6.7920e-08, 9.2069e-08,\n",
       "         1.2195e-05, 3.7874e-07, 1.7996e-07, 8.4062e-06]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9812)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*xla_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70.6 ms, sys: 118 ms, total: 189 ms\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "xla_res2 = learner.xla_get_preds(reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(xla_res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]), torch.Size([10000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "(xla_res2[0].shape, xla_res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res2[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9997e-01, 1.2037e-06, 2.2819e-07, 9.6082e-08, 5.1155e-08, 2.5031e-07,\n",
       "         2.1356e-05, 7.4675e-07, 1.8351e-07, 4.7405e-06],\n",
       "        [9.9949e-01, 9.3674e-07, 9.9061e-07, 2.3419e-07, 4.0992e-07, 6.5995e-07,\n",
       "         5.0583e-04, 8.3670e-08, 7.9095e-07, 2.8556e-06],\n",
       "        [8.7443e-01, 1.1864e-03, 1.4634e-05, 5.5702e-05, 3.1255e-03, 3.9448e-02,\n",
       "         8.0691e-02, 1.3605e-04, 2.0612e-04, 7.0657e-04],\n",
       "        [9.9999e-01, 9.1822e-07, 7.4076e-08, 1.3242e-07, 3.8235e-08, 9.4999e-08,\n",
       "         5.3028e-06, 8.0097e-07, 3.6222e-08, 9.3102e-07],\n",
       "        [9.9996e-01, 6.0875e-07, 9.9508e-08, 1.6203e-06, 2.5617e-07, 1.3026e-06,\n",
       "         2.4092e-05, 1.4711e-06, 3.8553e-06, 3.5397e-06],\n",
       "        [9.9967e-01, 2.5601e-06, 7.9427e-06, 7.0779e-07, 2.9737e-05, 6.6313e-07,\n",
       "         2.7755e-04, 8.1741e-07, 1.5646e-06, 5.0701e-06],\n",
       "        [9.9988e-01, 4.0136e-06, 4.6879e-06, 1.0828e-06, 1.6936e-06, 2.4147e-06,\n",
       "         7.2721e-05, 3.8035e-06, 1.4383e-06, 3.1155e-05],\n",
       "        [9.9994e-01, 5.1368e-07, 1.0097e-06, 1.6207e-07, 4.7854e-07, 1.5919e-07,\n",
       "         1.1031e-05, 8.6520e-06, 3.0814e-07, 3.5142e-05],\n",
       "        [9.9932e-01, 9.1196e-06, 2.2332e-06, 5.8100e-06, 1.6907e-05, 4.3462e-05,\n",
       "         5.6675e-04, 1.5917e-05, 5.3773e-06, 1.0780e-05],\n",
       "        [9.9997e-01, 4.1387e-06, 1.7671e-07, 6.1776e-08, 6.7920e-08, 9.2069e-08,\n",
       "         1.2195e-05, 3.7874e-07, 1.7996e-07, 8.4062e-06]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res2[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9812)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*xla_res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "%cd /content\n",
    "#test save preds and save targs to files per iter\n",
    "xla_res3 = learner.xla_get_preds(save_preds='my_preds', save_targs='my_targs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#8) [None,None,None,None,None,None,None,None],\n",
       " (#8) [None,None,None,None,None,None,None,None]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_preds0\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_preds1\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_preds2\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_preds3\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_preds4\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_preds5\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_preds6\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_preds7\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "!ls -ald /content/my_preds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_targs0\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_targs1\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_targs2\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_targs3\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_targs4\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_targs5\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:54 /content/my_targs6\n",
      "drwxr-xr-x 2 root root 4096 Mar 10 18:53 /content/my_targs7\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "!ls -ald /content/my_targs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "!rm -rf /content/my_preds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "!rm -rf /content/my_targs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx 1 root root   18 Mar 10 17:35 data -> /root/.fastai/data\n",
      "drwx------ 5 root root 4096 Mar 10 17:32 drive\n",
      "lrwxrwxrwx 1 root root   44 Mar 10 17:35 fastai_xla_extensions -> /content/drive/MyDrive/fastai_xla_extensions\n",
      "lrwxrwxrwx 1 root root   19 Mar 10 17:35 models -> /root/.torch/models\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "!ls -ald *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
