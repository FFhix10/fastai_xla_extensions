{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# attach gdrive holding repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Core XLA Inference \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/03e_multi_core.inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Multi Core XLA Extensions for inference\n",
    "\n",
    "Multi-core TPU implementation for inference is enabled by importing this module.\n",
    "```\n",
    "from fastai_xla_extensions.multi_core.inference import *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 80kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 405kB/s \n",
      "\u001b[31mERROR: earthengine-api 0.1.254 has requirement google-api-python-client>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 5.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 776.8MB 19kB/s \n",
      "\u001b[K     |████████████████████████████████| 12.8MB 44.7MB/s \n",
      "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for my-timesaver-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq git+https://github.com/butchland/my_timesaver_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 3.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.1\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.9.0\n",
      "torchvision==0.8.2\n",
      "fastai==2.2.7\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrelease==0.1.11\n",
      "fastrlock==0.5\n",
      "my-timesaver-utils==0.0.2\n",
      "nbdev==1.1.13\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep timesaver\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# link repo to work dir\n",
    "%cd /content\n",
    "!ln -s /content/drive/MyDrive/fastai_xla_extensions fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# <!-- Start of kernel -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try:\n",
    "    import torch_xla\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "#from fastai.vision.all import *\n",
    "from fastai_xla_extensions.utils import xla_imported\n",
    "from fastai_xla_extensions.misc_utils import *\n",
    "from fastai_xla_extensions.core import XLAOptCallback\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "from fastai_xla_extensions.multi_core.learner import *\n",
    "from fastai_xla_extensions.multi_core.callback import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#local\n",
    "\n",
    "# fake out torch_xla modules if not running on xla supported envs\n",
    "if not xla_imported():\n",
    "    # replace torch xla modules with fake equivalents\n",
    "    from types import SimpleNamespace\n",
    "    torch_xla = SimpleNamespace (\n",
    "    )\n",
    "    from typing import Union,BinaryIO\n",
    "    import os\n",
    "    import pickle\n",
    "    import torch.cuda\n",
    "\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "        \n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        if gpu_available:\n",
    "            return torch.device(torch.cuda.current_device()) \n",
    "        return torch.device('cpu')\n",
    "\n",
    "    def fake_save(obj, f: Union[str, os.PathLike, BinaryIO], \n",
    "                master_only=True, global_master=False): \n",
    "        return torch.save(obj,f,pickle_module=pickle, \n",
    "                        pickle_protocol=2, \n",
    "                        _use_new_zipfile_serialization=True)\n",
    "    def fake_rate():\n",
    "        return 230.20\n",
    "\n",
    "    def fake_global_rate():\n",
    "        return 830.10\n",
    "\n",
    "    def fake_add(*args,**kwargs):\n",
    "        pass\n",
    "\n",
    "    def fake_RateTracker():\n",
    "        return SimpleNamespace(\n",
    "            rate = fake_rate,\n",
    "            global_rate = fake_global_rate,\n",
    "            add = fake_add\n",
    "        )\n",
    "    def fake_xrt_world_size():\n",
    "        return 1\n",
    "    def fake_get_ordinal():\n",
    "        return 0\n",
    "    def fake_is_master_ordinal(*args,**kwargs): \n",
    "        return True\n",
    "    def fake_maybe_convert_to_cpu(data,*args,**kwargs):\n",
    "        return data\n",
    "\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device,\n",
    "        save = fake_save,\n",
    "        RateTracker = fake_RateTracker,\n",
    "        master_print = print,\n",
    "        xrt_world_size = fake_xrt_world_size,\n",
    "        get_ordinal = fake_get_ordinal,\n",
    "        is_master_ordinal = fake_is_master_ordinal,\n",
    "        _maybe_convert_to_cpu = fake_maybe_convert_to_cpu\n",
    "    )\n",
    "\n",
    "    def fake_metrics_report():\n",
    "        return \"Fake Metrics Report \\n\\n\\n\\n\"\n",
    "    met = SimpleNamespace (\n",
    "        metrics_report = fake_metrics_report\n",
    "    )\n",
    "\n",
    "    class FakePerDeviceLoader:\n",
    "        def __init__(self, *args):\n",
    "            pass\n",
    "        def close(self):\n",
    "            pass\n",
    "            \n",
    "    class FakeParallelLoader:\n",
    "        def __init__(self, loader, *args):\n",
    "            self.loader = loader\n",
    "        def per_device_loader(self,device):\n",
    "            return self.loader\n",
    "        \n",
    "    pl = SimpleNamespace(\n",
    "        ParallelLoader = FakeParallelLoader,\n",
    "        PerDeviceLoader = FakePerDeviceLoader\n",
    "\n",
    "    )\n",
    "\n",
    "    def fake_MpModelWrapper(o):\n",
    "        return o\n",
    "\n",
    "    def fake_run(f,*args, **kwargs):\n",
    "            return f(*args,**kwargs)\n",
    "        \n",
    "    def fake_MpSerialExecutor():\n",
    "        return SimpleNamespace(\n",
    "            run = fake_run\n",
    "        )\n",
    "    def fake_spawn(f, args=None, nprocs=0, start_method=None):\n",
    "        return f(0,*args)\n",
    "\n",
    "    xmp = SimpleNamespace (\n",
    "        MpModelWrapper = fake_MpModelWrapper,\n",
    "        MpSerialExecutor = fake_MpSerialExecutor,\n",
    "        spawn = fake_spawn\n",
    "    )\n",
    "\n",
    "    xu = SimpleNamespace (\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "if xla_imported():\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Multi Core TPU Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.learner import _ConstantFunc\n",
    "# from fastcore.basics import patch\n",
    "# from fastai.learner import Learner\n",
    "\n",
    "@patch\n",
    "def inner_get_preds(self:Learner, ds_idx=1, dl=None, with_input=False, with_decoded=False, with_loss=False, act=None,\n",
    "                inner=False, reorder=True, cbs=None, **kwargs):\n",
    "    \n",
    "    xla_rank = getattr(self,'xla_rank',None)\n",
    "    if xla_rank is None:\n",
    "        return\n",
    "\n",
    "    if dl is None: \n",
    "        dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "    else:\n",
    "        try: len(dl)\n",
    "        except TypeError as e:\n",
    "            raise TypeError(\"`dl` is something other than a single `DataLoader` object\")\n",
    "        if not isinstance(dl, TPUDistributedDL):            \n",
    "            world_size = kwargs.pop('world_size', xm.xrt_world_size())\n",
    "            seed = kwargs.pop('dl_seed',42)\n",
    "            dl = TPUDistributedDL(dl, xla_rank, world_size=world_size, seed=seed)\n",
    "\n",
    "    if reorder and hasattr(dl, 'get_idxs'):\n",
    "        idxs = dl.dl.get_idxs()\n",
    "        dl = dl.new(get_idxs = _ConstantFunc(idxs))\n",
    "        rank_idxs = dl.get_idxs()\n",
    "        rank_idxs_len = len(rank_idxs)\n",
    "\n",
    "    cb = GatherPredsCallback(with_input=with_input, with_loss=with_loss, **kwargs)\n",
    "    ctx_mgrs = self.validation_context(cbs=L(cbs)+[cb], inner=inner)\n",
    "    if with_loss: \n",
    "        ctx_mgrs.append(self.loss_not_reduced())\n",
    "    \n",
    "    with ContextManagers(ctx_mgrs):\n",
    "        self._do_epoch_validate(dl=dl)\n",
    "       \n",
    "        if act is None: \n",
    "            act = getattr(self.loss_func, 'activation', noop)\n",
    "\n",
    "        res = cb.all_tensors()\n",
    "        \n",
    "        pred_i = 1 if with_input else 0\n",
    "        if res[pred_i] is not None:\n",
    "            if act != noop:                \n",
    "                # compute activation on tpu device and detach after\n",
    "                tmp_pred = res[pred_i].to(xm.xla_device())\n",
    "                tmp_res = act(tmp_pred)\n",
    "                res[pred_i] = self.to_detach(tmp_res)\n",
    "                \n",
    "            if with_decoded:\n",
    "                res.insert(pred_i+2, getattr(self.loss_func, 'decodes', noop)(res[pred_i]))\n",
    "\n",
    "        if reorder and hasattr(dl, 'get_idxs'):\n",
    "            t_idxs = tensor(rank_idxs)\n",
    "            start_idx = xla_rank * rank_idxs_len\n",
    "            t_idxs = t_idxs - tensor(start_idx) # broadcast\n",
    "            sorted_idxs = t_idxs.argsort()\n",
    "            res = nested_reorder(res, sorted_idxs )\n",
    "        \n",
    "        return tuple(res)\n",
    "    self._end_cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastai.learner import CancelValidException\n",
    "\n",
    "@patch\n",
    "def before_validate(self:XLATrainingCallback):\n",
    "    \"Set the model in validation mode\"\n",
    "    if not getattr(self.learn,'inner_xla',False):\n",
    "        return # skip if not spawned\n",
    "    \n",
    "    if self.rank != 0 and not self.sync_valid:\n",
    "    # no need to compute valid loss/ metric if not master if not sync valid\n",
    "        raise CancelValidException()\n",
    "\n",
    "    if not isinstance(self.learn.dl, pl.PerDeviceLoader):\n",
    "        self.learn.dl = wrap_parallel_loader(self.learn.dl, self.pdevice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def new(self:TPUDistributedDL, dataset=None, cls=None, **kwargs):\n",
    "    new_dl = self.dl.new(dataset=dataset, cls=cls, **kwargs)\n",
    "    use_rank = self.rank\n",
    "    use_size = self.world_size\n",
    "    seed = self.seed\n",
    "\n",
    "    new_dl = TPUDistributedDL(new_dl,\n",
    "                        rank=use_rank,\n",
    "                        world_size=use_size, \n",
    "                        seed=seed)\n",
    "    \n",
    "    return new_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def setup_inference_args(rank, inference_args):\n",
    "    master_cbs = ifnone(inference_args.pop('master_cbs', None),[])\n",
    "    return inference_args, master_cbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pickle\n",
    "def save_pred_results(rank, results):\n",
    "    fn = f'preds{rank}.pkl'\n",
    "    fn = Path(fn)\n",
    "    with open(fn,'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def xla_run_inference(rank, learner_args, add_args, inference_args, ctrl_args):\n",
    "    sync_valid = True\n",
    "    learner = make_xla_child_learner(rank, sync_valid, learner_args, add_args, ctrl_args)\n",
    "    pred_args, master_cbs = setup_inference_args(rank, inference_args)\n",
    "\n",
    "    if rank == 0 and len(master_cbs) > 0:\n",
    "        learner.add_cbs(master_cbs)\n",
    "\n",
    "    learner.synced_cancel.before_fit()\n",
    "\n",
    "    if rank == 0:\n",
    "        learner.sync_recorder.orig_logger = learner.logger\n",
    "\n",
    "    results = learner.inner_get_preds(**pred_args)\n",
    "    xm.rendezvous('xla_run_inference')\n",
    "\n",
    "    save_pred_results(rank, results)\n",
    "    xm.mark_step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.foundation import L\n",
    "\n",
    "def reload_pred_results(num_files, n_samples):\n",
    "    all_preds = L()\n",
    "    for rank in range(num_files):\n",
    "        fn = f'preds{rank}.pkl'\n",
    "\n",
    "        fn = Path(fn)\n",
    "        if fn.is_file():\n",
    "            with open(fn,'rb') as f:\n",
    "                rank_preds = pickle.load(f)\n",
    "                all_preds.append(rank_preds)\n",
    "        else:\n",
    "            raise RuntimeException(f'Missing preds file for rank {rank}')\n",
    "\n",
    "    for rank in range(num_files):\n",
    "        fn = f'preds{rank}.pkl'\n",
    "        fn = Path(fn)\n",
    "        fn.unlink()\n",
    "\n",
    "    n_items = len(all_preds[0]) # num items per preds\n",
    "\n",
    "    all_res = []\n",
    "    for i in range(n_items):\n",
    "        items = all_preds.itemgot(i)\n",
    "\n",
    "        if isinstance(items[0], torch.Tensor):\n",
    "            all_items = torch.cat(tuple(items))\n",
    "        elif is_listy(items[0]):\n",
    "            all_items = [*items]\n",
    "        else:\n",
    "            all_items = items\n",
    "        all_res.append(all_items)\n",
    "    res = []\n",
    "    for i, pred in enumerate(all_res):\n",
    "        pred = pred[:n_samples] # take only first \n",
    "        res.append(pred)  \n",
    "    return res\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def pre_xla_inference(self:Learner):\n",
    "    ctrl_args = {}\n",
    "    progress_removed = False\n",
    "    if 'progress' in L(self.cbs).attrgot('name'):\n",
    "        self.remove_cbs(ProgressCallback)\n",
    "        progress_removed = True\n",
    "    ctrl_args['use_progress'] = progress_removed\n",
    "    return ctrl_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def post_xla_inference(self:Learner, ctrl_args):\n",
    "    if ctrl_args['use_progress']:\n",
    "        self.add_cbs(ProgressCallback)\n",
    "    self.recorder.reload_attrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def prep_inference_args(**kwargs):\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#export\n",
    "\n",
    "@patch\n",
    "@delegates(Learner.get_preds, but='num_cores,start_method,master_cbs')\n",
    "def xla_get_preds(self:Learner, ds_idx=1, dl=None, \n",
    "                  with_input=False, with_decoded=False, \n",
    "                  with_loss=False, act=None, inner=False, \n",
    "                  reorder=True, cbs=None, num_cores=8, \n",
    "                  start_method='fork', master_cbs=None,**kwargs):\n",
    "    ctrl_args = self.pre_xla_inference()\n",
    "    learner_args, add_args = self.pack_learner_args()\n",
    "\n",
    "    inference_args = prep_inference_args(ds_idx=ds_idx, dl=dl, \n",
    "                                         with_input=with_input, with_decoded=with_decoded, \n",
    "                                         with_loss=with_loss,\n",
    "                                         act=act, inner=inner, \n",
    "                                         reorder=reorder, \n",
    "                                         cbs=cbs, master_cbs=master_cbs, **kwargs)\n",
    "    if dl:\n",
    "        n_results = len(dl.dataset)\n",
    "    else:\n",
    "        n_results = len(self.dls.loaders[ds_idx].dataset)\n",
    "\n",
    "    xmp.spawn(xla_run_inference,\n",
    "              args=(learner_args, add_args, inference_args, ctrl_args),\n",
    "              nprocs=num_cores,\n",
    "              start_method=start_method)\n",
    "\n",
    "    all_results = reload_pred_results(num_cores, n_results)\n",
    "    self.post_xla_inference(ctrl_args)\n",
    "    return all_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "path = untar_data(URLs.MNIST)\n",
    "# path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock,CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "    item_tfms=Resize(28),\n",
    "    batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n",
    ")\n",
    "# pat = r'(.+)_\\d+.jpg$'\n",
    "# data = DataBlock(\n",
    "#     blocks=(ImageBlock,CategoryBlock),\n",
    "#     get_items=get_image_files,\n",
    "#     get_y=using_attr(RegexLabeller(pat),'name'),\n",
    "#     splitter=RandomSplitter(seed=42),\n",
    "#     item_tfms=Resize(224),\n",
    "#     batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "dls = data.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# loss_func=nn.CrossEntropyLoss()\n",
    "loss_func=CrossEntropyLossFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9db52010db4822a12ee38e0091c004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "learner = cnn_learner(dls, resnet18, metrics=accuracy, loss_func=loss_func, concat_pool=False)\n",
    "# learner = cnn_learner(dls, resnet34, metrics=accuracy, loss_func=loss_func, concat_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.557177</td>\n",
       "      <td>0.198589</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.229188</td>\n",
       "      <td>0.099969</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.141549</td>\n",
       "      <td>0.079136</td>\n",
       "      <td>0.974500</td>\n",
       "      <td>02:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "learner.xla_fit_one_cycle(3, lr_max=slice(3e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load('pets-stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('pets-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.087690</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.058692</td>\n",
       "      <td>0.069429</td>\n",
       "      <td>0.977200</td>\n",
       "      <td>02:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.080852</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>0.980700</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086271</td>\n",
       "      <td>0.059273</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077349</td>\n",
       "      <td>0.055652</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>03:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "learner.xla_fit_one_cycle(5,lr_max=slice(1e-6,2e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.save('pets-stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.2 s, sys: 1.09 s, total: 39.3 s\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "res = learner.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10000, 10]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(res))\n",
    "print(res[0].shape, res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9813)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "res[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 1.02 s, total: 38.8 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "res2 = learner.get_preds(reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10000, 10]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(res2))\n",
    "print(res2[0].shape, res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "res2[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9813)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "CPU times: user 187 ms, sys: 153 ms, total: 340 ms\n",
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "xla_res = learner.xla_get_preds(reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(xla_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]), torch.Size([10000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "(xla_res[0].shape, xla_res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.3227e-05, 9.9777e-01, 1.8993e-05, 1.4147e-05, 4.4221e-04, 4.3196e-04,\n",
       "         1.2528e-04, 1.8559e-04, 7.8385e-04, 1.5749e-04],\n",
       "        [3.7930e-06, 9.9990e-01, 1.0723e-06, 1.7454e-06, 1.3211e-05, 9.3661e-06,\n",
       "         2.8669e-06, 2.6495e-05, 4.4178e-05, 1.5767e-06],\n",
       "        [1.5091e-04, 9.9920e-01, 1.1045e-04, 5.1943e-05, 4.7102e-05, 1.9531e-05,\n",
       "         2.2440e-04, 1.1227e-04, 5.6824e-05, 2.4695e-05],\n",
       "        [1.0292e-05, 9.9979e-01, 1.9649e-05, 1.1793e-06, 1.8352e-05, 3.1917e-06,\n",
       "         7.2904e-06, 1.9972e-05, 1.1706e-04, 8.7981e-06],\n",
       "        [7.8981e-06, 9.9990e-01, 9.7631e-06, 2.2887e-06, 1.3191e-05, 2.5938e-06,\n",
       "         2.3175e-05, 2.3824e-05, 1.0166e-05, 2.3397e-06],\n",
       "        [3.0717e-05, 9.9962e-01, 4.3642e-05, 1.5713e-05, 3.4024e-05, 3.8474e-05,\n",
       "         1.2209e-04, 6.3268e-05, 1.3420e-05, 1.9892e-05],\n",
       "        [1.3539e-04, 9.9956e-01, 4.1930e-06, 1.8683e-06, 1.1204e-05, 2.9642e-06,\n",
       "         2.3243e-04, 1.3482e-05, 3.8045e-05, 3.7877e-06],\n",
       "        [1.4129e-06, 9.9996e-01, 8.9221e-08, 9.7131e-08, 1.0073e-05, 1.2251e-06,\n",
       "         1.9130e-05, 5.8627e-07, 4.2511e-06, 1.2738e-06],\n",
       "        [3.5239e-06, 9.9956e-01, 9.9273e-05, 1.3171e-05, 1.1879e-04, 2.2539e-05,\n",
       "         6.6234e-05, 4.8836e-05, 2.5220e-05, 4.6666e-05],\n",
       "        [1.2536e-05, 9.9991e-01, 2.0382e-07, 4.0083e-07, 1.1834e-05, 7.1591e-06,\n",
       "         4.6859e-06, 4.6123e-05, 7.2919e-06, 1.8044e-06]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9825)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*xla_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "CPU times: user 160 ms, sys: 272 ms, total: 431 ms\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "xla_res2 = learner.xla_get_preds(reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(len(xla_res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10]), torch.Size([10000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "(xla_res2[0].shape, xla_res2[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res2[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.3227e-05, 9.9777e-01, 1.8993e-05, 1.4147e-05, 4.4221e-04, 4.3196e-04,\n",
       "         1.2528e-04, 1.8559e-04, 7.8385e-04, 1.5749e-04],\n",
       "        [3.7930e-06, 9.9990e-01, 1.0723e-06, 1.7454e-06, 1.3211e-05, 9.3661e-06,\n",
       "         2.8669e-06, 2.6495e-05, 4.4178e-05, 1.5767e-06],\n",
       "        [1.5091e-04, 9.9920e-01, 1.1045e-04, 5.1943e-05, 4.7102e-05, 1.9531e-05,\n",
       "         2.2440e-04, 1.1227e-04, 5.6824e-05, 2.4695e-05],\n",
       "        [1.0292e-05, 9.9979e-01, 1.9649e-05, 1.1793e-06, 1.8352e-05, 3.1917e-06,\n",
       "         7.2904e-06, 1.9972e-05, 1.1706e-04, 8.7981e-06],\n",
       "        [7.8981e-06, 9.9990e-01, 9.7631e-06, 2.2887e-06, 1.3191e-05, 2.5938e-06,\n",
       "         2.3175e-05, 2.3824e-05, 1.0166e-05, 2.3397e-06],\n",
       "        [3.0717e-05, 9.9962e-01, 4.3642e-05, 1.5713e-05, 3.4024e-05, 3.8474e-05,\n",
       "         1.2209e-04, 6.3268e-05, 1.3420e-05, 1.9892e-05],\n",
       "        [1.3539e-04, 9.9956e-01, 4.1930e-06, 1.8683e-06, 1.1204e-05, 2.9642e-06,\n",
       "         2.3243e-04, 1.3482e-05, 3.8045e-05, 3.7877e-06],\n",
       "        [1.4129e-06, 9.9996e-01, 8.9221e-08, 9.7131e-08, 1.0073e-05, 1.2251e-06,\n",
       "         1.9130e-05, 5.8627e-07, 4.2511e-06, 1.2738e-06],\n",
       "        [3.5239e-06, 9.9956e-01, 9.9273e-05, 1.3171e-05, 1.1879e-04, 2.2539e-05,\n",
       "         6.6234e-05, 4.8836e-05, 2.5220e-05, 4.6666e-05],\n",
       "        [1.2536e-05, 9.9991e-01, 2.0382e-07, 4.0083e-07, 1.1834e-05, 7.1591e-06,\n",
       "         4.6859e-06, 4.6123e-05, 7.2919e-06, 1.8044e-06]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "xla_res2[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase(0.9825)\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "print(accuracy(*xla_res2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
