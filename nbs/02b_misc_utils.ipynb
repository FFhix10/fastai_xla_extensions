{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/02b_misc_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp misc_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 100kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 6.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.0+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.8.1+cu101\n",
      "fastai==2.2.5\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch the fastai `_BaseOptimizer` to be Pickable\n",
    "Patch the `fastai.optimizer._BaseOptimizer` `__getstate__` and `__setstate__` methods which are used in pickling fastai optimizers. \n",
    "\n",
    "This should fix the bug where running the learner on multiple TPU cores on XLA triggers an error in which the method `_fetch_gradients(optimizer)` fails in the statement `for param_group in optimizer.__getstate__()['param_groups']:` in the  `torch_xla.core.xla_model` module. \n",
    "\n",
    "The patch modifies the copy constructor to include the param_groups and defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.optimizer import _BaseOptimizer\n",
    "from fastcore.basics import patch\n",
    "\n",
    "@patch\n",
    "def __getstate__(self:_BaseOptimizer):\n",
    "    \"Pickling opt state should include `param_groups` and `defaults` \"\n",
    "    d = {\n",
    "            'state': self.state_dict(),\n",
    "            'param_groups': self.param_groups,\n",
    "        }\n",
    "    if hasattr(self,'defaults'):\n",
    "        d['defaults'] = self.defaults\n",
    "    return d\n",
    "\n",
    "@patch\n",
    "def __setstate__(self:_BaseOptimizer, data):\n",
    "    \"Pickling opt state should include `param_groups` and `defaults` \"\n",
    "\n",
    "    if 'defaults' in data:\n",
    "        self.defaults = data['defaults']\n",
    "    self.load_state_dict(data['state'])\n",
    "    self.param_groups = data['param_groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "#colab\n",
    "show_doc(_BaseOptimizer.__getstate__)\n",
    "show_doc(_BaseOptimizer.__setstate__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#TODO add tests for pickling optimizers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
