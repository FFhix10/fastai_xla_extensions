{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# attach gdrive holding repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multi_core.torch_compat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Compatible Utilities\n",
    "\n",
    "> Torch Dataset and Dataloader compatible classes and functions for multi-core TPU training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/03a_multi_core.torch_compat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 133.6MB 43kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 194kB 6.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# !pip install -Uqq git+https://github.com/fastai/fastai.git \n",
    "!pip install -Uqq fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for my-timesaver-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "# get profiling utils and callback\n",
    "!pip install -Uqq git+https://github.com/butchland/my_timesaver_utils.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r\u001b[K     |███████▏                        | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.0MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!pip install -qqq nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating fastai...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "!curl -s https://course19.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==1.7.0+cu101\n",
      "torch-xla==1.7\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.8.1+cu101\n",
      "fastai==2.2.5\n",
      "fastcore==1.3.19\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n",
      "my-timesaver-utils==0.0.2\n",
      "nbdev==1.1.12\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip freeze | grep torch\n",
    "!pip freeze | grep fast\n",
    "!pip freeze | grep timesaver\n",
    "!pip freeze | grep nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content\n",
    "!ln -s /content/drive/MyDrive/fastai_xla_extensions fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Start of kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/fastai_xla_extensions\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content/fastai_xla_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
      "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
     ]
    }
   ],
   "source": [
    "#exporti\n",
    "from fastai_xla_extensions.utils import xla_imported\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "from fastai_xla_extensions.misc_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "try:\n",
    "    import torch_xla\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "if not xla_imported():\n",
    "    # replace torch xla modules with fake equivalents\n",
    "    from types import SimpleNamespace\n",
    "    torch_xla = SimpleNamespace (\n",
    "    )\n",
    "    from typing import Union,BinaryIO\n",
    "    import os\n",
    "    import pickle\n",
    "    import torch.cuda\n",
    "\n",
    "    def fake_opt_step(opt,barrier=False):\n",
    "        opt.step()\n",
    "        \n",
    "    def fake_device(n=None, devkind=None):\n",
    "        gpu_available = torch.cuda.is_available()\n",
    "        if gpu_available:\n",
    "            return torch.device(torch.cuda.current_device()) \n",
    "        return torch.device('cpu')\n",
    "\n",
    "    def fake_save(obj, f: Union[str, os.PathLike, BinaryIO], \n",
    "                master_only=True, global_master=False): \n",
    "        return torch.save(obj,f,pickle_module=pickle, \n",
    "                        pickle_protocol=2, \n",
    "                        _use_new_zipfile_serialization=True)\n",
    "    def fake_rate():\n",
    "        return 230.20\n",
    "\n",
    "    def fake_global_rate():\n",
    "        return 830.10\n",
    "\n",
    "    def fake_add(*args,**kwargs):\n",
    "        pass\n",
    "\n",
    "    def fake_RateTracker():\n",
    "        return SimpleNamespace(\n",
    "            rate = fake_rate,\n",
    "            global_rate = fake_global_rate,\n",
    "            add = fake_add\n",
    "        )\n",
    "    def fake_xrt_world_size():\n",
    "        return 1\n",
    "    def fake_get_ordinal():\n",
    "        return 0\n",
    "    xm = SimpleNamespace(\n",
    "        optimizer_step = fake_opt_step,\n",
    "        xla_device = fake_device,\n",
    "        save = fake_save,\n",
    "        RateTracker = fake_RateTracker,\n",
    "        master_print = print,\n",
    "        xrt_world_size = fake_xrt_world_size,\n",
    "        get_ordinal = fake_get_ordinal\n",
    "    )\n",
    "\n",
    "    def fake_metrics_report():\n",
    "        return \"Fake Metrics Report \\n\\n\\n\\n\"\n",
    "    met = SimpleNamespace (\n",
    "        metrics_report = fake_metrics_report\n",
    "    )\n",
    "\n",
    "    class FakeParallelLoader:\n",
    "        def __init__(self, loader, *args):\n",
    "            self.loader = loader\n",
    "        def per_device_loader(self,device):\n",
    "            return self.loader\n",
    "        \n",
    "    pl = SimpleNamespace(\n",
    "        ParallelLoader = FakeParallelLoader\n",
    "    )\n",
    "\n",
    "    def fake_MpModelWrapper(o):\n",
    "        return o\n",
    "\n",
    "    def fake_run(f,*args, **kwargs):\n",
    "            return f(*args,**kwargs)\n",
    "        \n",
    "    def fake_MpSerialExecutor():\n",
    "        return SimpleNamespace(\n",
    "            run = fake_run\n",
    "        )\n",
    "    def fake_spawn(f, args=None, nprocs=0, start_method=None):\n",
    "        return f(0,*args)\n",
    "\n",
    "    xmp = SimpleNamespace (\n",
    "        MpModelWrapper = fake_MpModelWrapper,\n",
    "        MpSerialExecutor = fake_MpSerialExecutor,\n",
    "        spawn = fake_spawn\n",
    "    )\n",
    "\n",
    "    xu = SimpleNamespace (\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "if xla_imported():\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from fastcore.basics import patch_to\n",
    "import torch\n",
    "import torch.utils.data as th_data\n",
    "from fastcore.foundation import L\n",
    "from pathlib import Path\n",
    "from fastcore.transform import Pipeline\n",
    "from fastai.data.core import DataLoaders\n",
    "from pathlib import Path\n",
    "from fastai.torch_core import find_bs, TensorBase\n",
    "from fastai.torch_core import TensorBase\n",
    "from fastcore.xtras import is_listy\n",
    "import torch.utils.hooks\n",
    "import torch.utils.data.distributed as th_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdTorchDS(th_data.Dataset):\n",
    "    \"A torch dataset compatible holder for items with x and y transforms\"\n",
    "    def __init__(self, items, x_tfm=None, y_tfm=None):\n",
    "        self.items = items\n",
    "        self.x_tfm = x_tfm\n",
    "        self.y_tfm = y_tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.items[index]\n",
    "        x = self.x_tfm(item) if self.x_tfm is not None else item\n",
    "        y = self.y_tfm(item) if self.y_tfm is not None else item\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "def neg_tfm(o): return -o\n",
    "def double_tfm(o): return 2*o\n",
    "items = list(range(10))\n",
    "ds1 = TfmdTorchDS(items, x_tfm=neg_tfm, y_tfm=double_tfm)\n",
    "test_eq(ds1[5],(-5,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import torchvision as thv\n",
    "from operator import itemgetter\n",
    "from fastcore.imports import noop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_list(o):\n",
    "    \"return item o as a list (unchanged if o is already a list and empty list if o is None)\"\n",
    "    return [] if o is None else [o] if not is_listy(o) else o\n",
    "\n",
    "def has_setup(tfms):\n",
    "    \"\"\"returns last index if at least 1 `tfm` in `tfms` has a method `setup` else return -1\"\"\"\n",
    "    setups = L(tfms).attrgot('setup',None).argwhere(noop) # get indexes where tfm has `setup` attribute\n",
    "    return -1 if len(setups) == 0 else setups[-1]\n",
    "\n",
    "def run_setups(tfms, items):\n",
    "    \"\"\"run tfm setups including tfm for all items\"\"\"\n",
    "    indx = has_setup(tfms)\n",
    "    if indx == -1: # no setup found\n",
    "        return\n",
    "\n",
    "    for i,tfm in enumerate(tfms):\n",
    "        if hasattr(tfm,'setup'):\n",
    "            tfm.setup(items)\n",
    "        if i < indx:\n",
    "            # tfm items to be fed into next tfm\n",
    "            items = [tfm(item) for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TorchDatasetBuilder:\n",
    "    \"build torch compatible train and test datasets with transforms\"\n",
    "    def __init__(self, source, get_items, splitter,\n",
    "                x_tfms, y_tfms,\n",
    "                x_type_tfms=None,\n",
    "                x_train_tfms=None, x_test_tfms=None,\n",
    "                do_setup=False):\n",
    "        self.source = source\n",
    "        self.get_items = get_items\n",
    "        self.splitter = splitter\n",
    "        self.do_setup = do_setup\n",
    "        self.x_tfms = to_list(x_tfms)\n",
    "        self.y_tfms = to_list(y_tfms)\n",
    "        self.x_type_tfms = to_list(x_type_tfms)\n",
    "        self.x_train_tfms = to_list(x_train_tfms)\n",
    "        self.x_test_tfms = to_list(x_test_tfms)\n",
    "\n",
    "    def setup(self, items, do_setup=None, setup_x=False):\n",
    "        self.do_setup = do_setup if do_setup is not None else self.do_setup\n",
    "        if self.do_setup:\n",
    "            all_x_tfms = [*self.x_type_tfms, *self.x_train_tfms, *self.x_tfms]\n",
    "            if setup_x:\n",
    "                run_setups(all_x_tfms, items)\n",
    "            run_setups(self.y_tfms, items)\n",
    "            self.do_setup = False\n",
    "\n",
    "    def get_datasets(self, do_setup=None):\n",
    "        self.do_setup = do_setup if do_setup is not None else self.do_setup\n",
    "\n",
    "        items = self.get_items(self.source) if self.get_items is not None else self.source\n",
    "\n",
    "        train_idxs, test_idxs = self.splitter(items)\n",
    "\n",
    "        train_items = itemgetter(*train_idxs)(items)\n",
    "        test_items = itemgetter(*test_idxs)(items)\n",
    "        self.setup(train_items)\n",
    "        allx_test_tfms = [*self.x_type_tfms, *self.x_test_tfms, *self.x_tfms]\n",
    "        allx_train_tfms = [*self.x_type_tfms, *self.x_train_tfms, *self.x_tfms]\n",
    "        train_x_tfm = thv.transforms.Compose(allx_train_tfms)\n",
    "        test_x_tfm = thv.transforms.Compose(allx_test_tfms)\n",
    "        y_tfm = thv.transforms.Compose(self.y_tfms)\n",
    "        train_ds = TfmdTorchDS(train_items, x_tfm=train_x_tfm, y_tfm=y_tfm)\n",
    "        test_ds = TfmdTorchDS(test_items, x_tfm=test_x_tfm, y_tfm=y_tfm)\n",
    "        return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.transforms import CategoryMap\n",
    "\n",
    "class VocabularyMapper:\n",
    "    \"\"\"A simplified version of the fastai Categorize Transform\"\"\"\n",
    "    def __init__(self, vocab=None):\n",
    "        self.vocab = vocab\n",
    "        self.c = 0\n",
    "    def setup(self, items):\n",
    "        self.vocab = CategoryMap(items)\n",
    "        self.c = len(self.vocab)\n",
    "    def __call__(self, o):\n",
    "        if self.vocab is None: return o\n",
    "        try:\n",
    "            return torch.tensor(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision as thv\n",
    "\n",
    "pil2tensor = thv.transforms.ToTensor()\n",
    "resize28 = thv.transforms.Resize(28)\n",
    "norm = thv.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "\n",
    "from fastai.vision.core import PILImage\n",
    "from fastai.data.transforms import get_image_files, GrandparentSplitter, parent_label\n",
    "from fastai.data.external import untar_data, URLs\n",
    "\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "mnist_dset_builder =  TorchDatasetBuilder(\n",
    "                source=path, \n",
    "                get_items=get_image_files, \n",
    "                splitter=GrandparentSplitter(),\n",
    "                x_tfms=[resize28,pil2tensor,norm,], \n",
    "                y_tfms=[parent_label,VocabularyMapper(),],\n",
    "                x_type_tfms=PILImage.create)\n",
    "\n",
    "from fastcore.test import test_eq\n",
    "\n",
    "train_ds, test_ds = mnist_dset_builder.get_datasets(do_setup=True)\n",
    "\n",
    "test_eq(len(train_ds),709)\n",
    "test_eq(len(test_ds),699)\n",
    "test_eq(mnist_dset_builder.y_tfms[1].vocab, ('3','7'))\n",
    "test_eq(mnist_dset_builder.y_tfms[1].c, 2)\n",
    "test_eq(train_ds[0][1],mnist_dset_builder.y_tfms[1](parent_label(train_ds.items[0])))\n",
    "test_eq(train_ds[0][0],norm(pil2tensor(resize28(PILImage.create(train_ds.items[0])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.utils.data as th_data\n",
    "from fastcore.basics import patch_to\n",
    "@patch_to(th_data.DataLoader)\n",
    "def to(self, device):\n",
    "    \"move torch dataloader to device (for compatibility with fastai dataloader)\"\n",
    "    self.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"DataLoader.to\" class=\"doc_header\"><code>DataLoader.to</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>DataLoader.to</code>(**`device`**)\n\nmove torch dataloader to device (for compatibility with fastai dataloader)",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "#colab\n",
    "show_doc(th_data.DataLoader.to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_torch_dataloaders(train_dataset, test_dataset,\n",
    "                     rank,\n",
    "                     world_size,\n",
    "                     bs,\n",
    "                     num_workers=4,\n",
    "                     distrib=True,\n",
    "                     sync_valid=False):\n",
    "    \"make torch-based distributed dataloaders from torch compatible datasets\"\n",
    "    if distrib:\n",
    "        train_sampler = th_distrib.DistributedSampler(\n",
    "            train_dataset,\n",
    "            num_replicas=world_size,\n",
    "            rank=rank,\n",
    "            shuffle=True)\n",
    "        train_loader = th_data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=bs,\n",
    "            sampler=train_sampler,\n",
    "            # shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "        if sync_valid:\n",
    "            test_sampler = th_distrib.DistributedSampler(\n",
    "                test_dataset,\n",
    "                num_replicas=world_size,\n",
    "                rank=rank,\n",
    "                shuffle=False)\n",
    "\n",
    "            test_loader = th_data.DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=bs,\n",
    "                sampler=test_sampler,\n",
    "                # shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                drop_last=True)\n",
    "        else:\n",
    "            test_loader = th_data.DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=bs,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                drop_last=True)\n",
    "\n",
    "    else:\n",
    "        train_loader = th_data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=bs,\n",
    "            # sampler=train_sampler,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "        test_loader = th_data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=bs,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True)\n",
    "    dataloaders = DataLoaders(train_loader, test_loader, device=None)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FileNamePatternLabeller:\n",
    "    \"Delayed action version of fastai RegexLabeller with file name selection\"\n",
    "    def __init__(self, pat_str, match=False):\n",
    "        self.pat_str = pat_str\n",
    "        self.match = match\n",
    "        self.matcher = None\n",
    "        self.pat = None\n",
    "    def __call__(self, f):\n",
    "        if isinstance(f,str):\n",
    "            f = Path(f)\n",
    "        o = f.name\n",
    "        if self.pat is None:\n",
    "            self.pat = re.compile(self.pat_str)\n",
    "            self.matcher = self.pat.match if self.match else self.pat.search\n",
    "        res  = self.matcher(o)\n",
    "        assert res, f'Failed to find \"{self.pat}\" in {o}'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Training using Torch Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "from fastai.vision.all import *\n",
    "from fastai_xla_extensions.multi_core.base import *\n",
    "from fastai_xla_extensions.misc_utils import * # patch _BaseOptimizer.__get_state__ and __setstate__\n",
    "from my_timesaver_utils.profiling import *\n",
    "from my_timesaver_utils.profiling_callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#colab\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "def train_torch_model(rank):\n",
    "    torch.manual_seed(1)\n",
    "    xm.rendezvous('start_train_torch_model')\n",
    "    # Scale learning rate to num cores\n",
    "    learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
    "    IS_PROFILING = FLAGS['is_profiling']\n",
    "    SYNC_VALID = FLAGS['sync_valid']\n",
    "\n",
    "    # Get loss function, optimizer, and model\n",
    "    device = xm.xla_device()\n",
    "    model = WRAPPED_MODEL.to(device)\n",
    "    bs = FLAGS['batch_size']\n",
    "    world_size = xm.xrt_world_size()\n",
    "    moms =(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum'])\n",
    "    wd = FLAGS['weight_decay']\n",
    "    num_workers = FLAGS['num_workers']\n",
    "\n",
    "    if IS_PROFILING:\n",
    "        rec_name = 'rank' + str(rank) + '_dset_build'\n",
    "        print(f'start {rec_name}')\n",
    "        start_record(rec_name)\n",
    "    dsets = DSET_BUILDER.get_datasets()\n",
    "    if IS_PROFILING:\n",
    "        end_record(rec_name)\n",
    "        print_prof_data(rec_name)\n",
    "        print(f'finished {rec_name}')\n",
    "\n",
    "    if IS_PROFILING:\n",
    "        rec_name2 = 'rank' + str(rank) + '_dataloader_build'\n",
    "        print(f'start {rec_name2}')\n",
    "        start_record(rec_name2)\n",
    "    dls = make_torch_dataloaders(*dsets, \n",
    "                                  rank=rank, \n",
    "                                  world_size=world_size, \n",
    "                                  bs=bs,\n",
    "                                  num_workers=num_workers,\n",
    "                                  sync_valid=SYNC_VALID,\n",
    "                                 )\n",
    "\n",
    "    if IS_PROFILING:\n",
    "        end_record(rec_name2)\n",
    "        print_prof_data(rec_name2)\n",
    "        print(f'finished {rec_name2}')\n",
    "\n",
    "    xm.master_print('build learner')\n",
    "    learner = Learner(dls, model, \n",
    "                      loss_func=LOSS_FUNC, \n",
    "                      opt_func=OPT_FUNC, \n",
    "                      metrics=accuracy, \n",
    "                      wd=wd,\n",
    "                      moms=moms\n",
    "                      )\n",
    "                      \n",
    "    learner.to_multi_xla(device, rank=xm.get_ordinal(), sync_valid=SYNC_VALID)\n",
    "    if rank == 0 and IS_PROFILING:\n",
    "        learner.to_my_profile()\n",
    "                               \n",
    "    epochs = FLAGS['num_epochs']\n",
    "    xm.master_print('start running fit')\n",
    "    learner.unfreeze()\n",
    "\n",
    "    if IS_PROFILING:\n",
    "        rec_name3 = 'rank' + str(rank) + '_run_fit'\n",
    "        print(f'start {rec_name3}')\n",
    "        start_record(rec_name3)\n",
    "    learner.fit_one_cycle(epochs, lr_max=slice(learning_rate/10))\n",
    "\n",
    "    if IS_PROFILING:\n",
    "        end_record(rec_name3)\n",
    "        print_prof_data(rec_name3)\n",
    "        print(f'finished {rec_name3}')\n",
    "\n",
    "    learner.save('stage-1')\n",
    "    if rank == 0 and IS_PROFILING:\n",
    "        learner.my_profile.print_stats()\n",
    "    xm.mark_step() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# Start training processes\n",
    "def _mp_fn2(rank, flags):\n",
    "    global FLAGS\n",
    "    FLAGS = flags\n",
    "    train_torch_model(rank)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastcore.transform import DisplayedTransform, Transform\n",
    "from fastcore.basics import store_attr\n",
    "from fastai.vision.core import PILImage, PILBase, image2tensor\n",
    "from fastai.data.block import TransformBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import get_c\n",
    "# from fastai.vision.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.data.transforms import get_image_files, parent_label, GrandparentSplitter\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.data.transforms import Normalize\n",
    "from fastai.vision.core import imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "LOSS_FUNC = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.optimizer import Adam\n",
    "OPT_FUNC = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.learner import create_cnn_model\n",
    "from fastai.vision.models import resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "# FLAGS['batch_size'] = 1024\n",
    "FLAGS['sync_valid'] = True\n",
    "FLAGS['is_profiling'] = True\n",
    "FLAGS['batch_size'] = 64\n",
    "FLAGS['num_workers'] = 4\n",
    "FLAGS['learning_rate'] = 1e-3\n",
    "FLAGS['image_size'] = 224\n",
    "FLAGS['momentum'] = 0.85\n",
    "FLAGS['weight_decay'] = 2e-3\n",
    "FLAGS['num_epochs'] = 5\n",
    "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
    "\n",
    "# FLAGS['num_cores'] = 1 \n",
    "ARCH = resnet34\n",
    "USE_DBLOCK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastcore.xtras import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#colab\n",
    "PATH = untar_data(URLs.PETS)/'images'\n",
    "# PATH = untar_data(URLs.MNIST)\n",
    "# PATH = untar_data(URLs.MNIST_TINY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function master_vocab_setup called 1 times.\n",
      "Execution time max: 0.055, average: 0.055\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "imagenet_norm = thv.transforms.Normalize(\n",
    "    mean=(0.485, 0.456, 0.406), \n",
    "    std=(0.229, 0.224, 0.225))\n",
    "\n",
    "cifar_norm = thv.transforms.Normalize(\n",
    "    mean=(0.4914, 0.4822, 0.4465), \n",
    "    std=(0.2023, 0.1994, 0.2010))\n",
    "\n",
    "image_size = FLAGS['image_size']\n",
    "splitter = RandomSplitter(seed=42)\n",
    "pat = r'(.+)_\\d+.jpg$'\n",
    "fname_labeller = FileNamePatternLabeller(pat)\n",
    "\n",
    "DSET_BUILDER = TorchDatasetBuilder(\n",
    "    PATH, \n",
    "    get_items=get_image_files,\n",
    "    splitter=splitter,\n",
    "    x_tfms=[thv.transforms.Resize((image_size,image_size)), thv.transforms.ToTensor(), imagenet_norm],\n",
    "    y_tfms=[fname_labeller, VocabularyMapper(),],\n",
    "    x_type_tfms=PILImage.create,\n",
    ") \n",
    "start_record('master_vocab_setup')\n",
    "DSET_BUILDER.setup(get_image_files(PATH),do_setup=True)\n",
    "end_record('master_vocab_setup')\n",
    "print_prof_data('master_vocab_setup')\n",
    "clear_prof_data()\n",
    "N_OUT = DSET_BUILDER.y_tfms[1].c     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "assert N_OUT is not None and N_OUT > 0,f'N_OUT {N_OUT} should be > 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c9d5f6eb5f4fc7a1b62acd34b4d384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "custom_model = create_cnn_model(ARCH, N_OUT, \n",
    "                                pretrained=True,\n",
    "                                concat_pool=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "# Only instantiate model weights once in memory.\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build learner\n",
      "start running fit\n",
      "start fit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.790961</td>\n",
       "      <td>1.388766</td>\n",
       "      <td>0.628906</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.661789</td>\n",
       "      <td>1.147588</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.602246</td>\n",
       "      <td>0.583778</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505505</td>\n",
       "      <td>0.392288</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.421940</td>\n",
       "      <td>0.340927</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 131 ms, total: 243 ms\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "FLAGS['is_profiling'] = False\n",
    "# !rm -f /content/models/stage-1.pth\n",
    "xmp.spawn(_mp_fn2, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
    "        start_method='fork')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "mdsets = DSET_BUILDER.get_datasets()\n",
    "mdls = make_torch_dataloaders(*mdsets,\n",
    "                                rank=0,\n",
    "                                world_size=1,\n",
    "                                bs=FLAGS['batch_size'],\n",
    "                                num_workers=FLAGS['num_workers']\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "mlearner = Learner(mdls, custom_model, \n",
    "                    loss_func=LOSS_FUNC, \n",
    "                    opt_func=OPT_FUNC, \n",
    "                    metrics=accuracy, \n",
    "                    wd=FLAGS['weight_decay'],\n",
    "                    moms=(FLAGS['momentum'],FLAGS['momentum'],FLAGS['momentum']))\n",
    "mlearner.load('stage-1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab\n",
    "mlearner.dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import one_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "one_param(mlearner.model).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2993701994419098, 0.901494562625885]\n",
      "CPU times: user 3min 30s, sys: 3.18 s, total: 3min 33s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "#colab\n",
    "%%time\n",
    "valid_metrics = mlearner.validate();print(valid_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
