---

title: Miscellaneous Utilities


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/02b_misc_utils.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02b_misc_utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/02b_misc_utils.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="_BaseOptimizer-patches"><code>_BaseOptimizer</code> patches<a class="anchor-link" href="#_BaseOptimizer-patches"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="_BaseOptimizer.__getstate__" class="doc_header"><code>_BaseOptimizer.__getstate__</code><a href="__main__.py#L5" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>_BaseOptimizer.__getstate__</code>()</p>
</blockquote>
<p>Pickling opt state should include <code>param_groups</code> and <code>defaults</code></p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="_BaseOptimizer.__setstate__" class="doc_header"><code>_BaseOptimizer.__setstate__</code><a href="__main__.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>_BaseOptimizer.__setstate__</code>(<strong><code>data</code></strong>)</p>
</blockquote>
<p>Pickling opt state should include <code>param_groups</code> and <code>defaults</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Patch the <code>fastai.optimizer._BaseOptimizer</code> <code>__getstate__</code> and <code>__setstate__</code> methods which are used in pickling fastai optimizers.</p>
<p>This should fix the bug where running the learner on multiple TPU cores on XLA triggers an error in which the method <code>_fetch_gradients(optimizer)</code> fails in the statement <code>for param_group in optimizer.__getstate__()['param_groups']:</code> in the  <code>torch_xla.core.xla_model</code> module.</p>
<p>The patch modifies the copy constructor to include the param_groups and defaults.</p>

</div>
</div>
</div>
</div>
 

