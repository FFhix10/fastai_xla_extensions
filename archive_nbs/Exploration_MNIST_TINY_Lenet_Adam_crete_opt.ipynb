{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Exploration_MNIST_TINY_Lenet_Adam_Callback.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyoc213/fastai_xla_extensions/blob/explorations1/explore_nbs/Exploration_MNIST_TINY_Lenet_Adam_crete_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "nRmNYNMVw3MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "bd4a4f4a-2b5c-45d6-e27b-40d30b84efc6"
      },
      "source": [
        "VERSION = \"20200707\" #\"nightly\"  #\"20200515\" @param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4994  100  4994    0     0  60168      0 --:--:-- --:--:-- --:--:-- 60168\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Uninstalling torch-1.6.0a0+bf2bbd9:\n",
            "  Successfully uninstalled torch-1.6.0a0+bf2bbd9\n",
            "Uninstalling torchvision-0.7.0a0+a6073f0:\n",
            "  Successfully uninstalled torchvision-0.7.0a0+a6073f0\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "| [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "| [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Done updating TPU runtime\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n",
            "\u001b[31mERROR: fastai2 0.0.18 requires torchvision>=0.5, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+2b2085a\n",
            "    Uninstalling torch-xla-1.6+2b2085a:\n",
            "      Successfully uninstalled torch-xla-1.6+2b2085a\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ld07OxDfw3Mh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "058795c9-e2fc-4a83-d316-91c98dd876dc"
      },
      "source": [
        "!pip install https://github.com/fastai/fastcore/archive/master.zip\n",
        "!pip install https://github.com/fastai/fastai2/archive/master.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/fastai/fastcore/archive/master.zip\n",
            "  Using cached https://github.com/fastai/fastcore/archive/master.zip\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastcore==0.1.18 from https://github.com/fastai/fastcore/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7' in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.18) (0.7)\n",
            "Building wheels for collected packages: fastcore\n",
            "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastcore: filename=fastcore-0.1.18-cp36-none-any.whl size=28891 sha256=de681502a9e9d80e3392802b255ecda49ab0c2498fd9979eca93cd9348cda7db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ad0q2j7x/wheels/68/af/c5/c8a9f7370515ab9b237b3fd59c04a0e7c5d4dedc7a6768a772\n",
            "Successfully built fastcore\n",
            "Collecting https://github.com/fastai/fastai2/archive/master.zip\n",
            "  Using cached https://github.com/fastai/fastai2/archive/master.zip\n",
            "Requirement already satisfied (use --upgrade to upgrade): fastai2==0.0.18 from https://github.com/fastai/fastai2/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.1.18)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.7.0a0+a6073f0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (3.13)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.2.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (7.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2==0.0.18) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2==0.0.18) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2==0.0.18) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2==0.0.18) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2==0.0.18) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2==0.0.18) (2.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2==0.0.18) (0.15.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (47.3.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (0.7.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2==0.0.18) (7.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->fastai2==0.0.18) (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.18) (3.1.0)\n",
            "Building wheels for collected packages: fastai2\n",
            "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastai2: filename=fastai2-0.0.18-cp36-none-any.whl size=192058 sha256=75dc137019bd57828ebbcd6e38f608ae38a46f6871263f0e6420079bc3ac0fef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h51aplnb/wheels/b2/28/3b/7a38644c6129e851e0db09b594949028266a62f4cb234fd1f3\n",
            "Successfully built fastai2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "csJ1oBNIw3Mr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f337b711-3ddf-4fe4-e8e5-04225e7bb2e5"
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('__call__', <function LevelMapper.__call__ at 0x7fe4787fc730>), ('__init__', <function LevelMapper.__init__ at 0x7fe4787fc6a8>)]\n",
            "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7fe47859d2f0>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7fe47859d268>)]\n",
            "[('__init__', <function BoxCoder.__init__ at 0x7fe4785a8730>), ('decode', <function BoxCoder.decode at 0x7fe4785a88c8>), ('decode_single', <function BoxCoder.decode_single at 0x7fe4785a8950>), ('encode', <function BoxCoder.encode at 0x7fe4785a87b8>), ('encode_single', <function BoxCoder.encode_single at 0x7fe4785a8840>)]\n",
            "[('__call__', <function Matcher.__call__ at 0x7fe4785a8620>), ('__init__', <function Matcher.__init__ at 0x7fe4785a8a60>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7fe4785a86a8>)]\n",
            "[('__init__', <function ImageList.__init__ at 0x7fe4785a8bf8>), ('to', <function ImageList.to at 0x7fe4785a8b70>)]\n",
            "[('__init__', <function Timebase.__init__ at 0x7fe478486b70>)]\n",
            "[('__init__', <function VideoMetaData.__init__ at 0x7fe478486840>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mdVrkyB9w3Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.MNIST_TINY)\n",
        "datablock = DataBlock(\n",
        "    blocks=(ImageBlock(cls=PILImageBW),CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(),\n",
        "    item_tfms=Resize(28),\n",
        "    batch_tfms=[]\n",
        ")\n",
        "#datablock.summary(path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ONBUwwwzw3M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLenet(nn.Module):\n",
        "    \"\"\"Lenet with convs and F.max_pool2d\"\"\"\n",
        "    def __init__(self):\n",
        "        super(MyLenet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3) # set 3 for first item if RGB\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.hiden4 = nn.Linear(400, 2) # 2 outputs (3 and 7) instead of 10\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.hiden4(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "class Lenet2(nn.Module):\n",
        "    \"\"\"Lenet with layers\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3) # set 3 for first item if RGB\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs (3 and 7) instead of 10\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wsW5SYWNw3M6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "3109f253-5708-4698-a600-50e373a1c9b2"
      },
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "tpu_device = xm.xla_device()\n",
        "# Use same datablock, but load with TPU\n",
        "dls_tpu = datablock.dataloaders(path, device=tpu_device)\n",
        "dls_tpu.device, dls_tpu.vocab, dls_tpu.show_batch()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='xla', index=1), (#2) ['3','7'], None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o2_773Ihw3M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_local(msg):\n",
        "  if True: return\n",
        "  print(msg)\n",
        "\n",
        "class CallbackXLA(Callback):\n",
        "  def after_step(self):\n",
        "    xm.optimizer_step(self.opt, barrier=True)\n",
        "\n",
        "\n",
        "class XLAOptimProxy:\n",
        "    def __init__(self,opt:Optimizer):\n",
        "        self.opt = opt\n",
        "\n",
        "    def xla_step(self):\n",
        "        xm.optimizer_step(self.opt,barrier=True) # sync on gradient update\n",
        "\n",
        "    def __getattr__(self,name):\n",
        "        if name == 'step': # override proxying for step method\n",
        "                print_local(\"calling xla_step\")\n",
        "                return getattr(self,'xla_step')\n",
        "        # proxy everything else\n",
        "        print_local(f\"calling {name}\")\n",
        "        return getattr(self.opt,name)\n",
        "\n",
        "\n",
        "@patch_to(ParamScheduler)\n",
        "def _update_val(self, pct):\n",
        "#        for n,f in self.scheds.items(): self.opt.set_hyper(n, f(pct))\n",
        "        for n,f in self.scheds.items():\n",
        "            v = f(pct)\n",
        "            print_local(f\"---------------------- A f(pct) = {v}\")\n",
        "            self.opt.set_hyper(n, v)\n",
        "\n",
        "@patch_to(ParamScheduler)\n",
        "def after_batch(self):\n",
        "#        for p in self.scheds.keys(): self.hps[p].append(self.opt.hypers[-1][p])\n",
        "        for p in self.scheds.keys():\n",
        "            v = self.opt.hypers[-1][p]\n",
        "            print_local(f\"---------------------- B after_batch ParamScheduler {v}\")\n",
        "            self.hps[p].append(v)\n",
        "@patch_to(Learner)\n",
        "def create_opt(self):\n",
        "        print_local(\"create_opt!!!\")\n",
        "        ooo = self.opt_func(self.splitter(self.model), lr=self.lr)\n",
        "        prox = XLAOptimProxy(ooo)\n",
        "        self.opt = prox\n",
        "        if not self.wd_bn_bias:\n",
        "            for p in self._bn_bias_state(True ): p['do_wd'] = False\n",
        "        if self.train_bn:\n",
        "            for p in self._bn_bias_state(False): p['force_train'] = True\n",
        "\n",
        "proxyLearn = Learner(dls_tpu, Lenet2(), metrics=accuracy, opt_func=Adam)#, cbs=CallbackXLA)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QeNFvM6gw3ND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "848575f1-7e5a-4f9b-917a-896767b70fb3"
      },
      "source": [
        "proxyLearn.fit(50, 10e-3) # 0.05) NOTE: Im not sure if this works...!!! it is now 96!"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling set_hypers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.015934</td>\n",
              "      <td>0.008114</td>\n",
              "      <td>0.997139</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.015063</td>\n",
              "      <td>0.051340</td>\n",
              "      <td>0.985694</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.013705</td>\n",
              "      <td>0.012020</td>\n",
              "      <td>0.995708</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.009627</td>\n",
              "      <td>0.025635</td>\n",
              "      <td>0.992847</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.007156</td>\n",
              "      <td>0.009010</td>\n",
              "      <td>0.995708</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.005273</td>\n",
              "      <td>0.007940</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.008264</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.003049</td>\n",
              "      <td>0.006678</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.002361</td>\n",
              "      <td>0.005485</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.001844</td>\n",
              "      <td>0.004880</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>0.004317</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000910</td>\n",
              "      <td>0.003915</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>0.003860</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.003750</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.003613</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.003523</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.003496</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.003549</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.003524</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.003372</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.003265</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.003155</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.003249</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.003299</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.003039</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.003152</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.003030</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.003008</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.002967</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.002982</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.002894</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.002880</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.002959</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.002848</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002832</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002695</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002717</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002787</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.002781</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.002617</td>\n",
              "      <td>0.998569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2VJcUCGbMqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29f16901-c670-4d0f-8a15-82a6870db528"
      },
      "source": [
        "proxyLearn.lr_find()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling set_hypers\n",
            "calling state_dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "---------------------- A f(pct) = 1e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1e-07\n",
            "---------------------- A f(pct) = 1.202264434617413e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.202264434617413e-07\n",
            "---------------------- A f(pct) = 1.4454397707459274e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.4454397707459274e-07\n",
            "---------------------- A f(pct) = 1.7378008287493754e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.7378008287493754e-07\n",
            "---------------------- A f(pct) = 2.0892961308540395e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.0892961308540395e-07\n",
            "---------------------- A f(pct) = 2.51188643150958e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.51188643150958e-07\n",
            "---------------------- A f(pct) = 3.019951720402016e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.019951720402016e-07\n",
            "---------------------- A f(pct) = 3.6307805477010137e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.6307805477010137e-07\n",
            "---------------------- A f(pct) = 4.36515832240166e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 4.36515832240166e-07\n",
            "---------------------- A f(pct) = 5.248074602497725e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 5.248074602497725e-07\n",
            "---------------------- A f(pct) = 6.309573444801933e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 6.309573444801933e-07\n",
            "---------------------- A f(pct) = 7.585775750291837e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 7.585775750291837e-07\n",
            "---------------------- A f(pct) = 9.120108393559096e-07\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 9.120108393559096e-07\n",
            "---------------------- A f(pct) = 1.096478196143185e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.096478196143185e-06\n",
            "---------------------- A f(pct) = 1.3182567385564074e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.3182567385564074e-06\n",
            "---------------------- A f(pct) = 1.5848931924611132e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.5848931924611132e-06\n",
            "---------------------- A f(pct) = 1.9054607179632473e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.9054607179632473e-06\n",
            "---------------------- A f(pct) = 2.2908676527677735e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.2908676527677735e-06\n",
            "---------------------- A f(pct) = 2.754228703338166e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.754228703338166e-06\n",
            "---------------------- A f(pct) = 3.311311214825911e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.311311214825911e-06\n",
            "---------------------- A f(pct) = 3.981071705534973e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.981071705534973e-06\n",
            "---------------------- A f(pct) = 4.7863009232263826e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 4.7863009232263826e-06\n",
            "---------------------- A f(pct) = 5.754399373371569e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 5.754399373371569e-06\n",
            "---------------------- A f(pct) = 6.918309709189365e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 6.918309709189365e-06\n",
            "---------------------- A f(pct) = 8.317637711026708e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 8.317637711026708e-06\n",
            "---------------------- A f(pct) = 9.999999999999999e-06\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 9.999999999999999e-06\n",
            "---------------------- A f(pct) = 1.202264434617413e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.202264434617413e-05\n",
            "---------------------- A f(pct) = 1.4454397707459279e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.4454397707459279e-05\n",
            "---------------------- A f(pct) = 1.737800828749376e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.737800828749376e-05\n",
            "---------------------- A f(pct) = 2.0892961308540385e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.0892961308540385e-05\n",
            "---------------------- A f(pct) = 2.5118864315095795e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 2.5118864315095795e-05\n",
            "---------------------- A f(pct) = 3.019951720402016e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.019951720402016e-05\n",
            "---------------------- A f(pct) = 3.630780547701014e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 3.630780547701014e-05\n",
            "---------------------- A f(pct) = 4.365158322401661e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 4.365158322401661e-05\n",
            "---------------------- A f(pct) = 5.248074602497728e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 5.248074602497728e-05\n",
            "---------------------- A f(pct) = 6.309573444801929e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 6.309573444801929e-05\n",
            "---------------------- A f(pct) = 7.585775750291836e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 7.585775750291836e-05\n",
            "---------------------- A f(pct) = 9.120108393559096e-05\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 9.120108393559096e-05\n",
            "---------------------- A f(pct) = 0.00010964781961431851\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.00010964781961431851\n",
            "---------------------- A f(pct) = 0.00013182567385564074\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.00013182567385564074\n",
            "---------------------- A f(pct) = 0.0001584893192461114\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0001584893192461114\n",
            "---------------------- A f(pct) = 0.00019054607179632462\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.00019054607179632462\n",
            "---------------------- A f(pct) = 0.00022908676527677726\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.00022908676527677726\n",
            "---------------------- A f(pct) = 0.0002754228703338166\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0002754228703338166\n",
            "---------------------- A f(pct) = 0.0003311311214825911\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0003311311214825911\n",
            "---------------------- A f(pct) = 0.0003981071705534973\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0003981071705534973\n",
            "---------------------- A f(pct) = 0.0004786300923226385\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0004786300923226385\n",
            "---------------------- A f(pct) = 0.0005754399373371565\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0005754399373371565\n",
            "---------------------- A f(pct) = 0.0006918309709189362\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0006918309709189362\n",
            "---------------------- A f(pct) = 0.0008317637711026709\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0008317637711026709\n",
            "---------------------- A f(pct) = 0.001\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.001\n",
            "---------------------- A f(pct) = 0.001202264434617413\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.001202264434617413\n",
            "---------------------- A f(pct) = 0.001445439770745928\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.001445439770745928\n",
            "---------------------- A f(pct) = 0.001737800828749376\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.001737800828749376\n",
            "---------------------- A f(pct) = 0.0020892961308540407\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0020892961308540407\n",
            "---------------------- A f(pct) = 0.002511886431509582\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.002511886431509582\n",
            "---------------------- A f(pct) = 0.0030199517204020187\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0030199517204020187\n",
            "---------------------- A f(pct) = 0.00363078054770101\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.00363078054770101\n",
            "---------------------- A f(pct) = 0.004365158322401656\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.004365158322401656\n",
            "---------------------- A f(pct) = 0.005248074602497722\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.005248074602497722\n",
            "---------------------- A f(pct) = 0.006309573444801929\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.006309573444801929\n",
            "---------------------- A f(pct) = 0.007585775750291836\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.007585775750291836\n",
            "---------------------- A f(pct) = 0.009120108393559097\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.009120108393559097\n",
            "---------------------- A f(pct) = 0.01096478196143185\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.01096478196143185\n",
            "---------------------- A f(pct) = 0.013182567385564075\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.013182567385564075\n",
            "---------------------- A f(pct) = 0.01584893192461114\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.01584893192461114\n",
            "---------------------- A f(pct) = 0.019054607179632484\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.019054607179632484\n",
            "---------------------- A f(pct) = 0.022908676527677745\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.022908676527677745\n",
            "---------------------- A f(pct) = 0.027542287033381692\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.027542287033381692\n",
            "---------------------- A f(pct) = 0.03311311214825908\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.03311311214825908\n",
            "---------------------- A f(pct) = 0.03981071705534969\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.03981071705534969\n",
            "---------------------- A f(pct) = 0.0478630092322638\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.0478630092322638\n",
            "---------------------- A f(pct) = 0.05754399373371566\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.05754399373371566\n",
            "---------------------- A f(pct) = 0.06918309709189363\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.06918309709189363\n",
            "---------------------- A f(pct) = 0.08317637711026708\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.08317637711026708\n",
            "---------------------- A f(pct) = 0.09999999999999999\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.09999999999999999\n",
            "---------------------- A f(pct) = 0.12022644346174131\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.12022644346174131\n",
            "---------------------- A f(pct) = 0.1445439770745928\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.1445439770745928\n",
            "---------------------- A f(pct) = 0.17378008287493762\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.17378008287493762\n",
            "---------------------- A f(pct) = 0.2089296130854041\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.2089296130854041\n",
            "---------------------- A f(pct) = 0.25118864315095824\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.25118864315095824\n",
            "---------------------- A f(pct) = 0.3019951720402019\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.3019951720402019\n",
            "---------------------- A f(pct) = 0.36307805477010097\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.36307805477010097\n",
            "---------------------- A f(pct) = 0.43651583224016566\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.43651583224016566\n",
            "---------------------- A f(pct) = 0.5248074602497723\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.5248074602497723\n",
            "---------------------- A f(pct) = 0.630957344480193\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.630957344480193\n",
            "---------------------- A f(pct) = 0.7585775750291835\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.7585775750291835\n",
            "---------------------- A f(pct) = 0.9120108393559095\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 0.9120108393559095\n",
            "---------------------- A f(pct) = 1.096478196143185\n",
            "calling set_hyper\n",
            "calling xla_step\n",
            "calling zero_grad\n",
            "calling hypers\n",
            "calling hypers\n",
            "---------------------- B after_batch ParamScheduler 1.096478196143185\n",
            "calling zero_grad\n",
            "calling load_state_dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=8.31763736641733e-07, lr_steep=6.309573450380412e-07)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yJIU2E7rw3NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}