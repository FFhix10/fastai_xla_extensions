{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo batch_tfms TPU performance diff- debug-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1WvCml-U_6LrLls3rbneAR9AFhtgtpTOa",
      "authorship_tag": "ABX9TyO3sRs4eofOwd71TkkfMcgQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e2d29ff16884055affd52cbd25c0131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58dc8597b48a49bbb610605674b69569",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cadae07b42f4483b8e4cd3939ccab1d",
              "IPY_MODEL_df28a55828e74a44bb5a5098ea651236"
            ]
          }
        },
        "58dc8597b48a49bbb610605674b69569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cadae07b42f4483b8e4cd3939ccab1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_257837b1abaf419ea3d2c2dbd9cb4ad0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6139c2913004708b5f518ca27334a32"
          }
        },
        "df28a55828e74a44bb5a5098ea651236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4477e5f200f7444da4faebdc0238ecf7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [03:29&lt;00:00, 224kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d795263fc8304895937eddf5a1cce32c"
          }
        },
        "257837b1abaf419ea3d2c2dbd9cb4ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6139c2913004708b5f518ca27334a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4477e5f200f7444da4faebdc0238ecf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d795263fc8304895937eddf5a1cce32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/explore_nbs/Demo_batch_tfms_TPU_performance_diff_debug_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peHi6g9T93HM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0f434da-d0ca-4d4c-8e87-fe55b754a699"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR3nOBQ6-Kip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0d6be3de-bcd9-4b5d-abbb-35ed96075fa6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLQPoJ6Fn8wF",
        "colab_type": "text"
      },
      "source": [
        "### [RUNME] Install Colab compatible PyTorch/XLA wheels and dependencies\n",
        "This may take up to ~2 minutes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53lrJMDn9Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5c25f40-25ea-43be-8abf-006b21147348"
      },
      "source": [
        "VERSION = \"20200516\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5115  100  5115    0     0  61626      0 --:--:-- --:--:-- --:--:-- 61626\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200516 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (49.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Uninstalling torch-1.5.1+cu101:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.5.1+cu101\n",
            "Uninstalling torchvision-0.6.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.8 MiB/119.8 MiB]                                                \n",
            "Operation completed over 1 objects/119.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+83df3be\n",
            "Processing ./torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2191422\n",
            "Processing ./torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.6.0a0+83df3be)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200516) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+348dd5a\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (383 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W21CF87-WGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfb6b391-e076-4dbc-a476-23b96726cb74"
      },
      "source": [
        "!pip install fastai2 --upgrade > /dev/null\n",
        "!pip freeze | grep fastai2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai2==0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRxgodMi_TbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b5628f3-7c92-4649-e345-52b79012f50f"
      },
      "source": [
        "!pip install git+https://github.com/butchland/fastai_xla_extensions > /dev/null\n",
        "!pip freeze | grep fastai_xla_extensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/butchland/fastai_xla_extensions /tmp/pip-req-build-mh5077d7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1jhRI2W_KeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai_xla_extensions.core"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpyDErab_pJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ3IT9T0_3dR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "de55ab9f-f095-48ad-ffba-39f52d615715"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn5GRDr9GxuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38b44009-1e4a-42d0-b6c9-b9e0b9fe895b"
      },
      "source": [
        "Path.BASE_PATH = path; path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQkAJm2kBFRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock = DataBlock(\n",
        "    blocks=(ImageBlock,CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(train_name='training',valid_name='testing'),\n",
        "    item_tfms=Resize(28),\n",
        "    batch_tfms=[]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiw5dcc6Bxee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_tfms= datablock.new(batch_tfms=[*aug_transforms(size=28, do_flip=False), Normalize],item_tfms=Resize(40))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqAiBxQsMFv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffc350e4-90a0-4c26-cefe-b3098f24382f"
      },
      "source": [
        "datablock_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> AffineCoordTfm -> LightingTfm -> Normalize\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=40x40, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x40x40, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> AffineCoordTfm -> LightingTfm -> Normalize\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying AffineCoordTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying LightingTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying Normalize gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqW7O2HjCd5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8848fcc-7767-4391-d55a-f71fa2630a05"
      },
      "source": [
        "dls1 = datablock_tfms.dataloaders(path,bs=256)\n",
        "dls1.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-_a_HwuCsSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1e2d29ff16884055affd52cbd25c0131",
            "58dc8597b48a49bbb610605674b69569",
            "8cadae07b42f4483b8e4cd3939ccab1d",
            "df28a55828e74a44bb5a5098ea651236",
            "257837b1abaf419ea3d2c2dbd9cb4ad0",
            "f6139c2913004708b5f518ca27334a32",
            "4477e5f200f7444da4faebdc0238ecf7",
            "d795263fc8304895937eddf5a1cce32c"
          ]
        },
        "outputId": "dec9afba-6bf1-4b2e-c17a-315c8f25c9f8"
      },
      "source": [
        "learn1 = cnn_learner(dls1, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e2d29ff16884055affd52cbd25c0131",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyCGwlqkC34B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "a62a7bf3-368f-4ebb-8113-29df9ce5c486"
      },
      "source": [
        "learn1.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.571644</td>\n",
              "      <td>0.909826</td>\n",
              "      <td>0.715700</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.988431</td>\n",
              "      <td>0.603125</td>\n",
              "      <td>0.806000</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.655336</td>\n",
              "      <td>0.407106</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.452211</td>\n",
              "      <td>0.275844</td>\n",
              "      <td>0.912600</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0bwLRDDF5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_no_tfms= datablock.new(batch_tfms=[],item_tfms=Resize(28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpWVdxJXN7ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "5f6714fb-bdd6-402d-b552-f9002325262e"
      },
      "source": [
        "datablock_no_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alqvdILZENon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6266947-f7dd-4b2f-893f-e01128c5f18e"
      },
      "source": [
        "dls2 = datablock_no_tfms.dataloaders(path,bs=256)\n",
        "dls2.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z16-5jtfEcF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2 = cnn_learner(dls2, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbR9PtFsEmw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "0cee1c1a-b6f6-43a1-88a5-ace5060e001b"
      },
      "source": [
        "learn2.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.443302</td>\n",
              "      <td>0.865859</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>01:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.878908</td>\n",
              "      <td>0.581814</td>\n",
              "      <td>0.814500</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.551731</td>\n",
              "      <td>0.378798</td>\n",
              "      <td>0.878700</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.371268</td>\n",
              "      <td>0.261603</td>\n",
              "      <td>0.916700</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh7YjdBLLs_x",
        "colab_type": "text"
      },
      "source": [
        "Add Normalize to empty batch transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwl4zKlZh55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_tfms_norm_only = datablock.new(item_tfms=Resize(28), batch_tfms=[Normalize])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZJDFnIzeYku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "ede163ef-f495-4c45-9783-a75ba7be6f3b"
      },
      "source": [
        "datablock_tfms_norm_only.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> Normalize\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> Normalize\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying Normalize gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKbGqNlVZzdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98ac1c6a-c3c4-4f8b-ddfe-e78456df8533"
      },
      "source": [
        "dls3 = datablock_tfms_norm_only.dataloaders(path, bs=256)\n",
        "dls3.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWKIWykkaFoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn3 = cnn_learner(dls3, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6AnUINZaL4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "28bdfda0-ff6f-430e-931c-ba3ee71c5ce3"
      },
      "source": [
        "learn3.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.419888</td>\n",
              "      <td>0.883360</td>\n",
              "      <td>0.726900</td>\n",
              "      <td>01:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.845393</td>\n",
              "      <td>0.575396</td>\n",
              "      <td>0.818500</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.538643</td>\n",
              "      <td>0.390274</td>\n",
              "      <td>0.872400</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.371201</td>\n",
              "      <td>0.275787</td>\n",
              "      <td>0.911500</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coEU736edIoZ",
        "colab_type": "text"
      },
      "source": [
        "Normalize doesnt seem to slow it down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO4BsW7WdMxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_tfms = [*aug_transforms(size=28, do_flip=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UTtSTXkaQ9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18a3f288-1a8f-4ef1-a438-9b9d334dc08f"
      },
      "source": [
        "len(batch_tfms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHgb44IdhxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "bba36e2d-2bc5-4902-e193-ecf70f89fdf4"
      },
      "source": [
        "batch_tfms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AffineCoordTfm: (TensorBBox,object) -> encodes\n",
              " (TensorPoint,object) -> encodes\n",
              " (TensorImage,object) -> encodes\n",
              " (TensorMask,object) -> encodes ,\n",
              " LightingTfm: (TensorImage,object) -> encodes ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVpocMC-dmIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_affine_tfms = [batch_tfms[1],Normalize]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovKNbYJ2d8oS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2f18b379-4c1f-40de-f53a-dcdeccd76924"
      },
      "source": [
        "no_affine_tfms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LightingTfm: (TensorImage,object) -> encodes ,\n",
              " fastai2.data.transforms.Normalize]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjeAcRtkeBby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_no_affine_tfms = datablock.new(item_tfms=Resize(28), batch_tfms=no_affine_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKqJTza-eviq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "outputId": "dcccd37f-0c09-498f-9eee-b06916b6b9e8"
      },
      "source": [
        "datablock_no_affine_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> LightingTfm -> Normalize\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> LightingTfm -> Normalize\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying LightingTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying Normalize gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7n8cO2aezRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0747df50-de4a-48a0-bbb4-6c3e4183f87a"
      },
      "source": [
        "dls4 = datablock_no_affine_tfms.dataloaders(path, bs=256)\n",
        "dls4.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaNTamCFfc3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn4 = cnn_learner(dls4, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDhNbSsyfkiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "964831f4-73e7-4147-d3ee-2a38e0f7225f"
      },
      "source": [
        "learn4.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.428789</td>\n",
              "      <td>0.870235</td>\n",
              "      <td>0.727900</td>\n",
              "      <td>01:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.861603</td>\n",
              "      <td>0.564166</td>\n",
              "      <td>0.820700</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.540606</td>\n",
              "      <td>0.390945</td>\n",
              "      <td>0.874900</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.371852</td>\n",
              "      <td>0.266826</td>\n",
              "      <td>0.910500</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twbCSdHffu00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_affine_only_tfms = datablock.new(item_tfms=Resize(40), batch_tfms=[batch_tfms[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t38hJe8ih69e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "aa3741c9-7a05-4643-9c5d-5753fde97bca"
      },
      "source": [
        "datablock_affine_only_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=40x40, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x40x40, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying AffineCoordTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyJRIpavh-dC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d164d7a7-4ed0-4720-f203-7d12c827621c"
      },
      "source": [
        "dls5 = datablock_affine_only_tfms.dataloaders(path, bs=256)\n",
        "dls5.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clgU0ZnuiMCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn5 = cnn_learner(dls5, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPDyHjOJiXYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "be9d5c02-aa10-43dc-e6f5-3e8cc949ed0e"
      },
      "source": [
        "learn5.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.531065</td>\n",
              "      <td>0.877829</td>\n",
              "      <td>0.720200</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.967777</td>\n",
              "      <td>0.580436</td>\n",
              "      <td>0.813000</td>\n",
              "      <td>01:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.639149</td>\n",
              "      <td>0.379227</td>\n",
              "      <td>0.876600</td>\n",
              "      <td>01:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.437950</td>\n",
              "      <td>0.262171</td>\n",
              "      <td>0.913900</td>\n",
              "      <td>01:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1PwLyzNkKZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "717b7725-17ce-473c-f1e8-b41c509c62c5"
      },
      "source": [
        "min_aug = aug_transforms(size=28, do_flip=False, max_rotate=0.0, max_zoom=1.1,max_warp=0.)\n",
        "min_aug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AffineCoordTfm: (TensorBBox,object) -> encodes\n",
              " (TensorPoint,object) -> encodes\n",
              " (TensorImage,object) -> encodes\n",
              " (TensorMask,object) -> encodes ,\n",
              " LightingTfm: (TensorImage,object) -> encodes ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uc2zkOgnr-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_min_affine_only = datablock.new(item_tfms=Resize(40), batch_tfms=[min_aug[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8vlIzaNoFOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "e8bfc96c-0a51-4e39-b85d-0ac521ca8d1f"
      },
      "source": [
        "datablock_min_affine_only.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=40x40, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x40x40, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying AffineCoordTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKea-TOWoMbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "aea73538-6759-4c10-90df-f5ea81dcc4ba"
      },
      "source": [
        "min_aug[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffineCoordTfm: (TensorBBox,object) -> encodes\n",
              "(TensorPoint,object) -> encodes\n",
              "(TensorImage,object) -> encodes\n",
              "(TensorMask,object) -> encodes "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_9QA6dKoR1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls6 = datablock_min_affine_only.dataloaders(path, bs=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClVK4kv6ocnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "ead6c3e0-8c76-4a68-b902-c50d9479cc79"
      },
      "source": [
        "dls6.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Udx2y6-om92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn6 = cnn_learner(dls6, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEkBhWUDpXTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "b1c58c09-208a-4ba7-f105-a5794d651d24"
      },
      "source": [
        "learn6.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.393099</td>\n",
              "      <td>0.837496</td>\n",
              "      <td>0.735300</td>\n",
              "      <td>01:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.822208</td>\n",
              "      <td>0.554914</td>\n",
              "      <td>0.821900</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.528956</td>\n",
              "      <td>0.357311</td>\n",
              "      <td>0.884600</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.365569</td>\n",
              "      <td>0.242920</td>\n",
              "      <td>0.921600</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOxgDOuwpbRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "light_only_aug_tfms = aug_transforms(size=28, do_flip=False, max_rotate=0, max_zoom=1.0, max_warp=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsrXevsurWhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6eee458-4319-49be-caa4-998cb66c3088"
      },
      "source": [
        "light_only_aug_tfms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LightingTfm: (TensorImage,object) -> encodes ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIrsWt-ZrYdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_light_only_tfms = datablock.new(item_tfms=Resize(28), batch_tfms=light_only_aug_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSJSzHEarz1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "8557c1bc-7639-47c7-fc01-a6d39fe68ac3"
      },
      "source": [
        "datablock_light_only_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> LightingTfm\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> LightingTfm\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying LightingTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fam6zSKnrp0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls7 = datablock_light_only_tfms.dataloaders(path, bs=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6XXZ9PUrwfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "837a3889-7030-4f2f-97cb-4c361c422d8b"
      },
      "source": [
        "dls7.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lsKathWsA-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn7 = cnn_learner(dls7, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kT3KyrjsLGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "39becd19-a32f-42dc-9d34-1a50e5018b13"
      },
      "source": [
        "learn7.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.447988</td>\n",
              "      <td>0.857747</td>\n",
              "      <td>0.733100</td>\n",
              "      <td>01:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.875352</td>\n",
              "      <td>0.563979</td>\n",
              "      <td>0.821700</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.556831</td>\n",
              "      <td>0.382872</td>\n",
              "      <td>0.879900</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.379415</td>\n",
              "      <td>0.260477</td>\n",
              "      <td>0.916000</td>\n",
              "      <td>01:25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ6-3XUlsOmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4c917b76-74c4-4569-eaf6-0fed4529ccd0"
      },
      "source": [
        "warp_only_affine_tfms = aug_transforms(size=28, do_flip=False, max_rotate=0.0, max_zoom=1., max_lighting=0.0)\n",
        "warp_only_affine_tfms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AffineCoordTfm: (TensorBBox,object) -> encodes\n",
              " (TensorPoint,object) -> encodes\n",
              " (TensorImage,object) -> encodes\n",
              " (TensorMask,object) -> encodes ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxhupFXkuwqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_warp_only_affine_tfms = datablock.new(item_tfms=Resize(40), batch_tfms=warp_only_affine_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJFWZ01vJ5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "4097ca6a-d3e3-49e0-e458-808ba466d41e"
      },
      "source": [
        "datablock_warp_only_affine_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=40x40, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x40x40, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> AffineCoordTfm\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying AffineCoordTfm gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPx2bVwEvNbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3be86a4-bd66-4531-a2b8-35cefaab4f16"
      },
      "source": [
        "dls8 = datablock_warp_only_affine_tfms.dataloaders(path, bs=256)\n",
        "dls8.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_LPbNnvxx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn8 = cnn_learner(dls8, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jJ70dzAwgHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "d8963115-e0a9-4b7e-a8c1-eb0ad45328ef"
      },
      "source": [
        "learn8.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.530683</td>\n",
              "      <td>0.848905</td>\n",
              "      <td>0.733300</td>\n",
              "      <td>01:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.940204</td>\n",
              "      <td>0.550284</td>\n",
              "      <td>0.828200</td>\n",
              "      <td>01:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.609583</td>\n",
              "      <td>0.370258</td>\n",
              "      <td>0.880400</td>\n",
              "      <td>01:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.411337</td>\n",
              "      <td>0.249669</td>\n",
              "      <td>0.918400</td>\n",
              "      <td>01:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmcY6yivwkH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8231457b-3f4a-4f73-b87c-2b7229b8d462"
      },
      "source": [
        "size_only_aug_tfms = aug_transforms(size=28, do_flip=False, max_rotate=0.0, max_zoom=1.0, max_warp=0., max_lighting=0.0, min_scale=0.8)\n",
        "size_only_aug_tfms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RandomResizedCropGPU: (TensorImage,object) -> encodes ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUQXopDCyg0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock_size_only_aug_tfms = datablock.new(item_tfms=Resize(40), batch_tfms=size_only_aug_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QIEHugDy_bf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "f2c97622-1922-483b-f7be-bee19046722c"
      },
      "source": [
        "datablock_size_only_aug_tfms.summary(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_png\n",
            "Found 70000 items\n",
            "2 datasets of sizes 60000,10000\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_png/training/6/13035.png\n",
            "    applying parent_label gives\n",
            "      6\n",
            "    applying Categorize gives\n",
            "      TensorCategory(6)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor -> RandomResizedCropGPU\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(6))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=40x40, TensorCategory(6))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x40x40, TensorCategory(6))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor -> RandomResizedCropGPU\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x40x40, TensorCategory([6, 6, 6, 6], device='xla:1'))\n",
            "    applying RandomResizedCropGPU gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([6, 6, 6, 6], device='xla:1'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli6QM-HzDWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16e539de-fe6e-4bb0-a537-aa1ea69eb628"
      },
      "source": [
        "dls9 = datablock_size_only_aug_tfms.dataloaders(path, bs=256)\n",
        "dls9.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUz-YLp505_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn9 = cnn_learner(dls9, resnet18, metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNfXOpo-1AZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "b7ed7b29-95d1-4f5c-9716-7f77a514d6b2"
      },
      "source": [
        "learn9.fine_tune(0, freeze_epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.393913</td>\n",
              "      <td>0.873277</td>\n",
              "      <td>0.721300</td>\n",
              "      <td>01:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.834082</td>\n",
              "      <td>0.584564</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.536710</td>\n",
              "      <td>0.400622</td>\n",
              "      <td>0.872000</td>\n",
              "      <td>01:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.363823</td>\n",
              "      <td>0.287238</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH5mNwYd1FMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}